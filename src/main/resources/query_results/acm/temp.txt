@inproceedings{10.1007/978-3-642-28166-2_12,
author = {Saadatmand, Mehrdad and Cicchetti, Antonio and Sj\"{o}din, Mikael},
title = {Design of Adaptive Security Mechanisms for Real-Time Embedded Systems},
year = {2012},
isbn = {9783642281655},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-28166-2_12},
doi = {10.1007/978-3-642-28166-2_12},
abstract = {Introducing security features in a system is not free and brings along its costs and impacts. Considering this fact is essential in the design of real-time embedded systems which have limited resources. To ensure correct design of these systems, it is important to also take into account impacts of security features on other non-functional requirements, such as performance and energy consumption. Therefore, it is necessary to perform trade-off analysis among non-functional requirements to establish balance among them. In this paper, we target the timing requirements of real-time embedded systems, and introduce an approach for choosing appropriate encryption algorithms at runtime, to achieve satisfaction of timing requirements in an adaptive way, by monitoring and keeping a log of their behaviors. The approach enables the system to adopt a less or more time consuming (but presumably stronger) encryption algorithm, based on the feedback on previous executions of encryption processes. This is particularly important for systems with high degree of complexity which are hard to analyze statistically.},
booktitle = {Proceedings of the 4th International Conference on Engineering Secure Software and Systems},
pages = {121–134},
numpages = {14},
keywords = {security, trade-off, real-time embedded systems, runtime adaptation},
location = {Eindhoven, The Netherlands},
series = {ESSoS'12}
}

@article{10.1007/s00165-013-0286-3,
author = {Frappier, Marc and Gervais, Fr\'{e}d\'{e}ric and Laleau, R\'{e}gine and Milhau, J\'{e}r\'{e}my},
title = {Refinement Patterns for ASTDs},
year = {2014},
issue_date = {Sep 2014},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {26},
number = {5},
issn = {0934-5043},
url = {https://doi.org/10.1007/s00165-013-0286-3},
doi = {10.1007/s00165-013-0286-3},
abstract = {This paper introduces three refinement patterns for algebraic state-transition diagrams (astds): state refinement, transition refinement and loop-transition refinement. These refinement patterns are derived from practice in using astds for specifying information systems and security policies in two industrial research projects. Two refinement relations used in these patterns are formally defined. For each pattern, proof obligations are proposed to ensure preservation of behaviour through refinement. The proposed refinement relations essentially consist in preserving scenarios by replacing abstract events with concrete events, or by introducing new events. Deadlocks cannot be introduced; divergence over new events is allowed in one of the refinement relation. We prove congruence-like properties for these three patterns, in order to show that they can be applied to a subpart of a specification while preserving global properties. These three refinement patterns are illustrated with a simple case study of a complaint management system.},
journal = {Form. Asp. Comput.},
month = {sep},
pages = {919–941},
numpages = {23},
keywords = {Information systems, astd, Refinement, Patterns}
}

@inproceedings{10.1109/ANCS.2017.26,
author = {Pan, Liuxuan and Tomlinson, Allan and Koloydenko, Alexey A.},
title = {Time Pattern Analysis of Malware by Circular Statistics},
year = {2017},
isbn = {9781509063864},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ANCS.2017.26},
doi = {10.1109/ANCS.2017.26},
abstract = {Circular statistics present a new technique to analyse the time patterns of events in the field of cyber security. We apply this technique to analyse incidents of malware infections detected by network monitoring. In particular we are interested in the daily and weekly variations of these events.Based on "live" data provided by Spamhaus, we examine the hypothesis that attacks on four countries are distributed uniformly over 24 hours. Specifically, we use Rayleigh and Watson tests. While our results are mainly exploratory, we are able to demonstrate that the attacks are not uniformly distributed, nor do they follow a Poisson distribution as reported in other research. Our objective in this is to identify a distribution that can be used to establish risk metrics.Moreover, our approach provides a visual overview of the time patterns' variation, indicating when attacks are most likely. This will assist decision makers in cyber security to allocate resources or estimate the cost of system monitoring during high risk periods.Our results also reveal that the time patterns are influenced by the total number of attacks. Networks subject to a large volume of attacks exhibit bimodality while one case, where attacks were at relatively lower rate, showed a multi-modal daily variation.},
booktitle = {Proceedings of the Symposium on Architectures for Networking and Communications Systems},
pages = {119–130},
numpages = {12},
keywords = {uniformity hypothesis test, malware, time patterns, Circular statistics},
location = {Beijing, China},
series = {ANCS '17}
}

@inproceedings{10.1109/SEAMS.2007.2,
author = {Elkhodary, Ahmed and Whittle, Jon},
title = {A Survey of Approaches to Adaptive Application Security},
year = {2007},
isbn = {0769529739},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SEAMS.2007.2},
doi = {10.1109/SEAMS.2007.2},
abstract = {Adaptive systems dynamically change their behavior or structure at runtime to respond to environmental changes. This paper considers one class of adaptive systems-those that adapt application-level security mechanisms. Nowadays, adaptive software security is gaining greater attention as a way to balance the tradeoff between systems security and IT infrastructure overhead. Several adaptive security systems have been developed recently supporting hardware-level to application-level reconfiguration. This paper surveys four adaptive application-level security systems and evaluates them in terms of how well they support critical security services (i.e. authentication, authorization, and tolerance) and what level of adaptation they achieve. Based on our evaluation results, we provide recommendations for future research.},
booktitle = {Proceedings of the 2007 International Workshop on Software Engineering for Adaptive and Self-Managing Systems},
pages = {16},
series = {SEAMS '07}
}

@inproceedings{10.1109/SER-IP.2017..21,
author = {Pasquale, Liliana},
title = {Topology Aware Adaptive Security},
year = {2017},
isbn = {9781538627976},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SER-IP.2017..21},
doi = {10.1109/SER-IP.2017..21},
abstract = {Cyber-Physical Systems can be harmed through both cyber-enabled or physically-enabled attacks, particularly ones that exploit the often ignored interplay between the cyber and physical spaces characterizing a system operating environment. Awareness of the topology of the operating environment of systems as well as its dynamics can support adaptive security more effectively.In this talk I propose the use of Bigraphical Reactive Systems to represent the topology of cyber and physical spaces. I describe how to use this representation to reason about the consequences of the evolution of topological configurations on the satisfaction of security requirements. I also illustrate a planning technique to identify an adaptation strategy to be used at runtime, to circumvent, prevent, or mitigate security requirements violations previously identified. Finally I will describe how this approach has been integrated into an existing commercial access control software.},
booktitle = {Proceedings of the 4th International Workshop on Software Engineering Research and Industrial Practice},
pages = {2},
numpages = {1},
location = {Buenos Aires, Argentina},
series = {SER&amp;IP '17}
}

@inproceedings{10.1145/1023783.1023802,
author = {Brawerman, Alessandro and Blough, Douglas and Bing, Benny},
title = {Securing the Download of Radio Configuration Files for Software Defined Radio Devices},
year = {2004},
isbn = {1581139209},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1023783.1023802},
doi = {10.1145/1023783.1023802},
abstract = {Radio configuration (R-CFG) files for software defined radio (SDR) devices can be downloaded over the air, allowing these devices to support multi-mode functionality using a single transceiver. SDR device manufacturers are likely to provide the R-CFGs, which may contain proprietary information. In such cases, it is necessary to secure the server/SDR device connection during the R-CFG download. Therefore, a protocol to securely connect manufacturer's server and SDR devices, called LSSL, is proposed. The LSSL is a lightweight protocol based on the SSL protocol, but it takes up less bandwidth, thus, it is more suitable for SDR handheld devices operating under low-capabilities, low-bandwidth and error-prone wireless links. However, securing the R-CFG download connection does not guarantee that a valid R-CFG, that is, an R-CFG that has been approved by the regulatory agency, has been downloaded. In order to install only valid R-CFGs, a secure download protocol is presented. The secure protocol includes, besides the LSSL, steps of mutual authentication, public/private key mechanisms for data encryption and decryption, and fingerprint calculations to check data integrity. Finally, the secure protocol is analyzed and shown to be deadlock and livelock-free, and to properly terminate. Experiments using Java 2 Micro Edition (J2ME) are performed to compare the LSSL and the SSL, and to demonstrate the feasibility of the secure protocol.},
booktitle = {Proceedings of the Second International Workshop on Mobility Management &amp; Wireless Access Protocols},
pages = {98–105},
numpages = {8},
keywords = {analysis of protocols, radio configuration, security and privacy issues and software},
location = {Philadelphia, PA, USA},
series = {MobiWac '04}
}

@inproceedings{10.1145/1046290.1046320,
author = {Tongshen, Hu and Xiamin and Qingzhang, Chen and Kezhen, Ying},
title = {Design and Implement of Firewall-Log-Based Online Attack Detection System},
year = {2004},
isbn = {1581139551},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1046290.1046320},
doi = {10.1145/1046290.1046320},
abstract = {This paper presents a firewall-log-based online attack detection system, giving its inner logic, composing, detecting method and realization. The system is up to firewall-log's online analysis, between-log relevancy checking, and automatic audit by the way of state transition of finite state machine. Test shows the system will provide firewall with not only network attack detection ability but also the ability to scan network addresses, scan communication ports and deny service.},
booktitle = {Proceedings of the 3rd International Conference on Information Security},
pages = {146–149},
numpages = {4},
keywords = {firewall, network security, log analysis},
location = {Shanghai, China},
series = {InfoSecu '04}
}

@inproceedings{10.1145/1083217.1083226,
author = {Srivastava, Deepti and Narasimhan, Priya},
title = {Architectural Support for Mode-Driven Fault Tolerance in Distributed Applications},
year = {2005},
isbn = {1595931244},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1083217.1083226},
doi = {10.1145/1083217.1083226},
abstract = {Many distributed applications exhibit different types of system behaviors, or modes, during the course of their operation. Each such mode may have different functional and non-functional requirements (such as fault tolerance, availability, and security). A static software fault-tolerance solution can not cater to the needs of every mode, and also does not utilize system resources intelligently. A flexible architecture is required to provide dependability that can be tailored for such applications. We propose a novel mode-driven fault-tolerance approach that includes: (i) a generic framework to extend the specification of modes with fault-tolerance requirements, and (ii) a software architecture that uses this description to provide the appropriate fault tolerance for each mode at runtime. We also present a case study using a distributed multi-modal CORBA application to demonstrate the effectiveness of our approach.},
booktitle = {Proceedings of the 2005 Workshop on Architecting Dependable Systems},
pages = {1–7},
numpages = {7},
keywords = {distributed systems, COTS systems, fault tolerance, replication, modes, software architecture, CORBA},
location = {St. Louis, Missouri},
series = {WADS '05}
}

@article{10.1145/1082983.1083226,
author = {Srivastava, Deepti and Narasimhan, Priya},
title = {Architectural Support for Mode-Driven Fault Tolerance in Distributed Applications},
year = {2005},
issue_date = {July 2005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {4},
issn = {0163-5948},
url = {https://doi.org/10.1145/1082983.1083226},
doi = {10.1145/1082983.1083226},
abstract = {Many distributed applications exhibit different types of system behaviors, or modes, during the course of their operation. Each such mode may have different functional and non-functional requirements (such as fault tolerance, availability, and security). A static software fault-tolerance solution can not cater to the needs of every mode, and also does not utilize system resources intelligently. A flexible architecture is required to provide dependability that can be tailored for such applications. We propose a novel mode-driven fault-tolerance approach that includes: (i) a generic framework to extend the specification of modes with fault-tolerance requirements, and (ii) a software architecture that uses this description to provide the appropriate fault tolerance for each mode at runtime. We also present a case study using a distributed multi-modal CORBA application to demonstrate the effectiveness of our approach.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {may},
pages = {1–7},
numpages = {7},
keywords = {COTS systems, replication, modes, distributed systems, software architecture, fault tolerance, CORBA}
}

@article{10.1145/1108906.1108908,
author = {Zhang, Xinwen and Parisi-Presicce, Francesco and Sandhu, Ravi and Park, Jaehong},
title = {Formal Model and Policy Specification of Usage Control},
year = {2005},
issue_date = {November 2005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {4},
issn = {1094-9224},
url = {https://doi.org/10.1145/1108906.1108908},
doi = {10.1145/1108906.1108908},
abstract = {The recent usage control model (UCON) is a foundation for next-generation access control models with distinguishing properties of decision continuity and attribute mutability. A usage control decision is determined by combining authorizations, obligations, and conditions, presented as UCONABC core models by Park and Sandhu. Based on these core aspects, we develop a formal model and logical specification of UCON with an extension of Lamport's temporal logic of actions (TLA). The building blocks of this model include: (1) a set of sequences of system states based on the attributes of subjects, objects, and the system, (2) authorization predicates based on subject and object attributes, (3) usage control actions to update attributes and accessing status of a usage process, (4) obligation actions, and (5) condition predicates based on system attributes. A usage control policy is defined as a set of temporal logic formulas that are satisfied as the system state changes. A fixed set of scheme rules is defined to specify general UCON policies with the properties of soundness and completeness. We show the flexibility and expressive capability of this formal model by specifying the core models of UCON and some applications.},
journal = {ACM Trans. Inf. Syst. Secur.},
month = {nov},
pages = {351–387},
numpages = {37},
keywords = {security policy, usage control, Access control, formal specification}
}

@inproceedings{10.1145/1289816.1289830,
author = {Inoue, Hiroaki and Ikeno, Akihisa and Abe, Tsuyoshi and Sakai, Junji and Edahiro, Masato},
title = {Dynamic Security Domain Scaling on Symmetric Multiprocessors for Future High-End Embedded Systems},
year = {2007},
isbn = {9781595938244},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1289816.1289830},
doi = {10.1145/1289816.1289830},
abstract = {We propose a method for dynamic security domain scaling on SMPs that offers both highly scalable performance and high security for future high-end embedded systems. Its most important feature is its highly efficient use of processor resources, accomplished by dynamically changing the number of processors within a security domain in response to application load requirements. Two new technologies make this scaling possible without any virtualization software: 1) self-transition management and 2) unified virtual address mapping. Evaluations show that this domain control provides highly scalable performance and incurs almost no performance overhead in security domains. The increase in binary code size is less than 40KB, and the time required for individual state transitions is of a single-millisecond order. This scaling is the first in the world to make possible dynamic changing of the number of processors within a security domain on an ARM SMP.},
booktitle = {Proceedings of the 5th IEEE/ACM International Conference on Hardware/Software Codesign and System Synthesis},
pages = {39–44},
numpages = {6},
keywords = {AMP, dynamic security domain scaling, SMP},
location = {Salzburg, Austria},
series = {CODES+ISSS '07}
}

@inproceedings{10.1145/1314354.1314363,
author = {Gasmi, Yacine and Sadeghi, Ahmad-Reza and Stewin, Patrick and Unger, Martin and Asokan, N.},
title = {Beyond Secure Channels},
year = {2007},
isbn = {9781595938886},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1314354.1314363},
doi = {10.1145/1314354.1314363},
abstract = {A Trusted Channel is a secure communication channel which is cryptographically bound to the state of the hardware and software configurations of the endpoints. In this paper, we describe secure and flexible mechanisms to establish and maintain Trusted Channels which do not have the deficiencies of previous proposals. We also present a concrete implementation proposal based on Transport Layer Security (TLS) protocol, and Trusted Computing technology. We use Subject Key Attestation Evidence extensions to X.509v3 certificates to convey configuration information during key agreement (TLS handshake). The resulting session key is kept within the Trusted Computing Base, and is updated in a predetermined manner to reflect any detected change in the local configuration. This allows an endpoint to detect changes in the configuration of the peer endpoint while the Trusted Channel is in place, and to decide according to a local policy whether to maintain or tear down the Trusted Channel},
booktitle = {Proceedings of the 2007 ACM Workshop on Scalable Trusted Computing},
pages = {30–40},
numpages = {11},
keywords = {virtualization, relay attack, state changes, TLS, microkernel, trusted computing, remote attestation, trusted channel, hypervisor},
location = {Alexandria, Virginia, USA},
series = {STC '07}
}

@inproceedings{10.1145/1315843.1315875,
author = {Zaffar, Fareed and Kedem, Gershon},
title = {Cooperative Forensics Sharing},
year = {2006},
isbn = {1424404630},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1315843.1315875},
doi = {10.1145/1315843.1315875},
abstract = {Having timely and credible security information is becoming critical to network and security management. Most current sources of threat information and detection techniques suffer from having a limited view of the global threat scenario. In this paper, we present Foresight, an internet scale threat analysis, indication, early warning and response architecture. We describe the design of an incentive based cooperation scheme to create a global trusted community which is more accountable and hence less vulnerable to attacks and abuse. Foresight utilizes this infrastructure to share a global threat view in order to detect unknown threats and isolate them. We describe a novel behavioral signature scheme to extract a generalized footprint for multi-modal threats. System performance analysis through trace-based simulations show significant benefits for sharing forensics across cooperating domains.},
booktitle = {Proceedings of the 1st International Conference on Bio Inspired Models of Network, Information and Computing Systems},
pages = {26–es},
location = {Cavalese, Italy},
series = {BIONETICS '06}
}

@inproceedings{10.1145/1408800.1408885,
author = {Zeitz, William A. and Fairman, Bruce and Zeitz, Baila},
title = {The Multi-State Information System: Frontend Processing and Data Security},
year = {1974},
isbn = {9781450378505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1408800.1408885},
doi = {10.1145/1408800.1408885},
abstract = {The Multi-State Information System (MSIS), a patient oriented, clinical and administrative system designed for use in Psychiatric hospitals and Community Mental Health Centers, is currently in use in twelve states and several countries. The need to protect the confidentiality of the highly sensitive data stored by the users of this system and at the same time provide ease of access to a wide range of non-technical personnel actively engaged in the legitimate use of this data was mandatory. This paper describes the MSIS FRONTEND processing which was designed to accommodate authorized personnel who are not technically sophisticated, and at the same time, deny access to unauthorized personnel by combining the FRONTEND with internal OS and HASP modifications also described.},
booktitle = {Proceedings of the 1974 Annual ACM Conference - Volume 2},
pages = {696–704},
numpages = {9},
keywords = {job control, data management, information processing, data security},
series = {ACM '74}
}

@inproceedings{10.1145/1460877.1460902,
author = {Barry, Bazara I. A. and Chan, H. Anthony},
title = {On the Performance of a Hybrid Intrusion Detection Architecture for Voice over IP Systems},
year = {2008},
isbn = {9781605582412},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1460877.1460902},
doi = {10.1145/1460877.1460902},
abstract = {Voice over IP (VoIP) environments pose challenging threats to Intrusion Detection Systems (IDSs). Services over VoIP systems are provided by multiple interacting protocols, each with its own vulnerabilities. This scheme could result in novel and more complex attacks, and requires cross-protocol aware IDSs. Furthermore, VoIP devices may suffer a full or partial service loss if the syntax or semantics of the aforementioned protocols are violated. Usually, a single detection approach is suited to identify a subset of the security violations to which a system is subject in VoIP environments. Therefore, a hybrid approach that combines the strengths and avoids the weaknesses of various approaches is needed. In this paper, we discuss the performance and the detection accuracy of a hybrid, host-based intrusion detection system suitable for VoIP environments. Our system has two combined detection modules, namely, a specification-based and a signature-based module. Both modules use State Machines and State Transition Analysis Techniques to model proper protocols' behaviors and potential attacks. Both modules address the issues related to syntax and semantics anomaly detection for the monitored protocols. In addition, our architecture provides a cross-protocol framework for various protocols to exchange useful detection information in real time. We implement our proposed architecture in a network simulator, alongside implementing a variety of attacks to test the credibility of the design. The implemented IDS shows an excellent detection accuracy, and low runtime impact on the performance of the VoIP system.},
booktitle = {Proceedings of the 4th International Conference on Security and Privacy in Communication Netowrks},
articleno = {19},
numpages = {10},
keywords = {intrusion detection, hybrid detection, VoIP, performance},
location = {Istanbul, Turkey},
series = {SecureComm '08}
}

@article{10.1145/1497561.1497567,
author = {Inoue, Hiroaki and Abe, Tsuyoshi and Ishizaka, Kazuhisa and Sakai, Junji and Edahiro, Masato},
title = {Dynamic Security Domain Scaling on Embedded Symmetric Multiprocessors},
year = {2009},
issue_date = {March 2009},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {2},
issn = {1084-4309},
url = {https://doi.org/10.1145/1497561.1497567},
doi = {10.1145/1497561.1497567},
abstract = {We propose a method for dynamic security-domain scaling on SMPs that offers both highly scalable performance and high security for future high-end embedded systems. Its most important feature is its highly efficient use of processor resources, accomplished by dynamically changing the number of processors within a security-domain (i.e., dynamically yielding processors to other security-domains) in response to application load requirements. Two new technologies make this scaling possible without any virtualization software: (1) self-transition management and (2) unified virtual address mapping. Evaluations show that this domain control provides highly scalable performance and incurs almost no performance overhead in security-domains. The increase in OSs in binary code size is less than 1.5%, and the time required for individual state transitions is on the order of a single millisecond. This scaling is the first in the world to make possible the dynamic changing of the number of processors within a security-domain on an ARM SMP.},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = {apr},
articleno = {24},
numpages = {23},
keywords = {SMP, dynamic security-domain scaling, AMP}
}

@inproceedings{10.1145/1542207.1542214,
author = {Mondal, Samrat and Sural, Shamik and Atluri, Vijayalakshmi},
title = {Towards Formal Security Analysis of GTRBAC Using Timed Automata},
year = {2009},
isbn = {9781605585376},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1542207.1542214},
doi = {10.1145/1542207.1542214},
abstract = {An access control system is often viewed as a state transition system. Given a set of access control policies, a general safety requirement in such a system is to determine whether a desirable property is satisfied in all the reachable states. Such an analysis calls for formal verification. While formal analysis on traditional RBAC has been done to some extent, the extensions of RBAC lack such an analysis. In this paper, we propose a formal technique to perform security analysis on the Generalized Temporal RBAC (GTRBAC) model which can be used to express a wide range of temporal constraints on different RBAC components like role, user and permission. In the proposed approach, at first the GTRBAC system is mapped to a state transition system built using timed automata. Characteristics of each role, user and permission are captured with the help of timed automata. A single global clock is used to express the various temporal constraints supported in a GTRBAC model. Next, a set of safety and liveness properties is specified using computation tree logic (CTL). Model checking based formal verification is then done to verify the properties against the model to determine if the system is secure with respect to a given set of access control policies. Both time and space analysis has been done for studying the performance of the approach under different configurations.},
booktitle = {Proceedings of the 14th ACM Symposium on Access Control Models and Technologies},
pages = {33–42},
numpages = {10},
keywords = {ctl, security analysis, model checking, GTRBAC, timed automata},
location = {Stresa, Italy},
series = {SACMAT '09}
}

@inproceedings{10.1145/1542452.1542474,
author = {Fidge, Colin J. and Corney, Diane},
title = {Integrating Hardware and Software Information Flow Analyses},
year = {2009},
isbn = {9781605583563},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1542452.1542474},
doi = {10.1145/1542452.1542474},
abstract = {Security-critical communications devices must be evaluated to the highest possible standards before they can be deployed. This process includes tracing potential information flow through the device's electronic circuitry, for each of the device's operating modes. Increasingly, however, security functionality is being entrusted to embedded software running on microprocessors within such devices, so new strategies are needed for integrating information flow analyses of embedded program code with hardware analyses. Here we show how standard compiler principles can augment high-integrity security evaluations to allow seamless tracing of information flow through both the hardware and software of embedded systems. This is done by unifying input/output statements in embedded program execution paths with the hardware pins they access, and by associating significant software states with corresponding operating modes of the surrounding electronic circuitry.},
booktitle = {Proceedings of the 2009 ACM SIGPLAN/SIGBED Conference on Languages, Compilers, and Tools for Embedded Systems},
pages = {157–166},
numpages = {10},
keywords = {communications devices, embedded software, information security evaluation},
location = {Dublin, Ireland},
series = {LCTES '09}
}

@article{10.1145/1543136.1542474,
author = {Fidge, Colin J. and Corney, Diane},
title = {Integrating Hardware and Software Information Flow Analyses},
year = {2009},
issue_date = {July 2009},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {7},
issn = {0362-1340},
url = {https://doi.org/10.1145/1543136.1542474},
doi = {10.1145/1543136.1542474},
abstract = {Security-critical communications devices must be evaluated to the highest possible standards before they can be deployed. This process includes tracing potential information flow through the device's electronic circuitry, for each of the device's operating modes. Increasingly, however, security functionality is being entrusted to embedded software running on microprocessors within such devices, so new strategies are needed for integrating information flow analyses of embedded program code with hardware analyses. Here we show how standard compiler principles can augment high-integrity security evaluations to allow seamless tracing of information flow through both the hardware and software of embedded systems. This is done by unifying input/output statements in embedded program execution paths with the hardware pins they access, and by associating significant software states with corresponding operating modes of the surrounding electronic circuitry.},
journal = {SIGPLAN Not.},
month = {jun},
pages = {157–166},
numpages = {10},
keywords = {information security evaluation, embedded software, communications devices}
}

@article{10.1145/1543753.1543754,
author = {Venkataramani, Guru and Doudalis, Ioannis and Solihin, Yan and Prvulovic, Milos},
title = {MemTracker: An Accelerator for Memory Debugging and Monitoring},
year = {2009},
issue_date = {June 2009},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {2},
issn = {1544-3566},
url = {https://doi.org/10.1145/1543753.1543754},
doi = {10.1145/1543753.1543754},
abstract = {Memory bugs are a broad class of bugs that is becoming increasingly common with increasing software complexity, and many of these bugs are also security vulnerabilities. Existing software and hardware approaches for finding and identifying memory bugs have a number of drawbacks including considerable performance overheads, target only a specific type of bug, implementation cost, and inefficient use of computational resources.This article describes MemTracker, a new hardware support mechanism that can be configured to perform different kinds of memory access monitoring tasks. MemTracker associates each word of data in memory with a few bits of state, and uses a programmable state transition table to react to different events that can affect this state. The number of state bits per word, the events to which MemTracker reacts, and the transition table are all fully programmable. MemTracker's rich set of states, events, and transitions can be used to implement different monitoring and debugging checkers with minimal performance overheads, even when frequent state updates are needed. To evaluate MemTracker, we map three different checkers onto it, as well as a checker that combines all three. For the most demanding (combined) checker with 8 bits state per memory word, we observe performance overheads of only around 3%, on average, and 14.5% worst-case across different benchmark suites. Such low overheads allow continuous (always-on) use of MemTracker-enabled checkers, even in production runs.},
journal = {ACM Trans. Archit. Code Optim.},
month = {jul},
articleno = {5},
numpages = {33},
keywords = {memory access monitoring, Accelerator, debugging}
}

@inproceedings{10.1145/1655062.1655064,
author = {Montanari, Mirko and Campbell, Roy H.},
title = {Multi-Aspect Security Configuration Assessment},
year = {2009},
isbn = {9781605587783},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1655062.1655064},
doi = {10.1145/1655062.1655064},
abstract = {Evaluating the security of a computer network system is a challenging task. Configurations of large systems are complex entities in continuous evolution. The installation of new software, a change in the firewall rules, or the discovery of a software vulnerability can be exploited by a malicious user to gain unauthorized control of the integrity, availability and confidentiality of the assets of an organization.This paper presents a framework for building security assessment tools able to perform online verification of the security of a system configuration. Heterogeneous data generated from multiple sources are integrated into a homogeneous RDF representation using domain-specific ontologies and used for assessing the security of a configuration toward known attack vectors. Different vocabularies can be defined to express configurations, policies and attacks for each aspect of the security of an organization (e.g., network security, physical security and application level security) in a modular way. By automatically extracting part of the configuration from the network system, the tool is able to detect in near real-time security threats created by configuration changes.},
booktitle = {Proceedings of the 2nd ACM Workshop on Assurable and Usable Security Configuration},
pages = {1–6},
numpages = {6},
keywords = {security assessment, security, network management, attack tree},
location = {Chicago, Illinois, USA},
series = {SafeConfig '09}
}

@inproceedings{10.1145/1809980.1810030,
author = {Oliveira, Ana Liz Souto and Delicato, Fl\'{a}via C. and Pirmez, Marcos},
title = {JanioS: Um Servi\c{c}o de SSH Para o Prometheus},
year = {2008},
isbn = {9788576691990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1809980.1810030},
doi = {10.1145/1809980.1810030},
abstract = {The recent proliferation of portable devices with increasing computational power as well as the advent of new wireless network technologies has enabled the realization of the ubiquitous computing vision. The paradigm of ubiquitous computing raises new challenges and requirements, such as the need of applications to adapt in the face of context changes while providing a suitable level of security to the user. This paper presents JanioS, an implementation of a new version to a library that provides SSH tunnel connections (Secure Shell) between applications. JanioS will be part of Prometheus, a system for provision of a service for adaptive security target to ubiquitous environment. JanioS will be able to dynamically adapt security parameters, such as cryptographic and data compression algorithms, according to the current execution context.},
booktitle = {Companion Proceedings of the XIV Brazilian Symposium on Multimedia and the Web},
pages = {173–175},
numpages = {3},
location = {Vila Velha, Esp\'{\i}rito Santo, Brazil},
series = {WebMedia '08}
}

@inproceedings{10.1145/1842752.1842785,
author = {Savola, Reijo M. and Kanstr\'{e}n, Teemu and Evesti, Antti},
title = {First International Workshop on Measurability of Security in Software Architectures -- MeSSa 2010},
year = {2010},
isbn = {9781450301794},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842752.1842785},
doi = {10.1145/1842752.1842785},
abstract = {The growing complexity of service-centric systems has increased the need for pertinent and reliable software security and trusted system solutions. Systematic approaches to measuring security in software architectures are needed in order to obtain sufficient and credible proactive evidence of the security level or performance of a system, service or product. The systematic definition of security metrics and security assurance metrics is a young field that still lacks widely accepted definitions of metrics and applicable measuring techniques for design-time and run-time security monitoring. MeSSa 2010 workshop contributes on the following issues:• Security, trust and privacy metrics• Security assurance metrics• Security, trust and privacy measurement systems and associated data gathering• Metrics for adaptive security systems• Taxonomical and ontological research on security metrics• Experimental results from security measurements• Security measurability-increasing mechanisms for software architectures• The relationship and differences between security metrics and security assurance metrics• Trade-off analysis and decision-making at design-time and at run-time.},
booktitle = {Proceedings of the Fourth European Conference on Software Architecture: Companion Volume},
pages = {151–154},
numpages = {4},
keywords = {security, assessment, privacy, trust, evaluation, assurance, metrics, measurement},
location = {Copenhagen, Denmark},
series = {ECSA '10}
}

@inproceedings{10.1145/1842752.1842792,
author = {Blasi, Lorenzo and Savola, Reijo and Abie, Habtamu and Rotondi, Domenico},
title = {Applicability of Security Metrics for Adaptive Security Management in a Universal Banking Hub System},
year = {2010},
isbn = {9781450301794},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842752.1842792},
doi = {10.1145/1842752.1842792},
abstract = {Banking applications require a high standard of security, resilience and adaptation. The results presented here were obtained from a case study of the deployment of the security metrics-driven adaptive security solutions of a distributed middleware in the context of monetary transfers. The focus of this study is on the analysis of the applicability of security metrics for adaptive authentication, authorization, and end-to-end confidentiality, and the applicability of trust metrics.},
booktitle = {Proceedings of the Fourth European Conference on Software Architecture: Companion Volume},
pages = {197–204},
numpages = {8},
keywords = {security metrics, security measures, adaptive security},
location = {Copenhagen, Denmark},
series = {ECSA '10}
}

@inproceedings{10.1145/1882486.1882496,
author = {Bando, Masanori and Artan, N. Sertac and Chao, H. Jonathan},
title = {LaFA: Lookahead Finite Automata for Scalable Regular Expression Detection},
year = {2009},
isbn = {9781605586304},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1882486.1882496},
doi = {10.1145/1882486.1882496},
abstract = {Although Regular Expressions (RegExes) have been widely used in network security applications, their inherent complexity often limits the total number of RegExes that can be detected using a single chip for a reasonable throughput. This limit on the number of RegExes impairs the scalability of today's RegEx detection systems. The scalability of existing schemes is generally limited by the traditional per character state processing and state transition detection paradigm. The main focus of existing schemes is in optimizing the number of states and the required transitions, but not the suboptimal character-based detection method. Furthermore, the potential benefits of reduced number of operations and states using out-of-sequence detection methods have not been explored. In this paper, we propose Looka-head Finite Automata (LaFA) to perform scalable RegEx detection using very small amount of memory. LaFA's memory requirement is very small due to the following three areas of effort described in this paper: (1) Different parts of a RegEx, namely RegEx components, are detected using different detectors, each of which is specialized and optimized for the detection of a certain RegEx component. (2) We systematically reorder the RegEx component detection sequence, which provides us with new possibilities for memory optimization. (3) Many redundant states in classical finite automata are identified and eliminated in LaFA. Our simulations show that LaFA requires an order of magnitude less memory compared to today's state-of-the-art RegEx detection systems. A single commodity Field Programmable Gate Array (FPGA) chip can accommodate up to twenty-five thousand (25k) RegExes. Based on the throughput of our LaFA prototype on FPGA, we estimated that a 34-Gbps throughput can be achieved.},
booktitle = {Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems},
pages = {40–49},
numpages = {10},
keywords = {finite automation, FPGA, LaFA, network intrusion detection system, regular expressions, deep packet inspection},
location = {Princeton, New Jersey},
series = {ANCS '09}
}

@article{10.1145/1968587.1968603,
author = {Chandra, Shalini and Khan, Raees Ahmad},
title = {Availability State Transition Model},
year = {2011},
issue_date = {May 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {36},
number = {3},
issn = {0163-5948},
url = {https://doi.org/10.1145/1968587.1968603},
doi = {10.1145/1968587.1968603},
abstract = {Several security mechanisms such as digital signature, timestamp audits and trails, encryption, throttling, filtering, protect secrets etc. are available. These security mechanisms are not completely able to stop malicious attacks. For malicious hackers and attackers it is comparatively easy to exploit security loopholes at the user's end side. Behind such type of problem the main reason is bad software design and its implementation without proper risk analysis and mitigation. So, an idea to model availability states an Availability State Transition Model (ASTM) has been proposed in this article. In ASTM methodology, only design level details is required which can be easily retrieved from the software's design.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {may},
pages = {1–3},
numpages = {3},
keywords = {security quantification, security metric, software security}
}

@inproceedings{10.1145/2070425.2070451,
author = {Cheng, Liang and Zhang, Yang},
title = {Model Checking Security Policy Model Using Both UML Static and Dynamic Diagrams},
year = {2011},
isbn = {9781450310208},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2070425.2070451},
doi = {10.1145/2070425.2070451},
abstract = {An operating system relies heavily on its security model to defend against malicious attacks. It has been one of the hottest research domains for decades to validate security models' correctness by formal methods during the development of security operating systems. However, current studies on the formal verification of security models are sometimes too sophisticated for the developers of operating systems, who are usually not experts in mathematical reasoning and proving. So representing a security model in UML becomes a compromise choice for the developers' verification work during system developing. In this paper, we propose a new method to verify the security policy model against the security goals using model checker SPIN and UML modeling language. Given a security policy model and the security property to be validated, our approach leverages UML class diagrams and statechart diagrams to specify its state model and its state transitions respectively. Then we translate these UML diagrams into the input language of SPIN automatically, as well as the security property. The conformance between the security goal and security model can finally be analyzed by SPIN. We proved the effectiveness of our approach by checking the violation of confidentiality of the DBLP model.},
booktitle = {Proceedings of the 4th International Conference on Security of Information and Networks},
pages = {159–166},
numpages = {8},
keywords = {formal verification, uml, security model, model checking},
location = {Sydney, Australia},
series = {SIN '11}
}

@inproceedings{10.1145/2151024.2151052,
author = {Payer, Mathias and Gross, Thomas R.},
title = {Protecting Applications against TOCTTOU Races by User-Space Caching of File Metadata},
year = {2012},
isbn = {9781450311762},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2151024.2151052},
doi = {10.1145/2151024.2151052},
abstract = {Time Of Check To Time Of Use (TOCTTOU) race conditions for file accesses in user-space applications are a common problem in Unix-like systems. The mapping between filename and inode and device is volatile and can provide the necessary preconditions for an exploit. Applications use filenames as the primary attribute to identify files but the mapping between filenames and inode and device can be changed by an attacker.DynaRace is an approach that protects unmodified applications from file-based TOCTTOU race conditions. DynaRace uses a transparent mapping cache that keeps additional state and metadata for each accessed file in the application. The combination of file state and the current system call type are used to decide if (i) the metadata is updated or (ii) the correctness of the metadata is enforced between consecutive system calls.DynaRace uses user-mode path resolution internally to resolve individual file atoms. Each file atom is verified or updated according to the associated state in the mapping cache. More specifically, DynaRace protects against race conditions for all file-based system calls, by replacing the unsafe system calls with a set of safe system calls that utilize the mapping cache. The system call is executed only if the state transition is allowed and the information in the mapping cache matches.DynaRace deterministically solves the problem of file-based race conditions for unmodified applications and removes an attacker's ability to exploit the TOCTTOU race condition. DynaRace detects injected alternate inode and device pairs and terminates the application.},
booktitle = {Proceedings of the 8th ACM SIGPLAN/SIGOPS Conference on Virtual Execution Environments},
pages = {215–226},
numpages = {12},
keywords = {dynamic protection, race protection, virtualization, TOCTTOU races, security, file-based TOCTTOU race protection},
location = {London, England, UK},
series = {VEE '12}
}

@article{10.1145/2365864.2151052,
author = {Payer, Mathias and Gross, Thomas R.},
title = {Protecting Applications against TOCTTOU Races by User-Space Caching of File Metadata},
year = {2012},
issue_date = {July 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {7},
issn = {0362-1340},
url = {https://doi.org/10.1145/2365864.2151052},
doi = {10.1145/2365864.2151052},
abstract = {Time Of Check To Time Of Use (TOCTTOU) race conditions for file accesses in user-space applications are a common problem in Unix-like systems. The mapping between filename and inode and device is volatile and can provide the necessary preconditions for an exploit. Applications use filenames as the primary attribute to identify files but the mapping between filenames and inode and device can be changed by an attacker.DynaRace is an approach that protects unmodified applications from file-based TOCTTOU race conditions. DynaRace uses a transparent mapping cache that keeps additional state and metadata for each accessed file in the application. The combination of file state and the current system call type are used to decide if (i) the metadata is updated or (ii) the correctness of the metadata is enforced between consecutive system calls.DynaRace uses user-mode path resolution internally to resolve individual file atoms. Each file atom is verified or updated according to the associated state in the mapping cache. More specifically, DynaRace protects against race conditions for all file-based system calls, by replacing the unsafe system calls with a set of safe system calls that utilize the mapping cache. The system call is executed only if the state transition is allowed and the information in the mapping cache matches.DynaRace deterministically solves the problem of file-based race conditions for unmodified applications and removes an attacker's ability to exploit the TOCTTOU race condition. DynaRace detects injected alternate inode and device pairs and terminates the application.},
journal = {SIGPLAN Not.},
month = {mar},
pages = {215–226},
numpages = {12},
keywords = {file-based TOCTTOU race protection, security, dynamic protection, race protection, virtualization, TOCTTOU races}
}

@proceedings{10.1145/2248326,
title = {Airborne '12: Proceedings of the First ACM MobiHoc Workshop on Airborne Networks and Communications},
year = {2012},
isbn = {9781450312905},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {On behalf of the organizers, we extend a warm welcome to the first ACM MobiHoc workshop on "Airborne Networks and Communications" to all participants. An airborne network is a mobile network consisting of manned and unmanned air vehicles as well as ground vehicles. The ability of ground and air vehicles to communicate voice, video, and data offers enhanced safety and efficiency for the next generation (NextGen) air transportation systems. Airborne networks can benefit many civilian applications such as air-traffic control, border patrol, and search and rescue missions.This workshop is a result of the ideas that emerged from the meetings held over the past few years on topics that focused on cyber-physical systems (CPS) for air transportation as well as NextGen aviation systems. We believe that the time is right for airborne networking and communications to be part of main stream conferences. We believe that this workshop is an opportunity for researchers engaged in airborne networking and communications to discuss state-of-the-art, share their research results with their peers, and develop directions for future research in this emerging field.Airborne networking is a cyber-physical system. While computation, communication and networking elements form the cyber components of the system, flight-paths, maneuver geometries, and multi-mode resources including ground-based nodes and control stations form the physical components of the CPS. The synergy between the cyber and physical components, if explored and exploited, will significantly enhance the safety and security capabilities of Next Generation air transportation systems. However, fundamental design principles which are needed to explore this synergy do not exist and experimental datasets which are needed to develop such design principles are beyond the reach of academic community.During this workshop, we will hear from experienced speakers coming from the industry, universities, and federal laboratories on topics covering theoretical foundations and models for mobility, connectivity, and coverage, cyber-physical system perspective of airborne networks, airborne/satellite communication and networking platforms and strategies, protocols for secure information sharing, swarming, collaboration, and self-organization, network trials, test-beds, experiments, and measurements and applications of airborne networking to real world domains such as border patrol, air-traffic control, search and rescue missions, and unmanned cargo. We look forward to your active participation in this workshop.},
location = {Hilton Head, South Carolina, USA}
}

@inproceedings{10.1145/2342356.2342427,
author = {Reitblatt, Mark and Foster, Nate and Rexford, Jennifer and Schlesinger, Cole and Walker, David},
title = {Abstractions for Network Update},
year = {2012},
isbn = {9781450314190},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2342356.2342427},
doi = {10.1145/2342356.2342427},
abstract = {Configuration changes are a common source of instability in networks, leading to outages, performance disruptions, and security vulnerabilities. Even when the initial and final configurations are correct, the update process itself often steps through intermediate configurations that exhibit incorrect behaviors. This paper introduces the notion of consistent network updates---updates that are guaranteed to preserve well-defined behaviors when transitioning mbetween configurations. We identify two distinct consistency levels, per-packet and per-flow, and we present general mechanisms for implementing them in Software-Defined Networks using switch APIs like OpenFlow. We develop a formal model of OpenFlow networks, and prove that consistent updates preserve a large class of properties. We describe our prototype implementation, including several optimizations that reduce the overhead required to perform consistent updates. We present a verification tool that leverages consistent updates to significantly reduce the complexity of checking the correctness of network control software. Finally, we describe the results of some simple experiments demonstrating the effectiveness of these optimizations on example applications.},
booktitle = {Proceedings of the ACM SIGCOMM 2012 Conference on Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {323–334},
numpages = {12},
keywords = {network programming languages, openflow, consistency, software-defined networking, frenetic, planned change},
location = {Helsinki, Finland},
series = {SIGCOMM '12}
}

@inproceedings{10.1145/2345396.2345580,
author = {Chakravarthy, S. Deepan and Kingsly, P. Infant and Sadhasivam, Mahendran and Jayakumar, C.},
title = {Multi-Modal Biometric Approach to Enable High Security in Mobile Adhoc Network},
year = {2012},
isbn = {9781450311960},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2345396.2345580},
doi = {10.1145/2345396.2345580},
abstract = {The application of multi-modal biometric methods in securing mobile ad-hoc network has been addressed in this paper. A MANET is an infra structure less network for mobile devices connected by wireless link. The mobile network is often vulnerable to security attacks even though there are many traditional approaches, due to its features of open medium and dynamic changing topology. Multi-modal biometrics is deployed to work with intrusion detection systems (IDSs) to overcome the shortcomings of uni-modal biometric systems. The cluster head is elected in which Dempster-Shafer theory is evaluated in order to increase the observation accuracy to maintain high security and trusted MANET. Since each device in the network has measurement and estimated limitations, more than one device needs to be chosen, and observations can be fused to increase observation accuracy using Dempster--Shafer theory for data fusion.},
booktitle = {Proceedings of the International Conference on Advances in Computing, Communications and Informatics},
pages = {1148–1154},
numpages = {7},
keywords = {decision tree, IDS- intrusion detection system, Dempster Shafer theory, naive Bayes, MANET- mobile adhoc network, artificial neural networks},
location = {Chennai, India},
series = {ICACCI '12}
}

@article{10.1145/2377677.2377748,
author = {Reitblatt, Mark and Foster, Nate and Rexford, Jennifer and Schlesinger, Cole and Walker, David},
title = {Abstractions for Network Update},
year = {2012},
issue_date = {October 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {4},
issn = {0146-4833},
url = {https://doi.org/10.1145/2377677.2377748},
doi = {10.1145/2377677.2377748},
abstract = {Configuration changes are a common source of instability in networks, leading to outages, performance disruptions, and security vulnerabilities. Even when the initial and final configurations are correct, the update process itself often steps through intermediate configurations that exhibit incorrect behaviors. This paper introduces the notion of consistent network updates---updates that are guaranteed to preserve well-defined behaviors when transitioning mbetween configurations. We identify two distinct consistency levels, per-packet and per-flow, and we present general mechanisms for implementing them in Software-Defined Networks using switch APIs like OpenFlow. We develop a formal model of OpenFlow networks, and prove that consistent updates preserve a large class of properties. We describe our prototype implementation, including several optimizations that reduce the overhead required to perform consistent updates. We present a verification tool that leverages consistent updates to significantly reduce the complexity of checking the correctness of network control software. Finally, we describe the results of some simple experiments demonstrating the effectiveness of these optimizations on example applications.},
journal = {SIGCOMM Comput. Commun. Rev.},
month = {aug},
pages = {323–334},
numpages = {12},
keywords = {frenetic, openflow, network programming languages, software-defined networking, planned change, consistency}
}

@inproceedings{10.1145/2393596.2393618,
author = {Pasquale, Liliana and Menghi, Claudio and Salehie, Mazeiar and Cavallaro, Luca and Omoronyia, Inah and Nuseibeh, Bashar},
title = {SecuriTAS: A Tool for Engineering Adaptive Security},
year = {2012},
isbn = {9781450316149},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2393596.2393618},
doi = {10.1145/2393596.2393618},
abstract = {This paper presents SecuriTAS, a tool to engineer adaptive security. It allows software designers to model security concerns together with the requirements of a system. This model is then used at runtime to analyze changes in security concerns and select the best set of security controls necessary to protect the system.},
booktitle = {Proceedings of the ACM SIGSOFT 20th International Symposium on the Foundations of Software Engineering},
articleno = {19},
numpages = {4},
keywords = {goals, adaptive software, dynamic access control, security},
location = {Cary, North Carolina},
series = {FSE '12}
}

@inproceedings{10.1145/2396276.2396281,
author = {Lim, Jong Hyun and Zhan, Andong and Goldschmidt, Evan and Ko, JeongGil and Chang, Marcus and Terzis, Andreas},
title = {HealthOS: A Platform for Pervasive Health Applications},
year = {2012},
isbn = {9781450317641},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2396276.2396281},
doi = {10.1145/2396276.2396281},
abstract = {Pervasive health applications that compose longitudinal information streams to infer people's health and encourage lifestyle changes have the potential to substantially benefit public health. Off-the-shelf medical and wellness sensors meet the sensing requirements of such applications but their closed and vertically-integrated designs impede composability and complicate unified management. Furthermore, the lack of security and privacy controls discourages individuals from sharing their data. This paper presents HealthOS, a development and execution framework for pervasive health applications. HealthOS addresses the sensor and system incompatibility challenge through a set of adapters. Moreover, pipeline modules translate custom formats and protocols to the requirements of target applications/systems. These modules execute in HealthOS servers, programmable devices that expose Representational State Transfer (REST) interfaces for data retrieval and sensor management. HealthOS servers can store data locally or push them to untrusted, third party services. Finally, HealthOS leverages attribute-based encryption to offer sophisticated role-based and content-based access controls for users' data.},
booktitle = {Proceedings of the Second ACM Workshop on Mobile Systems, Applications, and Services for HealthCare},
articleno = {4},
numpages = {6},
keywords = {platform, RESTful API, pervasive health applications},
location = {Toronto, Ontario, Canada},
series = {mHealthSys '12}
}

@inproceedings{10.1145/2451116.2451147,
author = {Giuffrida, Cristiano and Kuijsten, Anton and Tanenbaum, Andrew S.},
title = {Safe and Automatic Live Update for Operating Systems},
year = {2013},
isbn = {9781450318709},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451116.2451147},
doi = {10.1145/2451116.2451147},
abstract = {Increasingly many systems have to run all the time with no downtime allowed. Consider, for example, systems controlling electric power plants and e-banking servers. Nevertheless, security patches and a constant stream of new operating system versions need to be deployed without stopping running programs. These factors naturally lead to a pressing demand for live update---upgrading all or parts of the operating system without rebooting. Unfortunately, existing solutions require significant manual intervention and thus work reliably only for small operating system patches.In this paper, we describe an automated system for live update that can safely and automatically handle major upgrades without rebooting. We have implemented our ideas in Proteos, a new research OS designed with live update in mind. Proteos relies on system support and nonintrusive instrumentation to handle even very complex updates with minimal manual effort. The key novelty is the idea of state quiescence, which allows updates to happen only in safe and predictable system states. A second novelty is the ability to automatically perform transactional live updates at the process level, ensuring a safe and stable update process. Unlike prior solutions, Proteos supports automated state transfer, state checking, and hot rollback. We have evaluated Proteos on 50 real updates and on novel live update scenarios. The results show that our techniques can effectively support both simple and complex updates, while outperforming prior solutions in terms of flexibility, security, reliability, and stability of the update process.},
booktitle = {Proceedings of the Eighteenth International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {279–292},
numpages = {14},
keywords = {automatic updates, state checking, operating systems, live update, update safety, state transfer},
location = {Houston, Texas, USA},
series = {ASPLOS '13}
}

@article{10.1145/2490301.2451147,
author = {Giuffrida, Cristiano and Kuijsten, Anton and Tanenbaum, Andrew S.},
title = {Safe and Automatic Live Update for Operating Systems},
year = {2013},
issue_date = {March 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {1},
issn = {0163-5964},
url = {https://doi.org/10.1145/2490301.2451147},
doi = {10.1145/2490301.2451147},
abstract = {Increasingly many systems have to run all the time with no downtime allowed. Consider, for example, systems controlling electric power plants and e-banking servers. Nevertheless, security patches and a constant stream of new operating system versions need to be deployed without stopping running programs. These factors naturally lead to a pressing demand for live update---upgrading all or parts of the operating system without rebooting. Unfortunately, existing solutions require significant manual intervention and thus work reliably only for small operating system patches.In this paper, we describe an automated system for live update that can safely and automatically handle major upgrades without rebooting. We have implemented our ideas in Proteos, a new research OS designed with live update in mind. Proteos relies on system support and nonintrusive instrumentation to handle even very complex updates with minimal manual effort. The key novelty is the idea of state quiescence, which allows updates to happen only in safe and predictable system states. A second novelty is the ability to automatically perform transactional live updates at the process level, ensuring a safe and stable update process. Unlike prior solutions, Proteos supports automated state transfer, state checking, and hot rollback. We have evaluated Proteos on 50 real updates and on novel live update scenarios. The results show that our techniques can effectively support both simple and complex updates, while outperforming prior solutions in terms of flexibility, security, reliability, and stability of the update process.},
journal = {SIGARCH Comput. Archit. News},
month = {mar},
pages = {279–292},
numpages = {14},
keywords = {update safety, state checking, state transfer, live update, operating systems, automatic updates}
}

@article{10.1145/2499368.2451147,
author = {Giuffrida, Cristiano and Kuijsten, Anton and Tanenbaum, Andrew S.},
title = {Safe and Automatic Live Update for Operating Systems},
year = {2013},
issue_date = {April 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2499368.2451147},
doi = {10.1145/2499368.2451147},
abstract = {Increasingly many systems have to run all the time with no downtime allowed. Consider, for example, systems controlling electric power plants and e-banking servers. Nevertheless, security patches and a constant stream of new operating system versions need to be deployed without stopping running programs. These factors naturally lead to a pressing demand for live update---upgrading all or parts of the operating system without rebooting. Unfortunately, existing solutions require significant manual intervention and thus work reliably only for small operating system patches.In this paper, we describe an automated system for live update that can safely and automatically handle major upgrades without rebooting. We have implemented our ideas in Proteos, a new research OS designed with live update in mind. Proteos relies on system support and nonintrusive instrumentation to handle even very complex updates with minimal manual effort. The key novelty is the idea of state quiescence, which allows updates to happen only in safe and predictable system states. A second novelty is the ability to automatically perform transactional live updates at the process level, ensuring a safe and stable update process. Unlike prior solutions, Proteos supports automated state transfer, state checking, and hot rollback. We have evaluated Proteos on 50 real updates and on novel live update scenarios. The results show that our techniques can effectively support both simple and complex updates, while outperforming prior solutions in terms of flexibility, security, reliability, and stability of the update process.},
journal = {SIGPLAN Not.},
month = {mar},
pages = {279–292},
numpages = {14},
keywords = {update safety, operating systems, state transfer, automatic updates, live update, state checking}
}

@inproceedings{10.1145/2459976.2459987,
author = {Zalewski, Janusz and Drager, Steven and McKeever, William and Kornecki, Andrew J.},
title = {Threat Modeling for Security Assessment in Cyberphysical Systems},
year = {2013},
isbn = {9781450316873},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2459976.2459987},
doi = {10.1145/2459976.2459987},
abstract = {In this paper, threat modeling issues in cyberphysical systems are discussed. First a generic model of a cyberphysical system is outlined, with an attack surface suitable for security analysis. Then, a case study of network communication in a road vehicle is presented, with its behavior modeled by a discrete time Markov chain, under the assumption that security violations can cause gradual degradation of functionality. Finally, two ways of numerical assessment of vulnerabilities are analyzed, to help better estimate probabilities of state changes in a Markov model.},
booktitle = {Proceedings of the Eighth Annual Cyber Security and Information Intelligence Research Workshop},
articleno = {10},
numpages = {4},
keywords = {security, security assessment, software assurance, simulation},
location = {Oak Ridge, Tennessee, USA},
series = {CSIIRW '13}
}

@inproceedings{10.1145/2459976.2460041,
author = {Hively, Lee M. and McDonald, J. Todd},
title = {Theorem-Based, Data-Driven, Cyber Event Detection},
year = {2013},
isbn = {9781450316873},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2459976.2460041},
doi = {10.1145/2459976.2460041},
abstract = {Nonlinear dynamics and graph theory may provide a theorem-based path to improve design security and aid detection of anomalous events in cyber applications. Using side-channel information such as power taken from underlying computer components and analyzing noisy data such as timing, we ask the question of whether such data can reveal anomalous activity or verify the changing dynamics of an underlying computer system. Takens' theorem in nonlinear dynamics allows reconstruction of topologically invariant, time-delay-embedding states from the computer dynamics in a sufficiently high-dimensional space. The resultant dynamical states are vertices, and the state-to-state transitions are edges in a graph. Graph theorems guarantee topologically invariant measures to quantify the dynamical changes, based on the applications that are executing. This paper highlights recent applications of the phase-space analysis technique in the non-cyber realm (forewarning of biomedical events and equipment failures), and proposes new applications that would bolster cyber event detection.},
booktitle = {Proceedings of the Eighth Annual Cyber Security and Information Intelligence Research Workshop},
articleno = {58},
numpages = {4},
keywords = {phasespace analysis, graph theory, power measurement, nonlinear dynamics, cyber anomaly detection},
location = {Oak Ridge, Tennessee, USA},
series = {CSIIRW '13}
}

@inproceedings{10.1145/2485922.2485933,
author = {Chang, Xiaotao and Franke, Hubertus and Ge, Yi and Liu, Tao and Wang, Kun and Xenidis, Jimi and Chen, Fei and Zhang, Yu},
title = {Improving Virtualization in the Presence of Software Managed Translation Lookaside Buffers},
year = {2013},
isbn = {9781450320795},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2485922.2485933},
doi = {10.1145/2485922.2485933},
abstract = {Virtualization has become an important technology that is used across many platforms, particularly servers, to increase utilization, multi-tenancy and security. Virtualization introduces additional overhead that often relates to memory management, interrupt handling and hypervisor mode switching. Among those, memory management and translation lookaside buffer (TLB) management have been shown to have a significant impact on the performance of systems. Two principal mechanisms for TLB management exist in today's systems, namely software and hardware managed TLBs. In this paper, we analyze and quantify the overhead of a pure software virtualization that is implemented over a software managed TLB. We then describe our design of hardware extensions to support virtualization in systems with software managed TLBs to remove the most dominant overheads. These extensions were implemented in the Power embedded A2 core, which is used in the PowerEN and in the Blue Gene/Q processors. They were used to implement a KVM port. We evaluate each of these hardware extensions to determine their overall contributions to performance and efficiency. Collectively these extensions demonstrate an average improvement of 232% over a pure software implementation.},
booktitle = {Proceedings of the 40th Annual International Symposium on Computer Architecture},
pages = {120–129},
numpages = {10},
location = {Tel-Aviv, Israel},
series = {ISCA '13}
}

@article{10.1145/2508148.2485933,
author = {Chang, Xiaotao and Franke, Hubertus and Ge, Yi and Liu, Tao and Wang, Kun and Xenidis, Jimi and Chen, Fei and Zhang, Yu},
title = {Improving Virtualization in the Presence of Software Managed Translation Lookaside Buffers},
year = {2013},
issue_date = {June 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {3},
issn = {0163-5964},
url = {https://doi.org/10.1145/2508148.2485933},
doi = {10.1145/2508148.2485933},
abstract = {Virtualization has become an important technology that is used across many platforms, particularly servers, to increase utilization, multi-tenancy and security. Virtualization introduces additional overhead that often relates to memory management, interrupt handling and hypervisor mode switching. Among those, memory management and translation lookaside buffer (TLB) management have been shown to have a significant impact on the performance of systems. Two principal mechanisms for TLB management exist in today's systems, namely software and hardware managed TLBs. In this paper, we analyze and quantify the overhead of a pure software virtualization that is implemented over a software managed TLB. We then describe our design of hardware extensions to support virtualization in systems with software managed TLBs to remove the most dominant overheads. These extensions were implemented in the Power embedded A2 core, which is used in the PowerEN and in the Blue Gene/Q processors. They were used to implement a KVM port. We evaluate each of these hardware extensions to determine their overall contributions to performance and efficiency. Collectively these extensions demonstrate an average improvement of 232% over a pure software implementation.},
journal = {SIGARCH Comput. Archit. News},
month = {jun},
pages = {120–129},
numpages = {10}
}

@proceedings{10.1145/2491260,
title = {ANC '13: Proceedings of the Second ACM MobiHoc Workshop on Airborne Networks and Communications},
year = {2013},
isbn = {9781450322089},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {On behalf of the organizers, we extend a warm welcome to the second ACM MobiHoc workshop on "Airborne Networks and Communications" to all participants. An airborne network is a mobile network consisting of manned and unmanned air vehicles as well as ground vehicles. The ability of ground and air vehicles to communicate voice, video, and data offers enhanced safety and efficiency for the next generation (NextGen) air transportation systems. Airborne networks can benefit many civilian applications such as air-traffic control, border patrol, and search and rescue missions.This workshop is a result of the ideas that emerged from the meetings held over the past few years on topics that focused on cyber-physical systems (CPS) for air transportation as well as NextGen aviation systems. We believe that this workshop is an opportunity for researchers engaged in airborne networking and communications to discuss state-of-the-art, share their research results with their peers, and develop directions for future research in this emerging field.Airborne networking is a cyber-physical system. While computation, communication and networking elements form the cyber components of the system, flight-paths, maneuver geometries, and multi-mode resources including ground-based nodes and control stations form the physical components of the CPS. The synergy between the cyber and physical components, if explored and exploited, will significantly enhance the safety and security capabilities of Next Generation air transportation systems. However, fundamental design principles which are needed to explore this synergy do not exist and experimental datasets which are needed to develop such design principles are beyond the reach of academic community.During this workshop, we will hear from experienced speakers coming from the industry, universities, and federal laboratories on topics covering theoretical foundations and models for mobility, connectivity, and coverage, cyber-physical system perspective of airborne networks, airborne/satellite communication and networking platforms and strategies, protocols for secure information sharing, swarming, collaboration, and self-organization, network trials, test-beds, experiments, and measurements and applications of airborne networking to real world domains such as border patrol, air-traffic control, search and rescue missions, and unmanned cargo. We look forward to your active participation in this workshop.},
location = {Bangalore, India}
}

@inproceedings{10.1145/2494091.2499770,
author = {Poslad, Stefan and Hamdi, Mohamed and Abie, Habtamu},
title = {Adaptive Security and Privacy Management for the Internet of Things (ASPI 2013)},
year = {2013},
isbn = {9781450322157},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2494091.2499770},
doi = {10.1145/2494091.2499770},
abstract = {The Internet of Things (IoT) was initially proposed to connect specific things via the Internet using devices, such as RFID readers, to realise intelligent identification and management. This vision has since expanded to include a more diverse range of devices, services and networks to become an Internet of anything, anywhere, connected, anyhow. Security and privacy management for the IoT remains a core challenge.Many IoT devices maybe may have zero or minimal security by design because they are low resource, low power devices, designed to work as closed vertical services. Security threats and risks may be higher because devices are unattended, use local wireless communication that have no or weak encryption making them more susceptible to eavesdropping and because users find security too unusable to setup and operate and hence leave devices relatively unsecure. It may also be less problematic to reproduce and fake data sources, access nodes and data sinks that interact with IoT devices in order to attack devices or the services they access. Devices can be moved between or removed from private, communal, public and hostile physical spaces. There is a higher risk of a loss of privacy for human users and organisations because of an increased ability to eavesdrop, because of wireless networks with soft boundaries, and because embedded environment devices can sense smaller amounts of physical trails with a greater degree of sensitivity and accuracy. A specific focus is on the need for IoT security to adapt. The adaptation has multiple dimensions. We can adapt existing conventional security models to more effectively secure an IoT. We can adapt security pre-planned and unplanned context changes such as different moving around in different physical spaces. IoT systems can be designed to self-adapt. IoT systems need to adapt to the active (re) configuration and maintenance of IoT devices and systems of devices by users and by artificial agents.The proposed workshop intends to bring together researchers and practitioners from relevant fields to present and disseminate the latest on-going research focussing on adapting security, privacy &amp; management for the Internet of Things. It aims to facilitate knowledge transfer and synergy, bridge gaps between different research communities and groups, to lay down foundation for common purposes, and to help identify opportunities and challenges for interested researchers and technology and system developers.},
booktitle = {Proceedings of the 2013 ACM Conference on Pervasive and Ubiquitous Computing Adjunct Publication},
pages = {373–378},
numpages = {6},
keywords = {user centred management, internet of things, privacy, security, ubiquitous computing},
location = {Zurich, Switzerland},
series = {UbiComp '13 Adjunct}
}

@inproceedings{10.1145/2516821.2516830,
author = {Jiang, Ke and Lifa, Adrian and Eles, Petru and Peng, Zebo and Jiang, Wei},
title = {Energy-Aware Design of Secure Multi-Mode Real-Time Embedded Systems with FPGA Co-Processors},
year = {2013},
isbn = {9781450320580},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2516821.2516830},
doi = {10.1145/2516821.2516830},
abstract = {We approach the emerging area of energy efficient, secure real-time embedded systems design. Many modern embedded systems have to fulfill strict security constraints and are often required to meet stringent deadlines in different operation modes, where the number and nature of active tasks vary (dynamic task sets). In this context, the use of dynamic voltage/frequency scaling (DVFS) techniques and onboard field-programmable gate array (FPGA) co-processors offer new dimensions for energy savings and performance enhancement. We propose a novel design framework that provides the best security protection consuming the minimal energy for all operation modes of a system. Extensive experiments demonstrate the efficiency of our techniques.},
booktitle = {Proceedings of the 21st International Conference on Real-Time Networks and Systems},
pages = {109–118},
numpages = {10},
location = {Sophia Antipolis, France},
series = {RTNS '13}
}

@inproceedings{10.1145/2517881.2517891,
author = {Jin, Xin and Krishnan, Ram and Sandhu, Ravi},
title = {Reachability Analysis for Role-Based Administration of Attributes},
year = {2013},
isbn = {9781450324939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2517881.2517891},
doi = {10.1145/2517881.2517891},
abstract = {Attribute-based access control (ABAC) is well-known and increasingly prevalent. Nonetheless, administration of attributes is not well-studied so far. Recently, the Generalized User-Role Assignment model (GURA) was proposed to provide ARBAC97-style (administrative role-based access control) administration of user attributes. An attribute is simply a name-value pair, examples of which include clearance, group and affiliations. In GURA, user attributes are collectively administered by different administrative roles to enable distributed administration. Given an administrative policy that specifies the conditions under which administrative roles can modify user attributes, it is useful to understand whether an attribute of a particular user can reach a specific value because user attributes are used for security-sensitive activities such as authentication, authorization and audit. In this paper, we study the user-attribute reachability problems in a restricted GURA model called rGURA. We formalize rGURA as a state transition system and show that the reachability problems for its general cases are PSPACE-complete. However, we do find polynomial-time solutions to reachability problems for limited versions of rGURA that are still useful in practice. The algorithms not only answer reachability problem but also provide a plan of sequential attribute updates by one or more administrators in order to reach particular values for user attributes. rGURA is relatively simple and practical. It is likely that other proposals will subsume the functionality of rGURA and thereby subsume its complexity results.},
booktitle = {Proceedings of the 2013 ACM Workshop on Digital Identity Management},
pages = {73–84},
numpages = {12},
keywords = {reachability analysis, administration, attributes},
location = {Berlin, Germany},
series = {DIM '13}
}

@inproceedings{10.1145/2523501.2523506,
author = {Berhanu, Yared and Abie, Habtamu and Hamdi, Mohamed},
title = {A Testbed for Adaptive Security for IoT in EHealth},
year = {2013},
isbn = {9781450325431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2523501.2523506},
doi = {10.1145/2523501.2523506},
abstract = {Wireless Body Area Sensor Networks (WBASNs) are networks of low-power sensing objects that collect and send vital signs of a patient using low-rate communication media. They have been originally created to improve the efficiency of e-health applications and they constitute now an important part of the Internet of Things (IoT) by bringing humans into the IoTs. The ASSET (Adaptive Security for Smart Internet of Things in eHealth) project [1] develops risk-based adaptive security methods and mechanisms for IoT in eHealth. The project requires a real-life testbed to evaluate accurately the adaptive security solutions in realistic simulation and use case scenarios. This paper describes the setup of a testbed for adaptive security for the IoT using current commercial off-the-shelf products and open source software. The particular features of the proposed testbed with regard to those published in the literature are underlined. The paper also discusses the validation of the setup through the study of the impact of antenna orientation on energy consumption. To this purpose, an estimation strategy of the energy consumption using the Holt-Winters prediction method has been developed. This will particularly be useful when studying the feasibility of the adaptive lightweight security solutions that will be part of the ASSET project.},
booktitle = {Proceedings of the International Workshop on Adaptive Security},
articleno = {5},
numpages = {8},
keywords = {eHealth, wireless body area sensor networks, testbed, adaptive security, IoT},
location = {Zurich, Switzerland},
series = {ASPI '13}
}

@proceedings{10.1145/2523514,
title = {SIN '13: Proceedings of the 6th International Conference on Security of Information and Networks},
year = {2013},
isbn = {9781450324984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The main theme of the SIN 2013 conference is security of information and networks. The theme includes the following topics: Access control and intrusion detection; Cyber physical systems; Autonomous and adaptive security; Security tools and development platforms; Computational intelligence techniques in security; Security ontology, models, protocols &amp; policies; Computer network defense; Standards, guidelines and certification; Cryptographic techniques and key management; Security-aware software engineering; Industrial applications of security; Trust and privacy; Information assurance; Cyber Warfare (attacks and defenses); Next generation network architectures; Malware analysis; Network security and protocols; Security challenges in mobile/embedded systems.},
location = {Aksaray, Turkey}
}

@article{10.1145/2555611,
author = {Yuan, Eric and Esfahani, Naeem and Malek, Sam},
title = {A Systematic Survey of Self-Protecting Software Systems},
year = {2014},
issue_date = {January 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {4},
issn = {1556-4665},
url = {https://doi.org/10.1145/2555611},
doi = {10.1145/2555611},
abstract = {Self-protecting software systems are a class of autonomic systems capable of detecting and mitigating security threats at runtime. They are growing in importance, as the stovepipe static methods of securing software systems have been shown to be inadequate for the challenges posed by modern software systems. Self-protection, like other self-* properties, allows the system to adapt to the changing environment through autonomic means without much human intervention, and can thereby be responsive, agile, and cost effective. While existing research has made significant progress towards autonomic and adaptive security, gaps and challenges remain. This article presents a significant extension of our preliminary study in this area. In particular, unlike our preliminary study, here we have followed a systematic literature review process, which has broadened the scope of our study and strengthened the validity of our conclusions. By proposing and applying a comprehensive taxonomy to classify and characterize the state-of-the-art research in this area, we have identified key patterns, trends and challenges in the existing approaches, which reveals a number of opportunities that will shape the focus of future research efforts.},
journal = {ACM Trans. Auton. Adapt. Syst.},
month = {jan},
articleno = {17},
numpages = {41},
keywords = {self-adaptive systems, Self-protection, adaptive security, autonomic computing, self-* properties}
}

@inproceedings{10.1145/2593929.2593938,
author = {Bennaceur, Amel and Bandara, Arosha K. and Jackson, Michael and Liu, Wei and Montrieux, Lionel and Tun, Thein Than and Yu, Yijun and Nuseibeh, Bashar},
title = {Requirements-Driven Mediation for Collaborative Security},
year = {2014},
isbn = {9781450328647},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2593929.2593938},
doi = {10.1145/2593929.2593938},
abstract = {Security is concerned with the protection of assets from intentional harm. Secure systems provide capabilities that enable such protection to satisfy some security requirements. In a world increasingly populated with mobile and ubiquitous computing technology, the scope and boundary of security systems can be uncertain and can change. A single functional component, or even multiple components individually, are often insufficient to satisfy complex security requirements on their own. Adaptive security aims to enable systems to vary their protection in the face of changes in their operational environment. Collaborative security, which we propose in this paper, aims to exploit the selection and deployment of multiple, potentially heterogeneous, software-intensive components to collaborate in order to meet security requirements in the face of changes in the environment, changes in assets under protection and their values, and the discovery of new threats and vulnerabilities. However, the components that need to collaborate may not have been designed and implemented to interact with one another collaboratively. To address this, we propose a novel framework for collaborative security that combines adaptive security, collaborative adaptation and an explicit representation of the capabilities of the software components that may be needed in order to achieve collaborative security. We elaborate on each of these framework elements, focusing in particular on the challenges and opportunities afforded by (1) the ability to capture, represent, and reason about the capabilities of different software components and their operational context, and (2) the ability of components to be selected and mediated at runtime in order to satisfy the security requirements. We illustrate our vision through a collaborative robotic implementation, and suggest some areas for future work.},
booktitle = {Proceedings of the 9th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
pages = {37–42},
numpages = {6},
keywords = {collaborative adaptation, Security requirements, mediation},
location = {Hyderabad, India},
series = {SEAMS 2014}
}

@inproceedings{10.1145/2593929.2593939,
author = {Pasquale, Liliana and Ghezzi, Carlo and Menghi, Claudio and Tsigkanos, Christos and Nuseibeh, Bashar},
title = {Topology Aware Adaptive Security},
year = {2014},
isbn = {9781450328647},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2593929.2593939},
doi = {10.1145/2593929.2593939},
abstract = {Adaptive security systems aim to protect valuable assets in the face of changes in their operational environment. They do so by monitoring and analysing this environment, and deploying security functions that satisfy some protection (security, privacy, or forensic) requirements. In this paper, we suggest that a key characteristic for engineering adaptive security is the topology of the operational environment, which represents a physical and/or a digital space - including its structural relationships, such as containment, proximity, and reachability. For adaptive security, topology expresses a rich representation of context that can provide a system with both structural and semantic awareness of important contextual characteristics. These include the location of assets being protected or the proximity of potentially threatening agents that might harm them. Security-related actions, such as the physical movement of an actor from a room to another in a building, may be viewed as topological changes. The detection of a possible undesired topological change (such as an actor possessing a safe’s key entering the room where the safe is located) may lead to the decision to deploy a particular security control to protect the relevant asset. This position paper advocates topology awareness for more effective engineering of adaptive security. By monitoring changes in topology at runtime one can identify new or changing threats and attacks, and deploy adequate security controls accordingly. The paper elaborates on the notion of topology and provides a vision and research agenda on its role for systematically engineering adaptive security systems.},
booktitle = {Proceedings of the 9th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
pages = {43–48},
numpages = {6},
keywords = {Topology, adaptation, digital forensics, privacy, security},
location = {Hyderabad, India},
series = {SEAMS 2014}
}

@inproceedings{10.1145/2593929.2593945,
author = {Bailey, Christopher and Montrieux, Lionel and de Lemos, Rog\'{e}rio and Yu, Yijun and Wermelinger, Michel},
title = {Run-Time Generation, Transformation, and Verification of Access Control Models for Self-Protection},
year = {2014},
isbn = {9781450328647},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2593929.2593945},
doi = {10.1145/2593929.2593945},
abstract = {Self-adaptive access control, in which self-* properties are applied to protecting systems, is a promising solution for the handling of malicious user behaviour in complex infrastructures. A major challenge in self-adaptive access control is ensuring that chosen adaptations are valid, and produce a satisfiable model of access. The contribution of this paper is the generation, transformation and verification of Role Based Access Control (RBAC) models at run-time, as a means for providing assurances that the adaptations to be deployed are valid. The goal is to protect the system against insider threats by adapting at run-time the access control policies associated with system resources, and access rights assigned to users. Depending on the type of attack, and based on the models from the target system and its environment, the adapted access control models need to be evaluated against the RBAC metamodel, and the adaptation constraints related to the application. The feasibility of the proposed approach has been demonstrated in the context of a fully working prototype using malicious scenarios inspired by a well documented case of insider attack.},
booktitle = {Proceedings of the 9th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
pages = {135–144},
numpages = {10},
keywords = {rbac, model verification, adaptive security, self-adaptation},
location = {Hyderabad, India},
series = {SEAMS 2014}
}

@inproceedings{10.1145/2598394.2605437,
author = {John, David J. and Smith, Robert W. and Turkett, William H. and Ca\~{n}as, Daniel A. and Fulp, Errin W.},
title = {Evolutionary Based Moving Target Cyber Defense},
year = {2014},
isbn = {9781450328814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2598394.2605437},
doi = {10.1145/2598394.2605437},
abstract = {A Moving Target (MT) defense constantly changes a system's attack surface, in an attempt to limit the usefulness of the reconnaissance the attacker has collected. One approach to this defense strategy is to intermittently change a system's configuration. These changes must maintain functionality and security, while also being diverse. Finding suitable configuration changes that form a MT defense is challenging. There are potentially a large number of individual configurations' settings to consider, without a full understanding of the settings' interdependencies.Evolution-based algorithms, which formulate better solutions from good solutions, can be used to create a MT defense. New configurations are created based on the security of previous configurations and can be periodically implemented to change the system's attack surface. This approach not only has the ability to discover new, more secure configurations, but is also proactive and resilient since it can continually adapt to the current environment in a fashion similar to systems found in nature.This article presents and compares two genetic algorithms to create a MT defense. The primary difference between the two is based on their approaches to mutation. One mutates values, and the other modifies the domains from which values are chosen.},
booktitle = {Proceedings of the Companion Publication of the 2014 Annual Conference on Genetic and Evolutionary Computation},
pages = {1261–1268},
numpages = {8},
keywords = {moving target defense, directed mutation, computer security},
location = {Vancouver, BC, Canada},
series = {GECCO Comp '14}
}

@inproceedings{10.1145/2611462.2611498,
author = {Libert, Beno\^{\i}t and Joye, Marc and Yung, Moti},
title = {Born and Raised Distributively: Fully Distributed Non-Interactive Adaptively-Secure Threshold Signatures with Short Shares},
year = {2014},
isbn = {9781450329446},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2611462.2611498},
doi = {10.1145/2611462.2611498},
abstract = {Threshold cryptography is a fundamental distributed computational paradigm for enhancing the availability and the security of cryptographic public-key schemes. It does it by dividing private keys into n shares handed out to distinct servers. In threshold signature schemes, a set of at least t+1 ≤ n servers is needed to produce a valid digital signature. Availability is assured by the fact that any subset of t+1 servers can produce a signature when authorized. At the same time, the scheme should remain robust (in the fault tolerance sense) and unforgeable (cryptographically) against up to t corrupted servers; i.e., it adds quorum control to traditional cryptographic services and introduces redundancy. Originally, most practical threshold signatures have a number of demerits: They have been analyzed in a static corruption model (where the set of corrupted servers is fixed at the very beginning of the attack), they require interaction, they assume a trusted dealer in the key generation phase (so that the system is not fully distributed), or they suffer from certain overheads in terms of storage (large share sizes). In this paper, we construct practical fully distributed (the private key is born distributed), non-interactive schemes --- where the servers can compute their partial signatures without communication with other servers--- with adaptive security (i.e., the adversary corrupts servers dynamically based on its full view of the history of the system). Our schemes are very efficient in terms of computation, communication, and scalable storage (with private key shares of size O(1), where certain solutions incur O(n) storage costs at each server). Unlike other adaptively secure schemes, our schemes are erasure-free (reliable erasure is a hard to assure and hard to administer property in actual systems).To the best of our knowledge, such a fully distributed highly constrained scheme has been an open problem in the area. In particular, and of special interest, is the fact that Pedersen's traditional distributed key generation (DKG) protocol can be safely employed in the initial key generation phase when the system is born -- although it is well-known not to ensure uniformly distributed public keys. An advantage of this is that this protocol only takes one round optimistically (in the absence of faulty player).},
booktitle = {Proceedings of the 2014 ACM Symposium on Principles of Distributed Computing},
pages = {303–312},
numpages = {10},
keywords = {availability, erasure-free schemes, distributed key generation, fault tolerance, non-interactivity, fully distributed systems, adaptive security, efficiency, threshold signature schemes},
location = {Paris, France},
series = {PODC '14}
}

@inproceedings{10.1145/2642803.2642805,
author = {Juhola, Arto and Ahola, Titta and Ahola, Kimmo},
title = {Adaptive Risk Management with Ontology Linked Evidential Statistics and SDN},
year = {2014},
isbn = {9781450327787},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2642803.2642805},
doi = {10.1145/2642803.2642805},
abstract = {New technologies have increased the dynamism of distributed systems; advances such as Software Defined Networking (SDN) and cloud computing enable unprecedented service flexibility and scalability. By their nature, they are in a constant state of flux, presenting tough challenges for system security. Here an adaptive -- in real time - risk management system capable of keeping abreast of these developments is considered. This paper presents an on-going work on combining a hierarchical threat ontology, real-time risk analysis, and SDN to an efficient whole. The main contribution of this paper is on finding the suitable architectures, components, necessary requirements, and favorable modifications on the systems and system modelling (including the models involving the security analysis) to reach this goal.},
booktitle = {Proceedings of the 2014 European Conference on Software Architecture Workshops},
articleno = {2},
numpages = {7},
keywords = {Threat ontology, Adaptive security, SDN, Neural Network inspired Fuzzy C-means, Dezert-Smarandache, Dempster-Schafer},
location = {Vienna, Austria},
series = {ECSAW '14}
}

@inproceedings{10.1145/2642803.2642807,
author = {Torjusen, Arild B. and Abie, Habtamu and Paintsil, Ebenezer and Trcek, Denis and Skomedal, \r{A}smund},
title = {Towards Run-Time Verification of Adaptive Security for IoT in EHealth},
year = {2014},
isbn = {9781450327787},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2642803.2642807},
doi = {10.1145/2642803.2642807},
abstract = {This paper integrates run-time verification enablers in the feedback adaptation loop of the ASSET adaptive security framework for Internet of Things (IoT) in the eHealth settings and instantiates the resulting framework with Colored Petri Nets. The run-time enablers make machine-readable formal models of a system state and context available at run-time. In addition, they make requirements that define the objectives of verification available at run-time as formal specifications and enable dynamic context monitoring and adaptation. Run-time adaptive behavior that deviates from the normal mode of operation of the system represents a major threat to the sustainability of critical eHealth services. Therefore, the integration of run-time enablers into the ASSET adaptive framework could lead to a sustainable security framework for IoT in eHealth.},
booktitle = {Proceedings of the 2014 European Conference on Software Architecture Workshops},
articleno = {4},
numpages = {8},
keywords = {IoT, Formal Run-time Verification, eHealth, Adaptive Security},
location = {Vienna, Austria},
series = {ECSAW '14}
}

@inproceedings{10.1145/2642803.2642808,
author = {Evesti, Antti and Abie, Habtamu and Savola, Reijo},
title = {Security Measuring for Self-Adaptive Security},
year = {2014},
isbn = {9781450327787},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2642803.2642808},
doi = {10.1145/2642803.2642808},
abstract = {Self-adaptive security is needed due to vast amount of changes in an execution environment and threat landscape, which all cannot be anticipated at software design-time. Self-adaptive security requires means for monitoring a security level and decision making capability to improve the current security level. In this paper, we describe how security metrics are able to support self-adaptive security. The paper analyses benefits and challenges of security measuring from the self-adaptive security perspective. Thus, five benefits and three challenges of security metrics in self-adaptive security are described. Furthermore, the paper derives requirements that measuring causes for self-adaptive security. Based on the derived requirements, extension components for the MAPE (Monitor, Analyse, Plan and Execute) reference model are proposed.},
booktitle = {Proceedings of the 2014 European Conference on Software Architecture Workshops},
articleno = {5},
numpages = {7},
keywords = {Self-adaptive, security metric, architecture, decision-making},
location = {Vienna, Austria},
series = {ECSAW '14}
}

@inproceedings{10.1145/2659651.2660516,
author = {Ramli, Ahmad Kamal and Djemame, Karim},
title = {Autonomic Management for Convergent Networks to Support Robustness of Appliance Technologies},
year = {2014},
isbn = {9781450330336},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2659651.2660516},
doi = {10.1145/2659651.2660516},
abstract = {Autonomic management within autonomic computing framework is considered as the future and viable solution for many appliances, either in software or hardware. Nevertheless, its current research application in computer networks is mainly visible in the intra domain space, and less attention is given to inter domain between one core network and another. This paper reviews some of the work on autonomic management and presents a framework that can be extended to a global and universal solution, such as fulfilling demand on bandwidth management, Quality of Service (QOS), and Service Level Agreements (SLA). The autonomic computing self- features are considered to show the viability of the proposed framework.},
booktitle = {Proceedings of the 7th International Conference on Security of Information and Networks},
pages = {47–51},
numpages = {5},
keywords = {Information Assurance, Adaptive Architecture, Next generation Networks, Bandwidth Management, Autonomic Management, Service Level Agreements, Autonomous and Adaptive Security},
location = {Glasgow, Scotland, UK},
series = {SIN '14}
}

@inproceedings{10.1145/2664243.2664273,
author = {Zhang, Tianwei and Lee, Ruby B.},
title = {New Models of Cache Architectures Characterizing Information Leakage from Cache Side Channels},
year = {2014},
isbn = {9781450330053},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2664243.2664273},
doi = {10.1145/2664243.2664273},
abstract = {Side-channel attacks try to breach confidentiality and retrieve critical secrets through the side channels. Cache memories are a potential source of information leakage through side-channel attacks, many of which have been proposed. Meanwhile, different cache architectures have also been proposed to defend against these attacks. However, there are currently no means for comparing and evaluating the effectiveness of different defense solutions against these attacks.In this paper, we propose a novel method to evaluate a system's vulnerability to side-channel attacks. We establish side-channel leakage models based on the non-interference property. Then we define how the security aspects of a cache architecture can be modeled as a finite-state machine (FSM) with state transitions that cause interference. We use mutual information to quantitatively reveal potential side-channel leakage of the architectures, and allow comparison of these architectures for their relative vulnerabilities to side-channel attacks. We use real attacks to validate our results.},
booktitle = {Proceedings of the 30th Annual Computer Security Applications Conference},
pages = {96–105},
numpages = {10},
location = {New Orleans, Louisiana, USA},
series = {ACSAC '14}
}

@inproceedings{10.1145/2676723.2691922,
author = {Ortiz, Ariel},
title = {A Bottom-Up Approach to Teaching Server-Side Web Development Skills (Abstract Only)},
year = {2015},
isbn = {9781450329668},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2676723.2691922},
doi = {10.1145/2676723.2691922},
abstract = {When dealing with the topic of back-end programming many CS web development courses typically focus on how to use a popular web framework, for example Spring MVC or Ruby on Rails. The problem with this approach is that students will most likely end up using some other different framework or technology if ever they decide to become professional web developers. Our students need to learn concepts and skills that serve as a foundation to learn whatever different technologies are used now or happen to appear in the future. This poster presents the author's experience on using a bottom-up approach to teach the fundamental aspects of how the HTTP protocol works, and how this knowledge can be used to get a deep understanding of the inner workings of the web by building a simple yet complete server-side web framework. Using Node.js as the development platform, students are able to take TCP sockets as the building blocks for higher-level web abstractions. This approach allows covering a variety of specific topics that are essential for a professional web developer: request and response structure and headers, HTTP methods, form processing, cookies and sessions, text encodings, MVC software architectural pattern, database integration using ORM (Object-Relational Mapping), REST (Representational State Transfer) architecture, security issues (HTTPS protocol, common web vulnerabilities), and client-side integration using AJAX (Asynchronous JavaScript and XML). Anecdotal evidence shows that students with this knowledge repertoire are better suited for learning, using and debugging new and existing web technologies.},
booktitle = {Proceedings of the 46th ACM Technical Symposium on Computer Science Education},
pages = {678},
numpages = {1},
keywords = {web development, node.js, server-side programming, javascript},
location = {Kansas City, Missouri, USA},
series = {SIGCSE '15}
}

@inproceedings{10.1145/2677855.2677898,
author = {Anwer, Faisal and Nazir, Mohd. and Mustafa, Khurram},
title = {Automatic Testing of Inconsistency Caused by Improper Error Handling: A Safety and Security Perspective},
year = {2014},
isbn = {9781450332163},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2677855.2677898},
doi = {10.1145/2677855.2677898},
abstract = {Object oriented programming language provides structured way of handling error through Exception handling mechanism. Exception handling must be carefully programmed, it may leave the application in inconsistent state. Inconsistency happens when state change by the program is not reverted to its consistent state in case of exceptions. Inconsistent state can have serious side effects, it may corrupt the system or may lead to software crashes. It may be misused by the attacker to make the system down or intentionally corrupt the system. Researchers have proposed several methods to protect inconsistency developed due to exceptions. Very few techniques have been developed to test the inconsistencies in the system. In this paper we have proposed a method to automatically detect the inconsistency in the system.},
booktitle = {Proceedings of the 2014 International Conference on Information and Communication Technology for Competitive Strategies},
articleno = {43},
numpages = {5},
keywords = {Atomic method, Exception handling, Symbolic execution},
location = {Udaipur, Rajasthan, India},
series = {ICTCS '14}
}

@article{10.1145/2693208.2693229,
author = {Dwivedi, Ashish Kumar and Rath, Santanu Kumar},
title = {Incorporating Security Features in Service-Oriented Architecture Using Security Patterns},
year = {2015},
issue_date = {January 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {1},
issn = {0163-5948},
url = {https://doi.org/10.1145/2693208.2693229},
doi = {10.1145/2693208.2693229},
abstract = {Service-Oriented Architecture is an architectural style where different heterogeneous components share information with each other by using special types of messages based on the protocol known as Simple Object Access Protocol. Various technologies, such as Common Object Request Broker Architecture, Java 2 Platform, Enterprise Edition, Java Message Service etc. are applied to realize Service-Oriented Architecture for different applications. Besides these approaches, two other techniques, REpresentational State Transfer, and web services are applied for the realization of Service-Oriented Architecture. Web services provide a platform independent communication scheme between applications. The security preservation among the composition of services is an important task for Service-Oriented Architecture. In this study, an attempt is made to incorporate security features in Service- Oriented Architecture with the help of software security patterns. This scheme is described by developing an architectural model integrated with security goals and security patterns. The structural and behavioral aspects of composition of web services incorporated with security features are presented using a Unified Modeling Language class diagram and a sequence diagram respectively. At the end of this study, an evaluation is performed between identified security patterns and critical security properties along with Service-Oriented Architecture design principles. A case study of an online banking system is considered to explain the use of security patterns.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {feb},
pages = {1–6},
numpages = {6},
keywords = {Web Services, Security Patterns, Service Composition, SOA}
}

@inproceedings{10.1145/2740908.2743045,
author = {Fertig, Tobias and Braun, Peter},
title = {Model-Driven Testing of RESTful APIs},
year = {2015},
isbn = {9781450334730},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2740908.2743045},
doi = {10.1145/2740908.2743045},
abstract = {In contrast to the increasing popularity of REpresentational State Transfer (REST), systematic testing of RESTful Application Programming Interfaces (API) has not attracted much attention so far. This paper describes different aspects of automated testing of RESTful APIs. Later, we focus on functional and security tests, for which we apply a technique called model-based software development. Based on an abstract model of the RESTful API that comprises resources, states and transitions a software generator not only creates the source code of the RESTful API but also creates a large number of test cases that can be immediately used to test the implementation. This paper describes the process of developing a software generator for test cases using state-of-the-art tools and provides an example to show the feasibility of our approach.},
booktitle = {Proceedings of the 24th International Conference on World Wide Web},
pages = {1497–1502},
numpages = {6},
keywords = {measurement, languages, verification},
location = {Florence, Italy},
series = {WWW '15 Companion}
}

@inproceedings{10.1145/2746285.2764870,
author = {Li, Depeng},
title = {Poster: Toward a Theoretical Privacy Framework for Electronic Locks in Context of Home Security Monitoring System for Clouds of Things},
year = {2015},
isbn = {9781450334891},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2746285.2764870},
doi = {10.1145/2746285.2764870},
abstract = {Current popular schemes e.g. homomorphic cryptography are extensively deployed to preserve privacy in a limited level but without a formal privacy model, we can neither offer privacy guarantee nor quantify the privacy loss. In this paper, we raise a few privacy-related questions, one after another, with the e-Lock state changes in a smart home as an example. In a novel privacy framework we proposed, the questions are partially addressed with the utilization of a set of theoretical models e.g. hidden markov model, differential privacy and information flow with belief. Since our paper is still at its start phase, we plan to accomplish the framework and wish can inspire colleagues' interests in this area.},
booktitle = {Proceedings of the 16th ACM International Symposium on Mobile Ad Hoc Networking and Computing},
pages = {393–394},
numpages = {2},
keywords = {privacy preservation, formal privacy model, electronic lock},
location = {Hangzhou, China},
series = {MobiHoc '15}
}

@inproceedings{10.1145/2837185.2837260,
author = {Mochizuki, Shouta and Takada, Tetsuji},
title = {Client-Oriented Web Alteration Detection System Using Link Change State of a Web Page Based on Past and Current Page Content},
year = {2015},
isbn = {9781450334914},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2837185.2837260},
doi = {10.1145/2837185.2837260},
abstract = {In this paper, we propose a client-oriented web alteration detection system that uses the changed state of links between the past and current versions of a browsing web page. Some measures against malicious web page alterations have been developed, such as URL-blacklist based access control. The limitations of such measures, however, are the coverage and timeliness. It is very difficult to capture all maliciously altered web page data on the Internet. A time delay from when an attacker alters a web page to when a browser blocks access to the web page is unavoidable. We focus on a page alteration such as a code injection or a page modification without a change in the visual layout. Such an alteration may lead users to experience further security threats. To detect altered web pages, whenever a user views a web page, our system extracts the link-based feature data from the page and stores it in a database. In addition, if the database has the feature data of a browsing web page from a previous access time, the system extracts the change in state of all links on the web page based on both the previous and current page content. Moreover, the results are provided to the users through a visual representation. Our system assists web-browsing users to remain aware of malicious alterations to a browsing web page. We believe that our system can engage web-browsing users to monitor web page alterations.},
booktitle = {Proceedings of the 17th International Conference on Information Integration and Web-Based Applications &amp; Services},
articleno = {84},
numpages = {5},
keywords = {web page alteration, information visualization, web browser extension, web link state change, alteration detection, web deface, drive-by download attack},
location = {Brussels, Belgium},
series = {iiWAS '15}
}

@inproceedings{10.1145/2897845.2897858,
author = {Zhang, Kai and Gong, Junqing and Tang, Shaohua and Chen, Jie and Li, Xiangxue and Qian, Haifeng and Cao, Zhenfu},
title = {Practical and Efficient Attribute-Based Encryption with Constant-Size Ciphertexts in Outsourced Verifiable Computation},
year = {2016},
isbn = {9781450342339},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2897845.2897858},
doi = {10.1145/2897845.2897858},
abstract = {In cloud computing, computationally weak users are always willing to outsource costly computations to a cloud, and at the same time they need to check the correctness of the result provided by the cloud. Such activities motivate the occurrence of verifiable computation (VC). Recently, Parno, Raykova and Vaikuntanathan showed any VC protocol can be constructed from an attribute-based encryption (ABE) scheme for a same class of functions. In this paper, we propose two practical and efficient semi-adaptively secure key-policy attribute-based encryption (KP-ABE) schemes with constant-size ciphertexts. The semi-adaptive security requires that the adversary designates the challenge attribute set after it receives public parameters but before it issues any secret key query, which is stronger than selective security guarantee. Our first construction deals with small universe while the second one supports large universe. Both constructions employ the technique underlying the prime-order instantiation of nested dual system groups, which are based on the $d$-linear assumption including SXDH and DLIN assumptions. In order to evaluate the performance, we implement our ABE schemes using $textsf{Python}$ language in Charm. Compared with previous KP-ABE schemes with constant-size ciphertexts, our constructions achieve shorter ciphertext and secret key sizes, and require low computation costs, especially under the SXDH assumption.},
booktitle = {Proceedings of the 11th ACM on Asia Conference on Computer and Communications Security},
pages = {269–279},
numpages = {11},
keywords = {charm, verifiable computation, outsourced computation, attribute-based encryption, dual system encryption},
location = {Xi'an, China},
series = {ASIA CCS '16}
}

@inproceedings{10.1145/2897937.2897992,
author = {Nahiyan, Adib and Xiao, Kan and Yang, Kun and Jin, Yeir and Forte, Domenic and Tehranipoor, Mark},
title = {AVFSM: A Framework for Identifying and Mitigating Vulnerabilities in FSMs},
year = {2016},
isbn = {9781450342360},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2897937.2897992},
doi = {10.1145/2897937.2897992},
abstract = {A finite state machine (FSM) is responsible for controlling the overall functionality of most digital systems and, therefore, the security of the whole system can be compromised if there are vulnerabilities in the FSM. These vulnerabilities can be created by improper designs or by the synthesis tool which introduces additional don't-care states and transitions during the optimization and synthesis process. An attacker can utilize these vulnerabilities to perform fault injection attacks or insert malicious hardware modifications (Trojan) to gain unauthorized access to some specific states. To our knowledge, no systematic approaches have been proposed to analyze these vulnerabilities in FSM. In this paper, we develop a framework named Analyzing Vulnerabilities in FSM (AVFSM) which extracts the state transition graph (including the don't-care states and transitions) from a gate-level netlist using a novel Automatic Test Pattern Generation (ATPG) based approach and quantifies the vulnerabilities of the design to fault injection and hardware Trojan insertion. We demonstrate the applicability of the AVFSM framework by analyzing the vulnerabilities in the FSM of AES and RSA encryption module. We also propose a low-cost mitigation technique to make FSM more secure against these attacks.},
booktitle = {Proceedings of the 53rd Annual Design Automation Conference},
articleno = {89},
numpages = {6},
location = {Austin, Texas},
series = {DAC '16}
}

@inproceedings{10.1145/2947626.2951955,
author = {Hong, Yong-pyo and Kim, Youngjun},
title = {A Study on Unified Security Mechanism and Platform for Centralized Business Contents},
year = {2016},
isbn = {9781450347648},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2947626.2951955},
doi = {10.1145/2947626.2951955},
abstract = {As business is getting sensitive to knowledge, the importance of the business contents that has business information and knowledge is rapidly increasing. Moreover, this business information includes diverse sensitive data, which should be handled in secured way.In sociological terms and information technical terms, it is important to have attention for the phenomenon that occurred in South Korea. Over the last decade in South Korea, many firms have been trying to equip some specialized security system for their internal content, which is known as 'Document (Contents) Centralization System'.This 'Document Centralization System' business became one of the biggest and hottest businesses in the area of Enterprise Contents Management Business and Contents Security Business in South Korea. Surprisingly, this system doesn't have any specialized security technologies. Moreover, it is not limited to digital security technology, but also some industrial security consideration based on business behavior. Additionally, this system needs the concept of serviced security.In order to understand this phenomenon and system effectively, it is not enough only to study information technology and security. Except for individual security technologies, we need to study other many sub themes, such as knowledge contents business, business behavior pattern in terms of industrial security, smart work business and knowledge product service system.Finally, this paper presented the adaptive security system in terms of management of technology, which means that security need to be managed, not installed.. This system has diverse characteristics, such as the convergence capability of digital security technologies, flexible system mechanism corresponding to business behavior and effective cloud system which is capable of servicing of knowledge contents.},
booktitle = {Proceedings of the 9th International Conference on Security of Information and Networks},
pages = {45–48},
numpages = {4},
keywords = {Security MOT, MOT, Management of Technology, Contents Security, Information Governance, Centralized Business Contents, Contents Centralizing System},
location = {Newark, NJ, USA},
series = {SIN '16}
}

@inproceedings{10.1145/2976749.2978412,
author = {Mao, Yunlong and Zhang, Yuan and Zhong, Sheng},
title = {Stemming Downlink Leakage from Training Sequences in Multi-User MIMO Networks},
year = {2016},
isbn = {9781450341394},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2976749.2978412},
doi = {10.1145/2976749.2978412},
abstract = {Multi-User MIMO has attracted much attention due to its significant advantage of increasing the utilization ratio of wireless channels. Recently a serious eavesdropping attack, which exploits the CSI feedback of the FDD system, is discovered in MU-MIMO networks. In this paper, we firstly show a similar eavesdropping attack for the TDD system is also possible by proposing a novel, feasible attack approach. Following it, a malicious user can eavesdrop on other users' downloads by transforming training sequences. To prevent this attack, we propose a secure CSI estimation scheme for instantaneous CSI. Furthermore, we extend this scheme to achieve adaptive security when CSI is relatively statistical. We have implemented our scheme for both uplink and downlink of MU-MIMO and performed a series of experiments. Results show that our secure CSI estimation scheme is highly effective in preventing downlink leakage against malicious users.},
booktitle = {Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security},
pages = {1580–1590},
numpages = {11},
keywords = {multi-user mimo, eavesdropping, physical security, channel state information},
location = {Vienna, Austria},
series = {CCS '16}
}

@inproceedings{10.1145/3011784.3011798,
author = {Rauter, Tobias and H\"{o}ller, Andrea and Iber, Johannes and Kreiner, Christian},
title = {Static and Dynamic Integrity Properties Patterns},
year = {2016},
isbn = {9781450340748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3011784.3011798},
doi = {10.1145/3011784.3011798},
abstract = {Integrity is a crucial property in current computing systems. Due to natural or human-made (malicious and non-malicious) faults this property can be violated. Therefore, many methodologies and patterns that check or verify the integrity of systems or data have been introduced. However, integrity as a property cannot be identified directly. Existing methodologies tackle this problem by identifying other, computable, properties of the system and use a policy that describes how these properties reflect the integrity of the overall system. It is thus a critical task to select the right properties that reflect the integrity of a system in such a way that given integrity requirements are met. To ease this process, we introduce two new patterns, Static Integrity Properties and Dynamic Integrity Properties to classify the properties. Static Integrity Properties are used to ensure the integrity of a component prior it's use (e.g., the integrity of an executable binary), while Dynamic Integrity Properties are used to ensure the integrity of a component during run-time (e.g., properties that reflect the component's behavior or state transitions). Based on an exemplary embedded control system, we show typical use cases to help the system or software architect to choose the right class of integrity properties for the targeted system.},
booktitle = {Proceedings of the 21st European Conference on Pattern Languages of Programs},
articleno = {14},
numpages = {11},
keywords = {security patterns, software integrity},
location = {Kaufbeuren, Germany},
series = {EuroPlop '16}
}

@inproceedings{10.1145/3011883.3011886,
author = {Brookes, Scott and Taylor, Stephen},
title = {Rethinking Operating System Design: Asymmetric Multiprocessing for Security and Performance},
year = {2016},
isbn = {9781450348133},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3011883.3011886},
doi = {10.1145/3011883.3011886},
abstract = {Developers and academics are constantly seeking to increase the speed and security of operating systems. Unfortunately, an increase in either one often comes at the cost of the other. In this paper, we present an operating system design that challenges a long-held tenet of multicore operating systems in order to produce an alternative architecture that has the potential to deliver both increased security and faster performance. In particular, we propose decoupling the operating system kernel from user processes by running each on completely separate processor cores instead of at different privilege levels within shared cores. Without using the hardware's privilege modes, virtualization and virtual memory contexts enforce the security policies necessary to maintain process isolation and protection. Our new kernel design paradigm offers the opportunity to simultaneously increase both performance and security; utilizing the hardware facilities for inter-core communication in place of those for privilege mode switching offers the opportunity for increased system call performance, while the hard separation between user processes and the kernel provides several strong security properties.},
booktitle = {Proceedings of the 2016 New Security Paradigms Workshop},
pages = {68–79},
numpages = {12},
location = {Granby, Colorado, USA},
series = {NSPW '16}
}

@inproceedings{10.1145/3019612.3019652,
author = {Shepherd, Carlton and Akram, Raja Naeem and Markantonakis, Konstantinos},
title = {Towards Trusted Execution of Multi-Modal Continuous Authentication Schemes},
year = {2017},
isbn = {9781450344869},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3019612.3019652},
doi = {10.1145/3019612.3019652},
abstract = {The emergence of powerful, sensor-rich devices has led to the development of continuous authentication (CA) schemes using off-the-shelf hardware, where user behaviour is compared to past experience to produce an authentication decision with the aim of addressing challenges with traditional authentication schemes. Current CA proposals, however, have largely neglected adversaries present in a real-world deployment, namely the ubiquity of mal ware and software attacks. This has particular importance when a device cannot be trusted by a third-party, such as a corporation, that controls access to assets based on that decision. A software compromise, either on the scheme implementation or platform, may enable an adversary to modify authentication scores to alter the status of the device in reality, give insights into user behaviour, or gain unauthorised access to restricted assets. Hence, for the first time, we examine two standardised constructs that offer isolated and trusted execution - Secure Elements (SEs) and Trusted Execution Environments (TEEs) - even when an adversary has root-level privileges, and propose measures for providing trusted CA while retaining deployability. Based on these, we implement the first system for evaluating TEE-based CA on a consumer mobile device using Intel SGX, thus providing confidentiality, integrity and trust while removing the main platform from the TCB. We present an empirical evaluation of TEE-and non-TEE performance using methods proposed in related CA schemes. Our results indicate that trusted CA can be provided with no significant performance penalty, and may even offer performance benefits.},
booktitle = {Proceedings of the Symposium on Applied Computing},
pages = {1444–1451},
numpages = {8},
keywords = {trusted execution environments, mobile security, continuous authentication, trusted computing},
location = {Marrakech, Morocco},
series = {SAC '17}
}

@inproceedings{10.1145/3019612.3019728,
author = {Radwan, Marwan and Heckel, Reiko},
title = {Prediction of the Domain Name System (DNS) Quality Attributes},
year = {2017},
isbn = {9781450344869},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3019612.3019728},
doi = {10.1145/3019612.3019728},
abstract = {The Domain Name System (DNS) has a direct impact on the performance and dependability of nearly all aspects of interactions on the Internet. DNS relies on a delegation-based architecture, where resolution of a name to its IP address requires resolving the names of the servers responsible for that name. The graphs of the inter-dependencies that exist between name servers associated with each zone are called Dependency Graphs. We constructed a DNS Dependency Model as a unified representation of these Dependency Graphs. We utilize a set of Structural Metrics defined over this model as indicators of external quality attributes of the domain name system. We explore the inter-metric and inter-quality relations further in order to quantify the indicative power of each metric. We apply some machine learning algorithms in order to construct Prediction Models of the perceived quality attributes of the operational system out of the structural metrics of the model. Assessing these quality attributes at an early stage of the design/deployment enables us to avoid the implications of defective and low-quality designs and deployment choices and identify configuration changes that might improve the availability, security, stability and resiliency postures of the DNS.},
booktitle = {Proceedings of the Symposium on Applied Computing},
pages = {578–585},
numpages = {8},
keywords = {domain name system, dependency graphs, predictive models, DNS qualities},
location = {Marrakech, Morocco},
series = {SAC '17}
}

@inproceedings{10.1145/3019612.3019755,
author = {Sartoli, Sara and Namin, Akbar Siami},
title = {A Semantic Model for Action-Based Adaptive Security},
year = {2017},
isbn = {9781450344869},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3019612.3019755},
doi = {10.1145/3019612.3019755},
abstract = {This paper presents a semantic model to represent topology-based security requirements, recommend measures to address any possible security violations, and thus make the underlying systems compliant with its security requirements. The proposed action-based model is capable of adaptively adjusting the topological model of a given system in response to changes in the structure of its operational environment. The proposed framework benefits from non-monotonic reasoning to reason about possible execution paths and hence recommend actions to prevent security requirements violations. The results of our case studies show that using the proposed approach to enforce security measures, not only can we detect possible security violations caused by changes in the structure of operational environment, but also recommend actions to address possible violations.},
booktitle = {Proceedings of the Symposium on Applied Computing},
pages = {1130–1135},
numpages = {6},
keywords = {formal methods, adaptive security, topology awareness, access control, answer set programming},
location = {Marrakech, Morocco},
series = {SAC '17}
}

@inproceedings{10.1145/3041021.3051694,
author = {Wang, Xin and Madaan, Aastha and Siow, Eugene and Tiropanis, Thanassis},
title = {Sharing Databases on the Web with Porter Proxy},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051694},
doi = {10.1145/3041021.3051694},
abstract = {With large number of datasets now available through the Web, data-sharing ecosystems such as the Web Observatory have emerged. The Web Observatory provides an active decentralised ecosystem for datasets and applications based on a number Web Observatory sites, each of which can run in a different administrative domain. On a Web Observatory site users can publish and securely access datasets across domains via a harmonised API and reverse proxies for access control. However, that API provides a different interface to that of the databases on which datasets are stored and, consequently, existing applications that consume data from specific databases require major modification to be added to the Web Observatory ecosystem. In this paper we propose a lightweight architecture called Porter Proxy to address this concern. Porter Proxy exposes the same interfaces as databases as requested by the users while enforcing access control. Characteristics of the proposed Porter Proxy architecture are evaluated based on adversarial scenario-handling in Web Observatory eco-system.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1673–1676},
numpages = {4},
keywords = {web observatory, data sharing, security, access control, proxy},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3052973.3053003,
author = {Kim, Jongkil and Susilo, Willy and Guo, Fuchun and Au, Man Ho and Nepal, Surya},
title = {An Efficient KP-ABE with Short Ciphertexts in Prime OrderGroups under Standard Assumption},
year = {2017},
isbn = {9781450349444},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3052973.3053003},
doi = {10.1145/3052973.3053003},
abstract = {We introduce an efficient Key-Policy Attribute-Based Encryption (KP-ABE) scheme in prime order groups. Our scheme is semi-adaptively secure under the decisional linear assumption and supports a large universe of attributes and multi-use of attributes. Those properties are critical for real applications of KP-ABE schemes since they enable an efficient and flexible access control. Prior to our work, existing KP-ABE schemes with short ciphertexts were in composite order groups or utilized either Dual Pairing Vector Spaces (DPVS) or Dual System Groups (DSG) in prime order groups. However, those techniques brought an efficiency loss. In this work, we utilize a nested dual system encryption which is a variant of Waters' dual system encryption (Crypto' 09) to achieve semi-adaptively secure KP-ABE. As a result, we obtain a new scheme having better efficiency compared to existing schemes while it keeps a semi-adaptive security under the standard assumption. We implement our scheme and compare its efficiency with the previous best work.},
booktitle = {Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security},
pages = {823–834},
numpages = {12},
keywords = {attribute based encryption, short ciphertexts, prime order groups, dual system encryption, standard assumption},
location = {Abu Dhabi, United Arab Emirates},
series = {ASIA CCS '17}
}

@inproceedings{10.1145/3134230.3134239,
author = {Van Laerhoven, Kristof and Wenzel, Mario and Geelen, Anouk and H\"{u}bel, Christopher and Wolters, Maike and Hebestreit, Antje and Andersen, Lene Frost and van't Veer, Pieter and Kubiak, Thomas},
title = {Experiences from a Wearable-Mobile Acquisition System for Ambulatory Assessment of Diet and Activity},
year = {2017},
isbn = {9781450352239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3134230.3134239},
doi = {10.1145/3134230.3134239},
abstract = {Public health trends are currently monitored and diagnosed based on large studies that often rely on pen-and-paper data methods that tend to require a large collection campaign. With the pervasiveness of smart-phones and -watches throughout the general population, we argue in this paper that such devices and their built-in sensors can be used to capture such data more accurately with less of an effort. We present a system that targets a pan-European and harmonised architecture, using smartphones and wrist-worn activity loggers to enable the collection of data to estimate sedentary behavior and physical activity, plus the consumption of sugar-sweetened beverages. We report on a unified pilot study across three countries and four cities (with different languages, locale formats, and data security and privacy laws) in which 83 volunteers were asked to log beverages consumption along with a series of surveys and longitudinal accelerometer data. Our system is evaluated in terms of compliance, obtained data, and first analyses.},
booktitle = {Proceedings of the 4th International Workshop on Sensor-Based Activity Recognition and Interaction},
articleno = {3},
numpages = {8},
keywords = {multi-modal data collection and presentation, activity recognition, barcode scanning, beverage consumption logging},
location = {Rostock, Germany},
series = {iWOAR '17}
}

@inproceedings{10.1145/3137003.3137004,
author = {Reddy, V. Ramu and Deshpande, Parijat and Pal, Arpan},
title = {Simultaneous Measurement and Correlation of PPG Signals Taken from Two Different Body Parts for Enhanced Biometric Security via Two-Level Authentication},
year = {2017},
isbn = {9781450355452},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3137003.3137004},
doi = {10.1145/3137003.3137004},
abstract = {In this paper we present a novel, multi-mode physiological photoplethysmogram (PPG) signal based biometric security system to be deployed in conjunction with existing face and finger recognition systems for enhanced security. We propose a two-level authentication system and use two PPG signals collected through face and finger of the subject for cross-correlation. PPG signals are generated due to involuntary body processes and therefore cannot be mimicked. Conventional face and finger print recognition is performed as the first-level security clearance. However, both these can be breached by wearing 3D printed finger tips or masking the face by undergoing surgery or 3D printed wearable face masks. Therefore, a second level security based on involuntary PPG signals is employed for enhanced security. This simultaneous measurement of these heart signals and their correlation is used as a biometric criterion for second level authentication and corresponding results are presented in this paper.},
booktitle = {Proceedings of the 1st ACM Workshop on the Internet of Safe Things},
pages = {32–37},
numpages = {6},
keywords = {Simultaneous measurement of HR waveforms at two separate body points / parts, two level authentication, Two sources for detecting Heart Rate (HR), Multi-mode biometric, Enhanced security, Person authentication via dual heart signal measurements, Heart signal waveforms or blood flow waveforms correlation},
location = {Delft, Netherlands},
series = {SafeThings'17}
}

@inproceedings{10.1145/3167086,
author = {P\^{\i}rlea, George and Sergey, Ilya},
title = {Mechanising Blockchain Consensus},
year = {2018},
isbn = {9781450355865},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3167086},
doi = {10.1145/3167086},
abstract = {We present the first formalisation of a blockchain-based distributed consensus protocol with a proof of its consistency mechanised in an interactive proof assistant. Our development includes a reference mechanisation of the block forest data structure, necessary for implementing provably correct per-node protocol logic. We also define a model of a network, implementing the protocol in the form of a replicated state-transition system. The protocol's executions are modeled via a small-step operational semantics for asynchronous message passing, in which packages can be rearranged or duplicated. In this work, we focus on the notion of global system safety, proving a form of eventual consistency. To do so, we provide a library of theorems about a pure functional implementation of block forests, define an inductive system invariant, and show that, in a quiescent system state, it implies a global agreement on the state of per-node transaction ledgers. Our development is parametric with respect to implementations of several security primitives, such as hash-functions, a notion of a proof object, a Validator Acceptance Function, and a Fork Choice Rule. We precisely characterise the assumptions, made about these components for proving the global system consensus, and discuss their adequacy. All results described in this paper are formalised in Coq.},
booktitle = {Proceedings of the 7th ACM SIGPLAN International Conference on Certified Programs and Proofs},
pages = {78–90},
numpages = {13},
keywords = {Coq, protocol verification, consensus, blockchain},
location = {Los Angeles, CA, USA},
series = {CPP 2018}
}

@inproceedings{10.1145/3176258.3176323,
author = {Masoumzadeh, Amirreza},
title = {Security Analysis of Relationship-Based Access Control Policies},
year = {2018},
isbn = {9781450356329},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3176258.3176323},
doi = {10.1145/3176258.3176323},
abstract = {Relationship-based access control (ReBAC) policies can express intricate protection requirements in terms of relationships among users and resources (which can be modeled as a graph). Such policies are useful in domains beyond online social networks. However, given the updating graph of user and resources in a system and expressive conditions in access control policy rules, it can be very challenging for security administrators to envision what can (or cannot) happen as the protection system evolves.In this paper, we introduce the security analysis problem for this class of policies, where we seek to answer security queries about future states of the system graph and authorizations that are decided accordingly. Towards achieving this goal, we propose a state-transition model of a ReBAC protection system, called RePM. We discuss about formulation of security analysis queries in RePM and present our initial results for a limited version of this model.},
booktitle = {Proceedings of the Eighth ACM Conference on Data and Application Security and Privacy},
pages = {186–195},
numpages = {10},
keywords = {security analysis, relationship-based access control, safety},
location = {Tempe, AZ, USA},
series = {CODASPY '18}
}

@inproceedings{10.1145/3194133.3194155,
author = {Tun, T. T. and Yang, M. and Bandara, A. K. and Yu, Y. and Nhlabatsi, A. and Khan, N. and Khan, K. M. and Nuseibeh, B.},
title = {Requirements and Specifications for Adaptive Security: Concepts and Analysis},
year = {2018},
isbn = {9781450357159},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3194133.3194155},
doi = {10.1145/3194133.3194155},
abstract = {In an adaptive security-critical system, security mechanisms change according to the type of threat posed by the environment. Specifying the behavior of these systems is difficult because conditions of the environment are difficult to describe until the system has been deployed and used for a length of time. This paper defines the problem of adaptation in security-critical systems, and outlines the RELAIS approach for expressing requirements and specifying the behavior in a way that helps identify the need for adaptation, and the appropriate adaptation behavior at runtime. The paper introduces the notion of adaptation via input approximation and proposes statistical machine learning techniques for realizing it. The approach is illustrated with a running example and is applied to a realistic security example from a cloud-based file-sharing application. Bayesian classification and logistic regression methods are used to implement adaptive specifications and these methods offer different levels of adaptive security and usability in the file-sharing application.},
booktitle = {Proceedings of the 13th International Conference on Software Engineering for Adaptive and Self-Managing Systems},
pages = {161–171},
numpages = {11},
keywords = {security requirements, self-adaptation},
location = {Gothenburg, Sweden},
series = {SEAMS '18}
}

@inproceedings{10.1145/3214292.3214300,
author = {Lowe-Power, Jason and Akella, Venkatesh and Farrens, Matthew K. and King, Samuel T. and Nitta, Christopher J.},
title = {Position Paper: A Case for Exposing Extra-Architectural State in the ISA},
year = {2018},
isbn = {9781450365000},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3214292.3214300},
doi = {10.1145/3214292.3214300},
abstract = {The recent Meltdown and Spectre attacks took the community by surprise. Rather than exploiting an incorrect implementation of the ISA, these attacks leverage the undocumented implementation-specific speculation behavior of high-performance microarchitectures to affect the extra-architectural state of the machine (e.g., caches).Inspired by these novel speculation-based attacks, we argue it is time to rethink the traditional ISA layers. Programmers and security professionals need a framework to reason about the effects of speculation and other microarchitectural performance optimizations. We propose judiciously extending the ISA to include the extra-architectural state so that an ISA implementation either completely squashes all system state changes caused by mis-speculated instructions or the potential changes are rigorously documented. We hope this new framework will give architects and security researchers tools to reduce the likelihood of future surprise vulnerabilities.},
booktitle = {Proceedings of the 7th International Workshop on Hardware and Architectural Support for Security and Privacy},
articleno = {8},
numpages = {6},
keywords = {ISA, security, speculation},
location = {Los Angeles, California},
series = {HASP '18}
}

@inproceedings{10.1145/3220267.3220281,
author = {AbdelRahim, Shourok and Ghoneimy, Samy and Selim, Gamal},
title = {Adaptive Security Scheme for Real-Time VoIP Using Multi-Layer Steganography},
year = {2018},
isbn = {9781450364690},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3220267.3220281},
doi = {10.1145/3220267.3220281},
abstract = {Nowadays Voice over Internet Protocol (VoIP) is one of the most widely used technologies to transmit the voice. With the widely spreading in such technology many counters attaches tried to apply different counter measure. In this paper we tried to build a counter countermeasure which increases the security of specific messages by performing a complicated three security stages. These stages are; embedding the selected voice into RGB image, hidden the image in voice signal and perform data integrity using real time protocol (RTP). Following such a proposed algorithm, the process of eavesdrop or counter attacks will not be able to break such a multi-layer security process. In this paper, we propose an Adaptive VoIP steganography approach to hide the audio information within images to enhance the security of the voice communications. The proposed system is completely implemented and developed using C++ in OPNET Modeler. Simulation results showed that the proposed system is robust enough to overcome many attacks such as denial of service, man-in-the-middle and eavesdrop without affecting network performance or quality of service.},
booktitle = {Proceedings of the 7th International Conference on Software and Information Engineering},
pages = {106–110},
numpages = {5},
keywords = {Voice over Internet Protocol, Real Time Protocol, audio security, Steganography, Least Significant Bit},
location = {Cairo, Egypt},
series = {ICSIE '18}
}

@inproceedings{10.1145/3230833.3230847,
author = {Gonzalez-Granadillo, Gustavo and Rubio-Hernan, Jose and Garcia-Alfaro, Joaquin},
title = {A Pyramidal-Based Model to Compute the Impact of Cyber Security Events},
year = {2018},
isbn = {9781450364485},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3230833.3230847},
doi = {10.1145/3230833.3230847},
abstract = {This paper presents a geometrical model that projects malicious and benign events (e.g., attacks, security countermeasures) as pyramidal instances in a multidimensional coordinate system. The approach considers internal event data related to the target system (e.g., users, physical, and logical resources, IP addresses, port numbers, etc.), and external event data related to the attacker (e.g., knowledge, motivation, skills, etc.) that can be obtained a priori and a posteriori. Internal data is used to model the base of the pyramid, whereas external data is used to model its height. In addition, the approach considers state transitions taken by the attacker to model the steps of a multi-stage attack to reach to its final goal. As a result, for each modeled state, new countermeasures are evaluated and the attacker's knowledge a posteriori changes accordingly, making it possible to evaluate the impact of the attack at time Ti, where i denotes the stage at which the attack is executed. A graphical representation of the impact of each evaluated event is depicted for visualization purposes. A use case of a cyber-physical system is proposed at the end of the paper to illustrate the applicability of the proposed geometrical model.},
booktitle = {Proceedings of the 13th International Conference on Availability, Reliability and Security},
articleno = {19},
numpages = {10},
keywords = {Pyramidal Model, Decision Support Tool, Visualization, Event Impact Representation, Geometrical Model, Countermeasure Selection},
location = {Hamburg, Germany},
series = {ARES 2018}
}

@article{10.1145/3234148,
author = {Tziakouris, Giannis and Bahsoon, Rami and Babar, Muhammad Ali},
title = {A Survey on Self-Adaptive Security for Large-Scale Open Environments},
year = {2018},
issue_date = {September 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3234148},
doi = {10.1145/3234148},
abstract = {Contemporary software systems operate in heterogeneous, dynamic, and distributed environments, where security needs change at runtime. The security solutions for such systems need to be adaptive for the continuous satisfaction of the software systems’ security goals. Whilst the existing research on self-adaptive security has made notable advancement towards designing and engineering self-adaptive security solutions, there exists little work on the taxonomic analysis of the architectures of the reported research and its applicability for open and ultra-large environments. We propose an architecture-centric taxonomy for mapping and comparing the current research and identifying the future research directions in this field. The proposed taxonomy has been used to review the representative work on the architectural characteristics that self-adaptive security systems must maintain for their effective application in large-scale open environments. We reflect on the findings from the taxonomic analysis and discuss the design principles, research challenges and limitations reported in the state of the art and practice. We outline the directions for the future research on architectural level support for self-adaptive security systems for large-scale open environments.},
journal = {ACM Comput. Surv.},
month = {oct},
articleno = {100},
numpages = {42},
keywords = {Self-adaptive systems, ultra-large environments}
}

@inproceedings{10.1145/3258045,
author = {Savola, Reijo and Abie, Habtamu and Kanstr\'{e}n, Teemu},
title = {Session Details: Fourth International Workshop on Measurability of Security in Software Architectures (MeSSa 2017)},
year = {2017},
isbn = {9781450352178},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258045},
doi = {10.1145/3258045},
abstract = {Cybersecurity incidents are increasing, and at the same time, our society depends more and more on cyber-physical systems. Systematic approaches to measure cybersecurity are needed in order to support efficient construction and maintenance of secure software systems. Security measurement of software architectures is needed to produce sufficient evidence of security level as early as in the design phase. Design-time security measuring should support "security by design" approach. Moreover, software architectures have to support runtime security measurement to obtain up-to-date security information from an online software system, service or product. Security metrics and measurements are exploited in situational awareness monitoring and self-adaptive security solutions. The area of security metrics and security assurance metrics research is evolving, but still lacks widely accepted metrics definitions and applicable measuring techniques. Strong collaboration between security experts, software architects and system developers is needed to address this. MeSSa2017 workshop addresses these and other related topics to increase the importance of the overall picture, requiring sets of design patterns, measurements, metrics, best practices, and means to integrate this cost-effectively in the overall design and operational profiles.The outcome of the workshop will be an increased shared understanding of challenges and opportunities in systematic approaches to measure cybersecurity, which are needed in order to support efficient construction and maintenance of secure software systems.},
booktitle = {Proceedings of the 11th European Conference on Software Architecture: Companion Proceedings},
location = {Canterbury, United Kingdom},
series = {ECSA '17}
}

@inproceedings{10.1145/3274808.3274823,
author = {Sartakov, Vasily A. and Brenner, Stefan and Ben Mokhtar, Sonia and Bouchenak, Sara and Thomas, Ga\"{e}l and Kapitza, R\"{u}diger},
title = {EActors: Fast and Flexible Trusted Computing Using SGX},
year = {2018},
isbn = {9781450357029},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3274808.3274823},
doi = {10.1145/3274808.3274823},
abstract = {Novel trusted execution support, as offered by Intel's Software Guard eXtensions (SGX), embeds seamlessly into user space applications by establishing regions of encrypted memory, called enclaves. Enclaves comprise code and data that is executed under special protection of the CPU and can only be accessed via an enclave defined interface. To facilitate the usability of this new system abstraction, Intel offers a software development kit (SGX SDK). While the SDK eases the use of SGX, it misses appropriate programming support for inter-enclave interaction, and demands to hardcode the exact use of trusted execution into applications, which restricts flexibility.This paper proposes EActors, an actor framework that is tailored to SGX and offers a more seamless, flexible and efficient use of trusted execution -- especially for applications demanding multiple enclaves. EActors disentangles the interaction with enclaves and, among them, from costly execution mode transitions. It features lightweight fine-grained parallelism based on the concept of actors, thereby avoiding costly SGX SDK provided synchronisation constructs. Finally, EActors offers a high degree of freedom to execute actors, either untrusted or trusted, depending on security requirements and performance demands. We implemented two use cases on top of EActors: (i) a secure instant messaging service, and (ii) a secure multi-party computation service. Both illustrate the ability of EActors to seamlessly and effectively build secure applications. Furthermore, our performance evaluation results show that securing the messaging service with EActors improves performance compared to the vanilla versions of JabberD2 and ejabberd by up to 40x.},
booktitle = {Proceedings of the 19th International Middleware Conference},
pages = {187–200},
numpages = {14},
keywords = {Actors, Intel SGX, Trusted Execution},
location = {Rennes, France},
series = {Middleware '18}
}

@inproceedings{10.1145/3297280.3297473,
author = {Speicher, Patrick and Steinmetz, Marcel and Hoffmann, J\"{o}rg and Backes, Michael and K\"{u}nnemann, Robert},
title = {Towards Automated Network Mitigation Analysis},
year = {2019},
isbn = {9781450359337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297280.3297473},
doi = {10.1145/3297280.3297473},
abstract = {Penetration testing is a well-established practical concept for the identification of potentially exploitable security weaknesses and an important component of a security audit. Providing a holistic security assessment for networks consisting of several hundreds hosts is hardly feasible though without some sort of mechanization. Mitigation, prioritizing counter-measures subject to a given budget, currently lacks a solid theoretical understanding and is hence more art than science. In this work, we propose the first approach for conducting comprehensive what-if analyses in order to reason about mitigation in a conceptually well-founded manner. To evaluate and compare mitigation strategies, we use simulated penetration testing, i.e., automated attack-finding, based on a network model to which a subset of a given set of mitigation actions, e.g., changes to the network topology, system updates, configuration changes etc. is applied. Using Stackelberg planning, we determine optimal combinations that minimize the maximal attacker success (similar to a Stackelberg game), and thus provide a well-founded basis for a holistic mitigation strategy. We show that these Stackelberg planning models can largely be derived from network scan, public vulnerability databases and manual inspection with various degrees of automation and detail, and we simulate mitigation analysis on networks of different size and vulnerability.},
booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
pages = {1971–1978},
numpages = {8},
keywords = {network security, planning, simulated penetration testing},
location = {Limassol, Cyprus},
series = {SAC '19}
}

@inproceedings{10.1145/3297280.3297588,
author = {Zoubi, Obada Al and Awad, Mariette},
title = {Toward a Continuous Authentication System Using a Biologically Inspired Machine Learning Approach: A Case Study},
year = {2019},
isbn = {9781450359337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297280.3297588},
doi = {10.1145/3297280.3297588},
abstract = {Smartphones have recently seen massive growth in usage and become a repository for many types of personal information. The privacy and security are primary concerns for their usage, where there is a need to provide seamless and continuous authentication systems(CASs) for smartphones. We introduce in this work a proof-of-concept design and a case study for using a biologically-inspired and hardware-friendly CAS. Our proposed design adopts a hybrid Liquid State Machine (LSM) approach to perform automatic features extraction and multi-modal fusion scheme for users' interaction. Our work establishes the design concepts for future on-chip and explains why LSM can be a promising approach for fast, adaptive and reliable hardware CASs. The experimental part reveals our proof-of-concept testing results against the golden standard features. Furthermore, The results indicate a promising future for such design and a potential biologically-inspired CASs.},
booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
pages = {1362–1364},
numpages = {3},
keywords = {biologically-inspired computational methods, security, smartphones, continuous authentication, liquid state machine},
location = {Limassol, Cyprus},
series = {SAC '19}
}

@inproceedings{10.1145/3307650.3322216,
author = {Sakalis, Christos and Kaxiras, Stefanos and Ros, Alberto and Jimborean, Alexandra and Sj\"{a}lander, Magnus},
title = {Efficient Invisible Speculative Execution through Selective Delay and Value Prediction},
year = {2019},
isbn = {9781450366694},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307650.3322216},
doi = {10.1145/3307650.3322216},
abstract = {Speculative execution, the base on which modern high-performance general-purpose CPUs are built on, has recently been shown to enable a slew of security attacks. All these attacks are centered around a common set of behaviors: During speculative execution, the architectural state of the system is kept unmodified, until the speculation can be verified. In the event that a misspeculation occurs, then anything that can affect the architectural state is reverted (squashed) and re-executed correctly. However, the same is not true for the microarchitectural state. Normally invisible to the user, changes to the microarchitectural state can be observed through various side-channels, with timing differences caused by the memory hierarchy being one of the most common and easy to exploit. The speculative side-channels can then be exploited to perform attacks that can bypass software and hardware checks in order to leak information. These attacks, out of which the most infamous are perhaps Spectre and Meltdown, have led to a frantic search for solutions.In this work, we present our own solution for reducing the microarchitectural state-changes caused by speculative execution in the memory hierarchy. It is based on the observation that if we only allow accesses that hit in the L1 data cache to proceed, then we can easily hide any microarchitectural changes until after the speculation has been verified. At the same time, we propose to prevent stalls by value predicting the loads that miss in the L1. Value prediction, though speculative, constitutes an invisible form of speculation, not seen outside the core. We evaluate our solution and show that we can prevent observable microarchitectural changes in the memory hierarchy while keeping the performance and energy costs at 11% and 7%, respectively. In comparison, the current state of the art solution, InvisiSpec, incurs a 46% performance loss and a 51% energy increase.},
booktitle = {Proceedings of the 46th International Symposium on Computer Architecture},
pages = {723–735},
numpages = {13},
keywords = {side-channel attacks, speculative execution, caches},
location = {Phoenix, Arizona},
series = {ISCA '19}
}

@inproceedings{10.1145/3320269.3372202,
author = {AlAhmadi, Bushra A. and Mariconti, Enrico and Spolaor, Riccardo and Stringhini, Gianluca and Martinovic, Ivan},
title = {BOTection: Bot Detection by Building Markov Chain Models of Bots Network Behavior},
year = {2020},
isbn = {9781450367509},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3320269.3372202},
doi = {10.1145/3320269.3372202},
abstract = {Botnets continue to be a threat to organizations, thus various machine learning-based botnet detectors have been proposed. However, the capability of such systems in detecting new or unseen botnets is crucial to ensure its robustness against the rapid evolution of botnets. Moreover, it prolongs the effectiveness of the system in detecting bots, avoiding frequent and time-consuming classifier re-training. We present BOTection, a privacy-preserving bot detection system that models the bot network flow behavior as a Markov Chain. The Markov Chain state transitions capture the bots' network behavior using high-level flow features as states, producing content-agnostic and encryption resilient behavioral features. These features are used to train a classifier to first detect flows produced by bots, and then identify their bot families. We evaluate our system on a dataset of over 7M malicious flows from 12 botnet families, showing its capability of detecting bots' network traffic with 99.78% F-measure and classifying it to a malware family with a 99.09% F-measure. Notably, due to the modeling of general bot network behavior by the Markov Chains, BOTection can detect traffic belonging to unseen bot families with an F-measure of 93.03% making it robust against malware evolution.},
booktitle = {Proceedings of the 15th ACM Asia Conference on Computer and Communications Security},
pages = {652–664},
numpages = {13},
keywords = {botnet, malware, malware detection, network security},
location = {Taipei, Taiwan},
series = {ASIA CCS '20}
}

@inproceedings{10.1145/3357223.3365759,
author = {Xu, Charles and Ilyevskiy, Dmitry},
title = {Isopod: An Expressive DSL for Kubernetes Configuration},
year = {2019},
isbn = {9781450369732},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3357223.3365759},
doi = {10.1145/3357223.3365759},
abstract = {Kubernetes is an open-source cluster orchestration system for containerized workloads to reduce idiosyncrasy across cloud vendors [2]. Using Kubernetes, Cruise has built a multi-tenant platform with thousands of cores and tens of terabytes of memory. Such a scale is possible in part thanks to the declarative abstraction of Kubernetes, where desired states are described in YAML manifests [5].However, YAML as a data serialization format is unfit for workload specification. Structured data in YAML are untyped and prone to wrong indents and missing fields. Due to poor meta-programming support, composing YAML with control logic---loops and branches---suffers from YAML fragmentation and indentation tracking (example at bit.ly/yml-hell). Moreover, YAML manifests are often generated by filling a shared template with cluster-specific parameters---the image tag and the replica count might differ in development and production environments. Existing templating tools---Helm [11], Kustomize [9], Kapitan [7] and the likes---assume these parameters are statically known and use CLIs to query dynamic ones, such as secrets stored in HashiCorp Vault [10]. Such scheme is hard to test, since side effects escape through CLIs, and highly depends on the execution environment, since CLI versions vary across machines or might not exist. Not least, YAML manifests describe the eventual state but not how existing workloads will be affected. Blindly applying the manifest---for example, from a stale version of code---can be disastrous and cause unexpected outages.Isopod presents an alternative configuration paradigm by treating Kubernetes objects as first-class citizens. Without intermediate YAML artifacts, Isopod renders Kubernetes objects directly in Protocol Buffers [8], so they are strongly typed and consumed directly by the Kubernetes API. With Isopod, configurations are scripted in Starlark [3], a Python dialect by Google also used by Bazel [1] and Buck [4] build systems. To replace CLI dependencies, Isopod extends Starlark with runtime built-ins to access services and utilities such as Vault, Kubernetes apiserver, Base64 encoder, and UUID generator, etc. Isopod uses a separate runtime for unit tests to mock all built-ins, providing test coverage that was not possible before.Isopod is also hermetic and secure. The common reliance on the kubeconfig file for cluster authentication leaks secrets to disk, a security risk if working from a shared host, such as a cluster node or CICD worker. Instead, Isopod builds Oauth2 tokens [6] to the target cluster using the Identity &amp; Access Management (IAM) service of the cloud vendor. Application secrets are stored in Vault and queried at runtime. Hence, no secrets escape to the disk. In fact, Isopod prohibits disk IO except for loading Starlark modules from other scripts. No external libraries can be loaded unless explicitly implemented as an Isopod built-in. Distributed as a single binary, Isopod is self-contained with all dependencies.Finally, Isopod is extensible. Protobuf packages of Kubernetes API groups added in the future can be loaded in the same way. Because built-ins are modular and pluggable, users can easily implement and register new built-ins with the Isopod runtime to support any Kubernetes vendors. Isopod offers many other features, such as object life cycle management and parallel rollout to multiple clusters, which is impossible if using kubeconfig. In dry-run mode, Isopod displays intended actions from the current code change as a YAML diff against live objects in the cluster to avoid unexpected configuration change.Since the adoption of Isopod, the PaaS team at Cruise has migrated 14 applications and added another 16 without outage or regression, totaling around 10,000 lines of Starlark. The migration results in up to 60% reduction in code size and 80% faster rollout due to code reuse, cluster parallelism, and the removal of YAML intermediaries. All unit tests take less than 10 secs to finish. Isopod is open source at github.com/cruise-automation/isopod.},
booktitle = {Proceedings of the ACM Symposium on Cloud Computing},
pages = {483},
numpages = {1},
keywords = {Configuration Language, Cluster Orchestration},
location = {Santa Cruz, CA, USA},
series = {SoCC '19}
}

@inproceedings{10.1145/337180.337228,
author = {Fielding, Roy T. and Taylor, Richard N.},
title = {Principled Design of the Modern Web Architecture},
year = {2000},
isbn = {1581132069},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/337180.337228},
doi = {10.1145/337180.337228},
abstract = {The World Wide Web has succeeded in large part because its software architecture has been designed to meet the needs of an Internet-scale distributed hypermedia system. The modern Web architecture emphasizes scalability of component interactions, generality of interfaces, independent deployment of components, and intermediary components to reduce interaction latency, enforce security, and encapsulate legacy systems. In this paper, we introduce the Representational State Transfer (REST) architectural style, developed as an abstract model of the Web architecture to guide our redesign and definition of the Hypertext Transfer Protocol and Uniform Resource Identifiers. We describe the software engineering principles guiding REST and the interaction constraints chosen to retain those principles, contrasting them to the constraints of other architectural styles. We then compare the abstract model to the currently deployed Web architecture in order to elicit mismatches between the existing protocols and the applications they are intended to support.},
booktitle = {Proceedings of the 22nd International Conference on Software Engineering},
pages = {407–416},
numpages = {10},
keywords = {WWW, software architectural style, software architecture},
location = {Limerick, Ireland},
series = {ICSE '00}
}

@inproceedings{10.1145/3405755.3406164,
author = {Meng, Linglong and Schaffer, Stefan},
title = {A Reporting Assistant for Railway Security Staff},
year = {2020},
isbn = {9781450375443},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3405755.3406164},
doi = {10.1145/3405755.3406164},
abstract = {In this paper, we introduce RARSS, a reporting assistant for railway security staff. RARSS is a demonstration application with a multi-modal interface based on the Mobile Multimodal Interaction and Rendering (MMIR) framework. The system should support the security staff at railway premises (stations, trains, etc.) in Germany and inform about security relevant information about the travel of football fans or a group of people on their way to a major event. In the application we leverage multi keyword spotting (KWS) for detecting of the actual context and a grammar with specific voice commands to improve the semantic interpretation. The results of friendly user testing showed that the multimodal conversational interface was positively rated according the simplicity and the efficiency to make security reports by the security staff.},
booktitle = {Proceedings of the 2nd Conference on Conversational User Interfaces},
articleno = {39},
numpages = {3},
keywords = {conversational interface, chatbot, mobile multimodal},
location = {Bilbao, Spain},
series = {CUI '20}
}

@inproceedings{10.1145/3445969.3450426,
author = {Shakarami, Mehrnoosh and Sandhu, Ravi},
title = {Role-Based Administration of Role-Based Smart Home IoT},
year = {2021},
isbn = {9781450383196},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3445969.3450426},
doi = {10.1145/3445969.3450426},
abstract = {Using role-based access control (RBAC) to manage RBAC is among RBAC's attractive benefits, contributing to its long-standing dominance in practice. Administrative models facilitate management of (mostly configuration) changes in the underlying operational models. Overall system security is crucially dependent on both the administrative and operational models. In this paper, we develop an RBAC administrative model to manage authorization assignments in the EGRBAC (enhanced generalized role-based access control) operational model for smart home IoT. We design the administrative model based on pairwise disjoint Administrative Units, each of which contains a uniquely assigned administrative role and a set of administrative tasks. Administrative tasks determine the administrative permissions available to manage the operational model assignments. We begin with a model containing a single administrative unit and then extend it to include additional units. Multiple administrative units enable decentralized administration which could be adapted to provide scalability in inherently distributed and large-scale environments beyond smart home, such as smart buildings or smart campuses. We provide formalism of our proposed model and illustrate it by specifying operational and administrative use cases. Although, the model is proposed based on a specific smart home operational model, our approach could be applied to environments with similar dynamics.},
booktitle = {Proceedings of the 2021 ACM Workshop on Secure and Trustworthy Cyber-Physical Systems},
pages = {49–58},
numpages = {10},
keywords = {RBAC administrative model, decentralized administration, smart home},
location = {Virtual Event, USA},
series = {SAT-CPS '21}
}

@inproceedings{10.1145/3452940.3452976,
author = {Jiang, Nan and Song, Baiyue and Chai, Qingxuan and Hu, Linxian and Li, Yansong},
title = {Study on the Influence of Power Grid Operation Mode on Wind Power Consumption in CHP System},
year = {2021},
isbn = {9781450388665},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452940.3452976},
doi = {10.1145/3452940.3452976},
abstract = {With the wind power grid-connected capacity and the amount of curtailment continue to increase, influence factor analysis of wind power consumption becomes more active. Firstly, this paper analyzes the wind power curtailment mechanism affected by power grid operation mode in CHP system. Then, an optimal dispatch model of the CHP system is established. It includes power and heat network security constraints, units' operating states, power network topological changes and the penalty cost of electric &amp; heat load loss. Finally, this paper analyzes the influences of power grid operation mode on wind power consumption by case simulations. Study shows the reason for wind power curtailment is not always single in a dispatch cycle. The CHP unit "thermo-electric coupling" constraints and power network safety constraints may alternately or simultaneously cause wind power curtailment. The unit startup plan and the power network topology all affect the reasons, the periods and the rate of wind power curtailment. In addition, the changes of grid operation mode due to quit equipment in different periods also affect the wind power curtailment rate. Meanwhile, the amount can be reduced by prioritized starting standby units in plant which occurs unit shutdown, and putting in standby transmission lines near the wind farm},
booktitle = {Proceedings of the 3rd International Conference on Information Technologies and Electrical Engineering},
pages = {183–189},
numpages = {7},
keywords = {Grid, Wind power consumption, Cogeneration system},
location = {Changde City, Hunan, China},
series = {ICITEE '20}
}

@inproceedings{10.1145/3453688.3461481,
author = {Guo, Yanan and Zigerelli, Andrew and Zhang, Youtao and Yang, Jun},
title = {IVcache: Defending Cache Side Channel Attacks via Invisible Accesses},
year = {2021},
isbn = {9781450383936},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3453688.3461481},
doi = {10.1145/3453688.3461481},
abstract = {The sharing of last-level cache (LLC) among different CPU cores makes cache vulnerable to side channel attacks. An attacker can get private information about co-running applications (victims) by monitoring their accesses in LLC. Cache side channel attacks can be mitigated by partitioning cache between the victim and attacker. However, previous partition works either make weak assumptions about the attacker's strength or force their security mechanisms and thus overhead to every user on the system, regardless of their security requirement.We argue that offering security protection as a service is a better choice for secure cache design. To achieve this, we propose Invisible-Victim cache (IVcache), a new cache partition design targeting both the original LLC attack and the new variant. IVcache classifies all security domains on the system as protected and unprotected. For LLC accesses from protected domains, IVcache handles cache state changes in a slightly different way to make those accesses invisible to any other security domains. We implement and evaluate IVcache in Gem5. The experimental results show that IVcache can defend against real-world attacks, and that it introduces negligible performance overhead to protected domains and no overhead to unprotected domains.},
booktitle = {Proceedings of the 2021 on Great Lakes Symposium on VLSI},
pages = {403–408},
numpages = {6},
keywords = {side channel, security, cache},
location = {Virtual Event, USA},
series = {GLSVLSI '21}
}

@inproceedings{10.1145/3456126.3456127,
author = {Ikbal Nacer, Mohamed and Prakoonwit, Simant and Prakash, Edmon},
title = {TheCoin: Privacy and Security Considerations within Blockchain Transactions},
year = {2021},
isbn = {9781450389082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3456126.3456127},
doi = {10.1145/3456126.3456127},
abstract = {TheChain is a solution to many problems such as monopoly, heavy state transition, and security vulnerabilities. TheChain solves these problems by introducing the intersection of regions as an incentive before allowing validators to nest a client directory. Intersecting their operating territories forces them to keep a watch over each other. The definition of privacy can take many forms, starting from the right to be forgotten beside being away from public attention. Although the pseudonymity of the user within the network can enhance the user's privacy, several pieces of research have studied the techniques to take advantage of the network structure to identify the users of pseudonyms. Moreover, two models have been used to record the updated exchange of values within the blockchain system, which are the unspent transaction output (UTXO) and the balance model. The UTXO suffers from duplication of information and the balance model suffers from having a single point of entry. This paper introduces TheCoin model that defines the protocol of the exchange of valuable datum within TheChain system. The solution has introduced a novel approach of initiating the transaction from the receiver side by taking advantage of mobile agents empowering a topology hiding to the network. Billing within the platform has been introduced to allow advanced contractual logic to be adopted into the system on the information level. Moreover, traceable fuzziness has been used to eliminate duplication. The paper presents an evaluation of the TheCoin model in terms of system security, block size, and search performance.},
booktitle = {2021 2nd Asia Service Sciences and Software Engineering Conference},
pages = {10–17},
numpages = {8},
location = {Macau, Macao},
series = {ASSE '21}
}

@inproceedings{10.1145/3468264.3468546,
author = {Zhang, Wuqi and Wei, Lili and Li, Shuqing and Liu, Yepang and Cheung, Shing-Chi},
title = {\DH{}Archer: Detecting on-Chain-off-Chain Synchronization Bugs in Decentralized Applications},
year = {2021},
isbn = {9781450385626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468264.3468546},
doi = {10.1145/3468264.3468546},
abstract = {Since the emergence of Ethereum, blockchain-based decentralized applications (DApps) have become increasingly popular and important. To balance the security, performance, and costs, a DApp typically consists of two layers: an on-chain layer to execute transactions and store crucial data on the blockchain and an off-chain layer to interact with users. A DApp needs to synchronize its off-chain layer with the on-chain layer proactively. Otherwise, the inconsistent data in the off-chain layer could mislead users and cause undesirable consequences, e.g., loss of transaction fees. However, transactions sent to the blockchain are not guaranteed to be executed and could even be reversed after execution due to chain reorganization. Such non-determinism in the transaction execution is unique to blockchain. DApp developers may fail to perform the on-chain-off-chain synchronization accurately due to their lack of familiarity with the complex transaction lifecycle. In this work, we investigate the challenges of synchronizing on-chain and off-chain data in Ethereum-based DApps. We present two types of bugs that could result in inconsistencies between the on-chain and off-chain layers. To help detect such on-chain-off-chain synchronization bugs, we introduce a state transition model to guide the testing of DApps and propose two effective oracles to facilitate the automatic identification of bugs. We build the first testing framework, \DH{}Archer, to detect on-chain-off-chain synchronization bugs in DApps. We have evaluated \DH{}Archer on 11 popular real-world DApps. \DH{}Archer achieves high precision (99.3%), recall (87.6%), and accuracy (89.4%) in bug detection and significantly outperforms the baseline methods. It has found 15 real bugs in the 11 DApps. So far, six of the 15 bugs have been confirmed by the developers, and three have been fixed. These promising results demonstrate the usefulness of \DH{}Archer.},
booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {553–565},
numpages = {13},
keywords = {Decentralized applications, DApps, Blockchain, Software testing},
location = {Athens, Greece},
series = {ESEC/FSE 2021}
}

@article{10.1145/3471930,
author = {Rauf, Irum and Petre, Marian and Tun, Thein and Lopez, Tamara and Lunn, Paul and Van Der Linden, Dirk and Towse, John and Sharp, Helen and Levine, Mark and Rashid, Awais and Nuseibeh, Bashar},
title = {The Case for Adaptive Security Interventions},
year = {2021},
issue_date = {January 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {1},
issn = {1049-331X},
url = {https://doi.org/10.1145/3471930},
doi = {10.1145/3471930},
abstract = {Despite the availability of various methods and tools to facilitate secure coding, developers continue to write code that contains common vulnerabilities. It is important to understand why technological advances do not sufficiently facilitate developers in writing secure code. To widen our understanding of developers' behaviour, we considered the complexity of the security decision space of developers using theory from cognitive and social psychology. Our interdisciplinary study reported in this article (1) draws on the psychology literature to provide conceptual underpinnings for three categories of impediments to achieving security goals, (2) reports on an in-depth meta-analysis of existing software security literature that identified a catalogue of factors that influence developers' security decisions, and (3) characterises the landscape of existing security interventions that are available to the developer during coding and identifies gaps. Collectively, these show that different forms of impediments to achieving security goals arise from different contributing factors. Interventions will be more effective where they reflect psychological factors more sensitively and marry technical sophistication, psychological frameworks, and usability. Our analysis suggests “adaptive security interventions” as a solution that responds to the changing security needs of individual developers and a present a proof-of-concept tool to substantiate our suggestion.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {sep},
articleno = {9},
numpages = {52},
keywords = {social psychology, adaptive software engineering, developers, security interventions, security goals, cognitive psychology, Security decisions}
}

@inproceedings{10.1145/3474718.3474726,
author = {Tinnel, Laura and Cochrane, Mike},
title = {Getting to the HART of the Matter: An Evaluation of Real-World Safety System OT/IT Interfaces, Attacks, and Countermeasures},
year = {2021},
isbn = {9781450390651},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474718.3474726},
doi = {10.1145/3474718.3474726},
abstract = {This paper discusses our experience evaluating attack paths and security controls in commonly used, real-world ICS safety system architectures. Specifically, we sought to determine if an SIS-mediated architecture could provide better protection against unauthorized and malicious safety instrument configuration changes than could a MUX-mediated architecture. An assessment question-driven approach was layered on top of standard penetration assessment methods. Test cases were planned around the questions and a sample set of vendor products typically used in the oil and gas sector. Four systems were composed from different product subsets and were assessed using the test cases. We analyzed results from the four assessments to illuminate issues that existed regardless of system composition. Analysis revealed recurring vulnerabilities that exist in all safety systems due to issues in the design of safety instruments and the HART protocol. We found that device-native hardware write-protections provide the best defense, followed by SIS write protections. We concluded that, when using SIS security controls, an SIS-mediated system can protect against unauthorized device reconfigurations better than can a MUX-based system. When SIS security controls are not used, there is no added security benefit. We present lessons learned for ICS stakeholders and for people who are interested in conducting this kind of evaluation.},
booktitle = {Cyber Security Experimentation and Test Workshop},
pages = {27–35},
numpages = {9},
keywords = {safety instruments, safety instrumented system, Industrial control system, HART, cyberattack, countermeasures, security controls, asset management, assessment methodology},
location = {Virtual, CA, USA},
series = {CSET '21}
}

@inproceedings{10.1145/3477113.3487267,
author = {Gerhorst, Luis and Herzog, Benedict and Reif, Stefan and Schr\"{o}der-Preikschat, Wolfgang and H\"{o}nig, Timo},
title = {AnyCall: Fast and Flexible System-Call Aggregation},
year = {2021},
isbn = {9781450387071},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3477113.3487267},
doi = {10.1145/3477113.3487267},
abstract = {Operating systems rely on system calls to allow the controlled communication of isolated processes with the kernel and other processes. Every system call includes a processor mode switch from the unprivileged user mode to the privileged kernel mode. Although processor mode switches are the essential isolation mechanism to guarantee the system's integrity, they induce direct and indirect performance costs as they invalidate parts of the processor state. In recent years, high-performance networks and storage hardware has made the user/kernel transition overhead the bottleneck for IO-heavy applications. To make matters worse, security vulnerabilities in modern processors (e.g., Meltdown) have prompted kernel mitigations that further increase the transition overhead. To decouple system calls from user/kernel transitions we propose AnyCall, which uses an in-kernel compiler to execute safety-checked user bytecode in kernel mode. This allows for very fast system calls interleaved with error checking and processing logic using only a single user/kernel transition. We have implemented AnyCall based on the Linux kernel's extended Berkeley Packet Filter (eBPF) subsystem. Our evaluation demonstrates that system call bursts are up to 55 times faster using AnyCall and that real-world applications can be sped up by 24 % even if only a minimal part of their code is run by AnyCall.},
booktitle = {Proceedings of the 11th Workshop on Programming Languages and Operating Systems},
pages = {1–8},
numpages = {8},
location = {Virtual Event, Germany},
series = {PLOS '21}
}

@inproceedings{10.1145/3485730.3494113,
author = {Zhao, Guangliang and Ben-yosef, Guy and Qiu, Jianwei and Zhao, Yang and Janakaraj, Prabhu and Boppana, Sriram and Schnore, Austars R.},
title = {Person Re-ID Testbed with Multi-Modal Sensors},
year = {2021},
isbn = {9781450390972},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3485730.3494113},
doi = {10.1145/3485730.3494113},
abstract = {Person Re-ID is a challenging problem and is gaining more attention due to demands in security, intelligent system and other applications. Most person Re-ID works are vision-based, such as image, video, or broadly speaking, face recognition-based techniques. Recently, several multi-modal person Re-ID datasets were released, including RGB+IR, RGB+text, RGB+WiFi, which shows the potential of the multi-modal sensor-based person Re-ID approach. However, there are several common issues in public datasets, such as short time duration, lack of appearance change, and limited activities, resulting in un-robust models. For example, vision-based Re-ID models are sensitive to appearance change. In this work, a person Re-ID testbed with multi-modal sensors is created, allowing the collection of sensing modalities including RGB, IR, depth, WiFi, radar, and audio. This novel dataset will cover normal daily office activities with large time span over multi-seasons. Initial analytic results are obtained for evaluating different person Re-ID models, based on small datasets collected in this testbed.},
booktitle = {Proceedings of the 19th ACM Conference on Embedded Networked Sensor Systems},
pages = {526–531},
numpages = {6},
keywords = {Face Recognition, Multi-Modal, Person Re-ID, Computer Vision, Deep Learning, WiFi, Neural Network},
location = {Coimbra, Portugal},
series = {SenSys '21}
}

@article{10.1145/3487292,
author = {Skandylas, Charilaos and Khakpour, Narges and Andersson, Jesper},
title = {AT-DIFC+: Toward Adaptive and Trust-Aware Decentralized Information Flow Control},
year = {2021},
issue_date = {December 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {4},
issn = {1556-4665},
url = {https://doi.org/10.1145/3487292},
doi = {10.1145/3487292},
abstract = {Modern software systems and their corresponding architectures are increasingly decentralized, distributed, and dynamic. As a consequence, decentralized mechanisms are required to ensure security in such architectures. Decentralized Information Flow Control (DIFC) is a mechanism to control information flow in distributed systems. This article presents and discusses several improvements to an adaptive decentralized information flow approach that incorporates trust for decentralized systems to provide security. Adaptive Trust-Aware Decentralized Information Flow (AT-DIFC+) combines decentralized information flow control mechanisms, trust-based methods, and decentralized control architectures to control and enforce information flow in an open, decentralized system. We strengthen our approach against newly discovered attacks and provide additional information about its reconfiguration, decentralized control architectures, and reference implementation. We evaluate the effectiveness and performance of AT-DIFC+ on two case studies and perform additional experiments and to gauge the mitigations’ effectiveness against the identified attacks.},
journal = {ACM Trans. Auton. Adapt. Syst.},
month = {dec},
articleno = {13},
numpages = {35},
keywords = {decentralized information flow control, adaptive trust, Adaptive security, decentralized feedback loop}
}

@inproceedings{10.1145/3488932.3517426,
author = {Li, Ang and Li, Jiawei and Han, Dianqi and Zhang, Yan and Li, Tao and Zhang, Yanchao},
title = {WearRF-CLA: Continuous Location Authentication with Wrist Wearables and UHF RFID},
year = {2022},
isbn = {9781450391405},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3488932.3517426},
doi = {10.1145/3488932.3517426},
abstract = {Continuous location authentication (CLA) seeks to continuously and automatically verify the physical presence of legitimate users in a protected indoor area. CLA can play an important role in contexts where access to electrical or physical resources must be limited to physically present legitimate users. In this paper, we present WearRF-CLA, a novel CLA scheme built upon increasingly popular wrist wearables and UHF RFID systems. WearRF-CLA explores the observation that human daily routines in a protected indoor area comprise a sequence of human-states (e.g., walking and sitting) that follow predictable state transitions. Each legitimate WearRF-CLA user registers his/her RFID tag and also wrist wearable during system enrollment. After the user enters a protected area, WearRF-CLA continuously collects and processes the gyroscope data of the wrist wearable and the phase data of the RFID tag signals to verify three factors to determine the user's physical presence/absence without explicit user involvement: (1) the tag ID as in a traditional RFID authentication system, (2) the validity of the human-state chain, and (3) the continuous coexistence of the paired wrist wearable and RFID tag with the user. The user passes CLA if and only if all three factors can be validated. Extensive user experiments on commodity smartwatches and UHF RFID devices confirm the very high security and low authentication latency of WearRF-CLA.},
booktitle = {Proceedings of the 2022 ACM on Asia Conference on Computer and Communications Security},
pages = {508–520},
numpages = {13},
keywords = {rfid, deep learning, wrist wearables, wireless security, continuous location authentication (cla)},
location = {Nagasaki, Japan},
series = {ASIA CCS '22}
}

@inproceedings{10.1145/3491315.3491327,
author = {Zhilin, Igor V. and Bushnaq, Osama M. and De Masi, Giulia and Natalizio, Enrico and Akyildiz, Ian F.},
title = {A Universal Multimode (Acoustic, Magnetic Induction, Optical, RF) Software Defined Radio Architecture for Underwater Communication},
year = {2022},
isbn = {9781450395625},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491315.3491327},
doi = {10.1145/3491315.3491327},
abstract = {Various underwater communication applications are proposed to maintain different economic, environmental, and security gains. To support the high quality of service (QoS) requirements of the involved communication tasks, one solution is to rely on multi-mode (i.e., acoustic, optical, magnetic induction (MI), and radio frequency (RF)) communication systems. Such a multi-mode communication system can take advantage of the complementary modes’ features, to obtain QoS requirements per transmission flow. However, challenges including high system cost and coordination between different modes need to be addressed. Therefore, in this paper a Universal Underwater Software Defined Radio (UniSDR) architecture is proposed that realizes joint operation of different modes, in order to deal with the latest use cases demands. Detailed description of the UniSDR architecture is presented. Novelty of the architecture provides flexibility, allowing designer to build a radio that includes any set of modes, which can operate jointly by exchanging data, control and synchronization. A numerical evaluation is conducted to assess the performance of the proposed UniSDR architecture. It clearly shows that the utilization of UniSDR allows to decrease the transmission latency and improve energy efficiency, while maintaining the reliability and robustness.},
booktitle = {Proceedings of the 15th International Conference on Underwater Networks &amp; Systems},
articleno = {4},
numpages = {6},
location = {Shenzhen, Guangdong, China},
series = {WUWNet '21}
}

@article{10.1145/3495534,
author = {Kang, Liuwang and Shen, Haiying},
title = {Detection and Mitigation of Sensor and CAN Bus Attacks in Vehicle Anti-Lock Braking Systems},
year = {2022},
issue_date = {January 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {1},
issn = {2378-962X},
url = {https://doi.org/10.1145/3495534},
doi = {10.1145/3495534},
abstract = {For a modern vehicle, if the sensor in a vehicle anti-lock braking system (ABS) or controller area network (CAN) bus is attacked during a brake process, the vehicle will lose driving direction control and the driver’s life will be highly threatened. However, current methods for detecting attacks are not sufficiently accurate, and no method can provide attack mitigation. To ensure vehicle ABS security, we propose an attack detection method to accurately detect both sensor attack (SA) and CAN bus attack in a vehicle ABS, and an attack mitigation strategy to mitigate their negative effects on the vehicle ABS. In our attack detection method, we build a vehicle state space equation that considers the real-time road friction coefficient to predict vehicle states (i.e., wheel speed and longitudinal brake force) with their previous values. Based on sets of historical measured vehicle states, we develop a search algorithm to find out attack changes (vehicle state changes because of attack) by minimizing errors between the predicted vehicle states and the measured vehicle states. In our attack mitigation strategy, attack changes are subtracted from the measured vehicle states to generate correct vehicle states for a vehicle ABS. We conducted the first real SA experiments to show how a magnet affects sensor readings. Our simulation results demonstrate that our attack detection method can detect SA and CAN bus attack more accurately compared with existing methods, and also that our attack mitigation strategy almost eliminates the attack’s effects on a vehicle ABS.},
journal = {ACM Trans. Cyber-Phys. Syst.},
month = {jan},
articleno = {9},
numpages = {24},
keywords = {sensor attack, CAN bus attack, Vehicle ABS, attack detection, attack mitigation}
}

@inproceedings{10.1145/3503161.3548252,
author = {Kumar, Abhishek and Lee, Lik-Hang and Chauhan, Jagmohan and Su, Xiang and Hoque, Mohammad A. and Pirttikangas, Susanna and Tarkoma, Sasu and Hui, Pan},
title = {PassWalk: Spatial Authentication Leveraging Lateral Shift and Gaze on Mobile Headsets},
year = {2022},
isbn = {9781450392037},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503161.3548252},
doi = {10.1145/3503161.3548252},
abstract = {Secure and usable user authentication on mobile headsets is a challenging problem. The miniature-sized touchpad on such devices becomes a hurdle to user interactions that impact usability. However, the most common authentication methods, i.e., the standard QWERTY virtual keyboard or mid-air inputs to enter passwords are highly vulnerable to shoulder surfing attacks. In this paper, we present PassWalk, a keyboard-less authentication system leveraging multi-modal inputs on mobile headsets. PassWalk demonstrates the feasibility of user authentication driven by the user's gaze and lateral shifts (i.e., footsteps) simultaneously. The keyboard-less authentication interface in PassWalk enables users to accomplish highly mobile inputs of graphical passwords, containing digital overlays and physical objects. We conduct an evaluation with 22 recruited participants (15 legitimate users and 7 attackers). Our results show that PassWalk provides high security (only 1.1% observation attacks were successful) with a mean authentication time of 8.028s, which outperforms the commercial method of using the QWERTY virtual keyboard (21.5% successful attacks) and a research prototype LookUnLock (5.5% successful attacks). Additionally, PassWalk entails a significantly smaller workload on the user than the current commercial methods.},
booktitle = {Proceedings of the 30th ACM International Conference on Multimedia},
pages = {952–960},
numpages = {9},
keywords = {AR/VR, mobile headsets, metaverse, authentication, immersive reality},
location = {Lisboa, Portugal},
series = {MM '22}
}

@inproceedings{10.1145/3545948.3545980,
author = {Franzen, Fabian and Holl, Tobias and Andreas, Manuel and Kirsch, Julian and Grossklags, Jens},
title = {Katana: Robust, Automated, Binary-Only Forensic Analysis of Linux Memory Snapshots},
year = {2022},
isbn = {9781450397049},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545948.3545980},
doi = {10.1145/3545948.3545980},
abstract = {The development and research of tools for forensically analyzing Linux memory snapshots have stalled in recent years as they cannot deal with the high degree of configurability and fail to handle security advances like structure layout randomization. Existing tools such as Volatility and Rekall require a pre-generated profile of the operating system, which is not always available, and can be invalidated by the smallest source code or configuration changes in the kernel. In this paper, we create a reference model of the control and data flow of selected representative Linux kernels. Using this model, ABI properties, and Linux’s own runtime information, we apply a configuration- and instruction-set-agnostic structural matching between the reference model and the loaded kernel to obtain enough information to drive all practically relevant forensic analyses. We implemented our approach in Katana 1, and evaluated it against Volatility. Katana is superior where no perfect profile information is available. Furthermore, we show correct functionality on an extensive set of 85 kernels with different configurations and 45 realistic snapshots taken while executing popular Linux distributions or recent versions of Android from version 8.1 to 11. Our approach translates to other CPU architectures in the Internet-of-Things (IoT) device domain such as MIPS and ARM64 as we show by analyzing a TP-Link router and a smart camera. We also successfully generalize to modified Linux kernels such as Android.},
booktitle = {Proceedings of the 25th International Symposium on Research in Attacks, Intrusions and Defenses},
pages = {214–231},
numpages = {18},
keywords = {binary analysis, memory forensics, automated profile generation},
location = {Limassol, Cyprus},
series = {RAID '22}
}

@article{10.1145/3547350,
author = {Almohri, Hussain and Watson, Layne and Evans, David and Billups, Stephen},
title = {Dynamic System Diversification for Securing Cloud-Based IoT Subnetworks},
year = {2022},
issue_date = {June 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {1–2},
issn = {1556-4665},
url = {https://doi.org/10.1145/3547350},
doi = {10.1145/3547350},
abstract = {Remote exploitation attacks use software vulnerabilities to penetrate through a network of Internet of Things (IoT) devices. This work addresses defending against remote exploitation attacks on vulnerable IoT devices. As an attack mitigation strategy, we assume it is not possible to fix all the vulnerabilities and propose to diversify the open-source software used to manage IoT devices. Our approach is to deploy dynamic cloud-based virtual machine proxies for physical IoT devices. Our architecture leverages virtual machine proxies with diverse software configurations to mitigate vulnerable and static software configurations on physical devices. We develop an algorithm for selecting new configurations based on network anomaly detection signals to learn vulnerable software configurations on IoT devices, automatically shifting towards more secure configurations. Cloud-based proxy machines mediate requests between application clients and vulnerable IoT devices, facilitating a dynamic diversification system. We report on simulation experiments to evaluate the dynamic system. Two models of powerful adversaries are introduced and simulated against the diversified defense strategy. Our experiments show that a dynamically diversified IoT architecture can be invulnerable to large classes of attacks that would succeed against a static architecture.},
journal = {ACM Trans. Auton. Adapt. Syst.},
month = {sep},
articleno = {2},
numpages = {23},
keywords = {network security, Diversity, optimization, adaptive security}
}

@inproceedings{10.1145/3558819.3558821,
author = {Niu, Zhi and Dong, Luming and Zhu, Yong},
title = {The Runtime Model Checking Method for Zero Trust Security Policy},
year = {2022},
isbn = {9781450397414},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3558819.3558821},
doi = {10.1145/3558819.3558821},
abstract = {The policy administrator is a zero trust dynamic authority determination component, which is mainly responsible for the management, storage and evaluation of policies. Aiming at the evaluation of the security and effectiveness of the policies in the policy administrator, this paper proposes to introduce the policy model online service verification component in the policy administrator. First, the policy file is formalized into a policy instance logic specification through logical abstraction, and then the policy instance logic specification Perform model check with the policy abstract logic specification developed by the policy designer to realize the pre-check verification of the consistency of the police file. After the completion of the pre-check and verification, the policy will be executed for the policy manager to make a decision on the execution point of the policy. At this time, the system operating state data intercepted by the policy enforcement point and the embedded system's security, compliance, and legal treaty form process specifications are used to perform model post-check to achieve the security and alarm after the implementation of the policy. Through the combination of pre-check and post-check, the evaluation and testing of the policy and effectiveness of the zero-trust security policy are finally realized.},
booktitle = {Proceedings of the 7th International Conference on Cyber Security and Information Engineering},
pages = {8–12},
numpages = {5},
location = {Brisbane, QLD, Australia},
series = {ICCSIE '22}
}

@inproceedings{10.1145/3576914.3587508,
author = {Meza, Andres and Kastner, Ryan},
title = {Automated Generation, Verification, and Ranking of Secure SoC Access Control Policies},
year = {2023},
isbn = {9798400700491},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576914.3587508},
doi = {10.1145/3576914.3587508},
abstract = {Modern System-on-chip (SoC) architectures are a heterogeneous mix of microprocessors, custom accelerators, memories, interfaces, peripherals, and other resources. These resources communicate using complex on-chip interconnect networks that attempt to quickly and efficiently arbitrate memory transactions whose behaviors can vary drastically depending on the current mode of operation and system operating state. Security- and safety-critical applications require access control policies that define how these resources interact to ensure that malicious and unsafe behaviors do not occur. The process of defining and then verifying the security of these access control policies relies heavily on manual effort. This paper describes an automated methodology to generate, verify, and rank secure SoC access control policies. Our methodology targets access control policies for AKER access control systems.},
booktitle = {Proceedings of Cyber-Physical Systems and Internet of Things Week 2023},
pages = {198–202},
numpages = {5},
keywords = {System-on-Chip, Access Control, Security Verification},
location = {San Antonio, TX, USA},
series = {CPS-IoT Week '23}
}

@inproceedings{10.1145/3593856.3595894,
author = {Roitzsch, Michael and Miemietz, Till and Von Elm, Christian and Asmussen, Nils},
title = {Software-Defined CPU Modes},
year = {2023},
isbn = {9798400701955},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593856.3595894},
doi = {10.1145/3593856.3595894},
abstract = {Our CPUs contain a compute instruction set, which regular applications use. But they also feature an intricate underworld of different CPU modes, combined with trap and exception handling to transition between these modes. These mechanisms are manifold and complex, yet the layering and functionality offered by the CPU modes is fixed. We have to take what CPU vendors provide, including potential security problems from unneeded modes. This paper explores the question, whether CPU modes could instead be defined entirely by software. We show how such a design would function and explore the advantages it enables. We believe that pushing all existing modes under a common design umbrella would enforce a cleaner structure and more control over exposed functionality. At the same time, the flexibility of software-defined modes enables interesting new use cases.},
booktitle = {Proceedings of the 19th Workshop on Hot Topics in Operating Systems},
pages = {23–29},
numpages = {7},
keywords = {mode transitions, microcode, processor modes},
location = {Providence, RI, USA},
series = {HOTOS '23}
}

@article{10.1145/3605952,
author = {Johansen, Nicklas S. and K\ae{}r, Lasse B. and Madsen, Andreas L. and Nielsen, Kristian \O{}. and Srba, Ji\v{r}\'{\i} and Tollund, Rasmus G.},
title = {Kaki: Efficient Concurrent Update Synthesis for SDN},
year = {2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {0934-5043},
url = {https://doi.org/10.1145/3605952},
doi = {10.1145/3605952},
abstract = {Modern computer networks based on the software-defined networking (SDN) paradigm are becoming increasingly complex and often require frequent configuration changes in order to react to traffic fluctuations. It is essential that forwarding policies are preserved not only before and after the configuration update but also at any moment during the inherently distributed execution of such an update. We present Kaki, a&nbsp;Petri game based tool for automatic synthesis of switch batches which can be updated in parallel without violating a given (regular) forwarding policy like waypointing or service chaining. Kaki guarantees to find the minimum number of concurrent batches and supports both splittable and nonsplittable flow forwarding. In order to achieve optimal performance, we introduce two novel optimisation techniques based on static analysis: decomposition into independent subproblems and identification of switches that can be collectively updated in the same batch. These techniques considerably improve the performance of our tool Kaki, relying on TAPAAL’s verification engine for Petri games as its backend. Experiments on a large benchmark of real networks from the Internet Topology Zoo database demonstrate that Kaki outperforms the state-of-the-art tools Netstack and FLIP. Kaki computes concurrent update synthesis significantly faster than Netstack and compared to FLIP, it provides shorter (and provably optimal) concurrent update sequences at similar runtimes.},
note = {Just Accepted},
journal = {Form. Asp. Comput.},
month = {jun},
keywords = {software defined networking, computer networks, security policies, concurrent update synthesis}
}

@article{10.1145/514183.514185,
author = {Fielding, Roy T. and Taylor, Richard N.},
title = {Principled Design of the Modern Web Architecture},
year = {2002},
issue_date = {May 2002},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {2},
issn = {1533-5399},
url = {https://doi.org/10.1145/514183.514185},
doi = {10.1145/514183.514185},
abstract = {The World Wide Web has succeeded in large part because its software architecture has been designed to meet the needs of an Internet-scale distributed hypermedia application. The modern Web architecture emphasizes scalability of component interactions, generality of interfaces, independent deployment of components, and intermediary components to reduce interaction latency, enforce security, and encapsulate legacy systems. In this article we introduce the Representational State Transfer (REST) architectural style, developed as an abstract model of the Web architecture and used to guide our redesign and definition of the Hypertext Transfer Protocol and Uniform Resource Identifiers. We describe the software engineering principles guiding REST and the interaction constraints chosen to retain those principles, contrasting them to the constraints of other architectural styles. We then compare the abstract model to the currently deployed Web architecture in order to elicit mismatches between the existing protocols and the applications they are intended to support.},
journal = {ACM Trans. Internet Technol.},
month = {may},
pages = {115–150},
numpages = {36},
keywords = {Network-based applications, World Wide Web, REST}
}

@inproceedings{10.1145/67386.67426,
author = {Martin, Bruce},
title = {Concurrent Programming vs. Concurrency Control: Shared Events or Shared Data},
year = {1988},
isbn = {0897913043},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/67386.67426},
doi = {10.1145/67386.67426},
abstract = {Two views of concurrency in an object system exist. Those pursuing concurrent programming believe that activities in the real world are inherently concurrent and therefore objects are themselves active. Objects engage in shared events by sending and receiving messages. Communicating Sequential Processes [Hoar85a] and Actors [Agha86a] embrace this view. On the other hand, those pursuing models of concurrency control believe that objects are data and that concurrent access to data needs to be controlled by the system according to some correctness notion. Database transactions, atomic objects [Weih84a, Schw84a] and nested objects [Mart88a] embrace this view.Concurrent programming, in our view, places a significant burden on programming. Correct concurrent behavior is specified as combinations of interactions within a potentially large set of concurrent objects. A programmer must verify that the implementations of all the objects never produce undesirable interactions. Correctness of concurrent behavior is left to the programmer.We are pursuing models embracing concurrency control primarily because a programmer is not required to consider concurrency. The operations on an object can be specified in terms of preconditions and postconditions and traditional program verification techniques can be used to verify an operation's implementation. A programmer only considers the serial behavior of an object in isolation; he need not concern himself with how other concurrent activities might affect the object. Correctness of interleavings is left to the system.Serializability is the usual correctness notion for concurrency control algorithms. In transaction terminology, each competing transaction executes a sequence of basic actions. Any interleaving of the actions is correct if it is equivalent to some serial execution of the transaction. Serializability allows a transaction to be programmed in isolation, that is without considering possible interleavings with other transactions. The system may indeed interleave the actions of several transactions but it is up to the system to make the interleaving appear serial.Concurrent programming is apparently more general. A programmer can implement anything, including undesirable interactions like deadlock. The price for this generality is that the programmer must reason about global orderings of events and thus correctness is difficult to show.The traditional transaction model is not general enough for programming shared object systems. For example, several researchers, [Bern87a, Garc87a, Pu88a], have recognized that transactions are too restrictive for long-lived activities. The problem is that the transaction model is too conservative. Only reading and writing a data item at a single layer of abstraction is modeled. Once a read-write, write-read or write-write dependency is established between two transactions, it remains for the life of the transaction and limits further interleavings.Our approach is to discover and explore less restrictive correctness notions that still allow programmers to implement operations on objects in isolation. In [Mart88a] we present two such correctness notions: externally serializable computations and semantically verifiable nonserializable computations. Both correctness notions assume the nested object model. In [Mart87a] we give a nested object solution to the Dining Philosophers' Problem [Dijk71a]. Nested objects incorporate both the semantics of an object and the data abstraction hierarchy of an object.Nested objects form a nested object system. A nested object system is hierarchical; objects exist at different levels of the system. The execution of an operation on an object at level i results in the execution of operations on objects at level i-1. However, only top level objects are viewed externally.A computation at level i is a description of the state change made to level i objects and the return values produced by executing a partially ordered set of operations on level i objects. The computations at each level together form an n-level system computation.Externally serializable computations are n-level system computations in which the top level objects are left in states that could be produced by serial computations. However, lower level objects may be left in states that no serial computation could produce. Because both data abstraction hierarchies and operations semantics are considered in the nested object model, dependencies established between concurrent computations can be systematically ignored. Long-lived computations can execute efficiently if dependencies can later be ignored.Nested objects are more general than other models of concurrency control. Transactions are two-level nested objects that read and write basic data items. Atomic objects are two-level nested objects that perform abstract operations.The 1988 Object Based Concurrent Programming Workshop did not directly address the differences between concurrent programming and concurrency control. Perhaps future workshops can contrast the generality, the applicability, the programmability, the security and the performance implications of models from both concurrent programming and concurrency control.},
booktitle = {Proceedings of the 1988 ACM SIGPLAN Workshop on Object-Based Concurrent Programming},
pages = {142–144},
numpages = {3},
location = {San Diego, California, USA},
series = {OOPSLA/ECOOP '88}
}

@article{10.1145/67387.67426,
author = {Martin, Bruce},
title = {Concurrent Programming vs. Concurrency Control: Shared Events or Shared Data},
year = {1988},
issue_date = {April 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/67387.67426},
doi = {10.1145/67387.67426},
abstract = {Two views of concurrency in an object system exist. Those pursuing concurrent programming believe that activities in the real world are inherently concurrent and therefore objects are themselves active. Objects engage in shared events by sending and receiving messages. Communicating Sequential Processes [Hoar85a] and Actors [Agha86a] embrace this view. On the other hand, those pursuing models of concurrency control believe that objects are data and that concurrent access to data needs to be controlled by the system according to some correctness notion. Database transactions, atomic objects [Weih84a, Schw84a] and nested objects [Mart88a] embrace this view.Concurrent programming, in our view, places a significant burden on programming. Correct concurrent behavior is specified as combinations of interactions within a potentially large set of concurrent objects. A programmer must verify that the implementations of all the objects never produce undesirable interactions. Correctness of concurrent behavior is left to the programmer.We are pursuing models embracing concurrency control primarily because a programmer is not required to consider concurrency. The operations on an object can be specified in terms of preconditions and postconditions and traditional program verification techniques can be used to verify an operation's implementation. A programmer only considers the serial behavior of an object in isolation; he need not concern himself with how other concurrent activities might affect the object. Correctness of interleavings is left to the system.Serializability is the usual correctness notion for concurrency control algorithms. In transaction terminology, each competing transaction executes a sequence of basic actions. Any interleaving of the actions is correct if it is equivalent to some serial execution of the transaction. Serializability allows a transaction to be programmed in isolation, that is without considering possible interleavings with other transactions. The system may indeed interleave the actions of several transactions but it is up to the system to make the interleaving appear serial.Concurrent programming is apparently more general. A programmer can implement anything, including undesirable interactions like deadlock. The price for this generality is that the programmer must reason about global orderings of events and thus correctness is difficult to show.The traditional transaction model is not general enough for programming shared object systems. For example, several researchers, [Bern87a, Garc87a, Pu88a], have recognized that transactions are too restrictive for long-lived activities. The problem is that the transaction model is too conservative. Only reading and writing a data item at a single layer of abstraction is modeled. Once a read-write, write-read or write-write dependency is established between two transactions, it remains for the life of the transaction and limits further interleavings.Our approach is to discover and explore less restrictive correctness notions that still allow programmers to implement operations on objects in isolation. In [Mart88a] we present two such correctness notions: externally serializable computations and semantically verifiable nonserializable computations. Both correctness notions assume the nested object model. In [Mart87a] we give a nested object solution to the Dining Philosophers' Problem [Dijk71a]. Nested objects incorporate both the semantics of an object and the data abstraction hierarchy of an object.Nested objects form a nested object system. A nested object system is hierarchical; objects exist at different levels of the system. The execution of an operation on an object at level i results in the execution of operations on objects at level i-1. However, only top level objects are viewed externally.A computation at level i is a description of the state change made to level i objects and the return values produced by executing a partially ordered set of operations on level i objects. The computations at each level together form an n-level system computation.Externally serializable computations are n-level system computations in which the top level objects are left in states that could be produced by serial computations. However, lower level objects may be left in states that no serial computation could produce. Because both data abstraction hierarchies and operations semantics are considered in the nested object model, dependencies established between concurrent computations can be systematically ignored. Long-lived computations can execute efficiently if dependencies can later be ignored.Nested objects are more general than other models of concurrency control. Transactions are two-level nested objects that read and write basic data items. Atomic objects are two-level nested objects that perform abstract operations.The 1988 Object Based Concurrent Programming Workshop did not directly address the differences between concurrent programming and concurrency control. Perhaps future workshops can contrast the generality, the applicability, the programmability, the security and the performance implications of models from both concurrent programming and concurrency control.},
journal = {SIGPLAN Not.},
month = {sep},
pages = {142–144},
numpages = {3}
}

@article{10.1145/99926.99928,
author = {Benson, Glenn S. and Akyildiz, Ian F. and Appelbe, William F.},
title = {A Formal Protection Model of Security in Centralized, Parallel, and Distributed Systems},
year = {1990},
issue_date = {Aug. 1990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {3},
issn = {0734-2071},
url = {https://doi.org/10.1145/99926.99928},
doi = {10.1145/99926.99928},
abstract = {One way to show that a system is not secure is to demonstrate that a malicious or mistake-prone user or program can break security by causing the system to reach a nonsecure state. A fundamental aspect of a security model is a proof that validates that every state reachable from a secure initial state is secure. A sequential security model assumes that every command that acts as a state transition executes sequentially, while a concurrent security model assumes that multiple commands execute concurrently. This paper presents a security model called the Centralized-Parallel-Distributed model (CPD model) that defines security for logically, or physically centralized, parallel, and distributed systems. The purpose of the CPD model is to define concurrency conditions that guarentee that a concurrent system cannot reach a state in which privileges are configured in a nonsecure manner. As an example, the conditions are used to construct a representation of a distributed system.},
journal = {ACM Trans. Comput. Syst.},
month = {aug},
pages = {183–213},
numpages = {31},
keywords = {concurrency control, distributed system security, protection model, operating system security, access control}
}

@article{10.14778/3574245.3574278,
author = {Xu, Zihuan and Chen, Lei},
title = {L2chain: Towards High-Performance, Confidential and Secure Layer-2 Blockchain Solution for Decentralized Applications},
year = {2022},
issue_date = {December 2022},
publisher = {VLDB Endowment},
volume = {16},
number = {4},
issn = {2150-8097},
url = {https://doi.org/10.14778/3574245.3574278},
doi = {10.14778/3574245.3574278},
abstract = {With the rapid development of blockchain, the concept of decentralized applications (DApps), built upon smart contracts, has attracted much attention in academia and industry. However, significant issues w.r.t. system throughput, transaction confidentiality, and the security guarantee of the DApp transaction execution and order correctness hinder the border adoption of blockchain DApps.To address these issues, we propose L2chain, a novel blockchain framework aiming to scale the system through a layer-2 network where DApps process transactions in the layer-2 network and only the system state digest, acting as the state integrity proof, is maintained on-chain. To achieve high performance, we introduce the split-execute-merge (SEM) transaction processing workflow with the help of the RSA accumulator, allowing DApps to lock and update a part of the state digest in parallel. We also design a witness cache mechanism for DApp executors to reduce the transaction processing latency. To fulfill confidentiality, we leverage the trusted execution environment (TEE) for DApps to execute encrypted transactions off-chain. To ensure transaction execution and order correctness, we propose a two-step execution process for DApps to prevent attacks (i.e., rollback attacks) from subverting the state transition. Extensive experiments have demonstrated that L2chain can achieve 1.5X to 42.2X and 7.1X to 8.9X throughput improvements in permissioned and permissionless settings respectively.},
journal = {Proc. VLDB Endow.},
month = {dec},
pages = {986–999},
numpages = {14}
}

@inproceedings{10.5555/1339264.1339633,
author = {Jean, Evens and Jiao, Yu and Hurson, Ali R. and Potok, Thomas E.},
title = {Boosting-Based Distributed and Adaptive Security-Monitoring through Agent Collaboration},
year = {2007},
isbn = {0769530281},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {The use of mobile agents to support the development of practical applications is limited primarily by the risks to which hosts in the system are subject to. This article introduces a distributed and adaptive security-monitoring framework to decrease such potential threats. The proposed framework is based on a modified version of the popular Boosting algorithm to classify malicious agents based on their execution patterns on current and prior hosts. Having implemented the framework for the Aglet platform, we herein present the results of our experiments showcasing the detection of agent entities in the system with intention deviating from that of their well-behaved counterparts.},
booktitle = {Proceedings of the 2007 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology - Workshops},
pages = {516–520},
numpages = {5},
series = {WI-IATW '07}
}

@article{10.5555/2168874.2168917,
author = {Agarwal, Ravikant and Bilokhatniuk, Sergii},
title = {Android Authentication and Device Administration API},
year = {2012},
issue_date = {May 2012},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {27},
number = {5},
issn = {1937-4771},
abstract = {This paper examines security capabilities of Android open source operating system based on GNU/Linux and components developed by Google. The focus of this paper is analysis of Android screen-locker and login applications. Many default Android applications can be replaced by new applications, which can offer different interface or add new functionality. Screen-locker is an integral part of Android, and while it cannot be replaced directly, there are ways to implement applications to offer same functionality, and possibly more features. Android 2.2 Device Administration API is tightly coupled with the native screen-locker and login mechanism, allowing for development of robust and adaptive security applications and centralized policy management tools. A new screen-locker and authentication app was created using Device Administration API and is discussed in this paper.},
journal = {J. Comput. Sci. Coll.},
month = {may},
pages = {187–195},
numpages = {9}
}

@inproceedings{10.5555/2527218.2527220,
author = {Benard, Vincent and Richard, Philippe and Vanderhaegen, Fr\'{e}d\'{e}ric and Caulier, Patrice},
title = {Contribution to the Characterization and Identification of Human Stability with Regard to Safety: Application to Guided Transport Systems},
year = {2012},
isbn = {9781921770159},
publisher = {Australian Computer Society, Inc.},
address = {AUS},
abstract = {This paper presents an original contribution based on the concept of human stability by identifying the associated risks as part of the safety system assessment. The difficulties to take into account human factors in safety studies are first highlighted and definitions of new ways for the integration of human factors based on the existing concepts of stability and resilience are proposed. Although the stability concept is usually defined around a sustainable equilibrium point that induces a feeling of safety control during normal operation, it appears that the stable behaviour of a human operator can lead to risk in certain situations or contexts such as hypo-vigilance, inattention and so on. The core of this paper lays the foundation of human stability for risks assessment. Here, Human stability is defined as the ability of the operator to stay in a stable operating state under specified conditions. This concept is formalized and 3 modes of stability are developed (time, frequency and sequential modes) in order to identify states and change of states of the human stability. The concept of human stability is then applied in the framework of ERTMS/ETCS and shows that sequences of Human stability states and changes of Human stability states may be precursors of risk. Finally, some perspectives highlight the interest of human stability for the definition of risk indicators to assess system safety, by considering the Human operator as a safety/security multi-criteria sensor for the supervision of human-machine systems.},
booktitle = {Proceedings of the Australian System Safety Conference - Volume 145},
pages = {13–20},
numpages = {8},
keywords = {transportation application, resilience, safety, human stability},
location = {Brisbane, Australia},
series = {ASSC '12}
}

@inproceedings{10.5555/2666759.2666769,
author = {Salehie, Mazeiar and Pasquale, Liliana and Omoronyia, Inah and Nuseibeh, Bashar},
title = {Adaptive Security and Privacy in Smart Grids: A Software Engineering Vision},
year = {2012},
isbn = {9781467318648},
publisher = {IEEE Press},
abstract = {Despite the benefits offered by smart grids, energy producers, distributors and consumers are increasingly concerned about possible security and privacy threats. These threats typically manifest themselves at runtime as new usage scenarios arise and vulnerabilities are discovered. Adaptive security and privacy promise to address these threats by increasing awareness and automating prevention, detection and recovery from security and privacy requirements' failures at runtime by re-configuring system controls and perhaps even changing requirements. This paper discusses the need for adaptive security and privacy in smart grids by presenting some motivating scenarios. We then outline some research issues that arise in engineering adaptive security. We particularly scrutinize published reports by NIST on smart grid security and privacy as the basis for our discussions.},
booktitle = {Proceedings of the First International Workshop on Software Engineering Challenges for the Smart Grid},
pages = {46–49},
numpages = {4},
keywords = {adaptive software, security requirements, smart grid, security and privacy},
location = {Zurich, Switzerland},
series = {SE4SG '12}
}

@inproceedings{10.5555/2666795.2666813,
author = {Yuan, Eric and Malek, Sam},
title = {A Taxonomy and Survey of Self-Protecting Software Systems},
year = {2012},
isbn = {9781467317870},
publisher = {IEEE Press},
abstract = {Self-protecting software systems are a class of autonomic systems capable of detecting and mitigating security threats at runtime. They are growing in importance, as the stovepipe static methods of securing software systems have shown inadequate for the challenges posed by modern software systems. While existing research has made significant progress towards autonomic and adaptive security, gaps and challenges remain. In this paper, we report on an extensive study and analysis of the literature in this area. The crux of our contribution is a comprehensive taxonomy to classify and characterize research efforts in this arena. We also describe our experiences with applying the taxonomy to numerous existing approaches. This has shed light on several challenging issues and resulted in interesting observations that could guide the future research.},
booktitle = {Proceedings of the 7th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
pages = {109–118},
numpages = {10},
keywords = {autonomic systems, taxonomy, adaptive security, self-management, self-protection},
location = {Zurich, Switzerland},
series = {SEAMS '12}
}

@inproceedings{10.5555/2666795.2666821,
author = {Pasquale, Liliana and Salehie, Mazeiar and Ali, Raian and Omoronyia, Inah and Nuseibeh, Bashar},
title = {On the Role of Primary and Secondary Assets in Adaptive Security: An Application in Smart Grids},
year = {2012},
isbn = {9781467317870},
publisher = {IEEE Press},
abstract = {Adaptive security aims to protect valuable assets managed by a system, by applying a varying set of security controls. Engineering adaptive security is not an easy task. A set of effective security countermeasures should be identified. These countermeasures should not only be applied to (primary) assets that customers desire to protect, but also to other (secondary) assets that can be exploited by attackers to harm the primary assets. Another challenge arises when assets vary dynamically at runtime. To accommodate these variabilities, it is necessary to monitor changes in assets, and apply the most appropriate countermeasures at runtime. The paper provides three main contributions for engineering adaptive security. First, it proposes a modeling notation to represent primary and secondary assets, along with their variability. Second, it describes how to use the extended models in engineering security requirements and designing required monitoring functions. Third, the paper illustrates our approach through a set of adaptive security scenarios in the customer domain of a smart grid. We suggest that modeling secondary assets aids the deployment of countermeasures, and, in combination with a representation of assets variability, facilitates the design of monitoring functions.},
booktitle = {Proceedings of the 7th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
pages = {165–170},
numpages = {6},
keywords = {adaptive security, assets, adaptive software, smart grid},
location = {Zurich, Switzerland},
series = {SEAMS '12}
}

@inproceedings{10.5555/2819009.2819150,
author = {Tsigkanos, Christos and Pasquale, Liliana and Ghezzi, Carlo and Nuseibeh, Bashar},
title = {Ariadne: Topology Aware Adaptive Security for Cyber-Physical Systems},
year = {2015},
publisher = {IEEE Press},
abstract = {This paper presents Ariadne, a tool for engineering topology aware adaptive security for cyber-physical systems. It allows security software engineers to model security requirements together with the topology of the operational environment. This model is then used at runtime to perform speculative threat analysis to reason about the consequences that topological changes arising from the movement of agents and assets can have on the satisfaction of security requirements. Our tool also identifies an adaptation strategy that applies security controls when necessary to prevent potential security requirements violations.},
booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 2},
pages = {729–732},
numpages = {4},
location = {Florence, Italy},
series = {ICSE '15}
}

@inproceedings{10.5555/2819009.2819191,
author = {Sartoli, Sara and Namin, Akbar Siami},
title = {Reasoning Based on Imperfect Context Data in Adaptive Security},
year = {2015},
publisher = {IEEE Press},
abstract = {Enabling software systems to adjust their protection in continuously changing environments with imperfect context information is a grand challenging problem. The issue of uncertain reasoning based on imperfect information has been overlooked in traditional logic programming with classical negation when applied to dynamic systems. This paper sketches a non-monotonic approach based on Answer Set Programming to reason with imperfect context data in adaptive security where there is little or no knowledge about certainty of the actions and events.},
booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 2},
pages = {835–836},
numpages = {2},
keywords = {non-monotonic logic, adaptive security, imperfect data},
location = {Florence, Italy},
series = {ICSE '15}
}

@inproceedings{10.5555/3105716.3105717,
author = {Nuseibeh, Bashar},
title = {Crossing Boundaries: On the Inevitable Intertwining of Digital, Physical, and Social Spaces},
year = {2017},
isbn = {9781538640432},
publisher = {IEEE Press},
abstract = {"Having Divided to Conquer We Must Reunite [to] Rule" [3]. Decomposition of problems and systems into smaller, more manageable units has been at the heart of software engineering practice for decades. "Separation of concerns" gives software engineers the conceptual and practical tools to focus their attention, and their tools, on the parts of the problem or solution to which they are best suited. Perhaps one of the earliest boundaries used to separate concerns is that which exists between hardware and software - once that boundary is drawn, software engineers were able to focus their attention on the development of software within the hardware boundaries chosen. There has however, been a steady erosion of such boundaries: digital and physical connectivity have become the norm, and increasingly such connectivity can be ad hoc, spontaneous, and often unplanned (perhaps best exemplified by the Internet of Things paradigm). Moreover, the fluid and disappearing boundaries between technology and people have radically affected social behaviours (again, perhaps well exemplified by the proliferation of mobile and ubiquitous computing such as wearable and 'smart' technologies used in variety of personal and community settings). Such convergence between digital, physical, and social spaces has provided exciting opportunities for software engineers to, literally, 'cross boundaries', and, as a result, to have an impact on the physical and social worlds in which the software they build will operate. But in this brave new world with porous boundaries, security engineering and privacy management challenges abound. Effective security depends on the ability to control access to assets protected by boundaries [2]. Effective privacy management depends on informed, consensual sharing of information across boundaries [4]. Our thesis is that, although increasingly invisible, and rightly so, explicit awareness and sometimes representation of boundaries in cyber-physical-social systems facilitate good old fashioned separation of concerns, which in turn enables more effective software engineering of secure, privacy-aware software [5, 6]. We support our thesis with examples from our research in adaptive security [7] and privacy [1].},
booktitle = {Proceedings of the 3rd International Workshop on Software Engineering for Smart Cyber-Physical Systems},
pages = {2},
numpages = {1},
keywords = {adaptive security and privacy, cyber-physical-social systems},
location = {Buenos Aires, Argentina},
series = {SEsCPS '17}
}

@inproceedings{10.5555/3108760.3108769,
author = {Rao, Aakarsh and Rozenblit, Jerzy and Lysecky, Roman and Sametinger, Johannes},
title = {Composite Risk Modeling for Automated Threat Mitigation in Medical Devices},
year = {2017},
isbn = {9781510838253},
publisher = {Society for Computer Simulation International},
address = {San Diego, CA, USA},
abstract = {Medical device security is a growing concern with increasing incorporation of complex software and hardware. Security threats exploiting vulnerabilities in medical devices may directly impact patient safety. Standardization and federal organizations are hence, actively involved in setting up new paradigms for guidance and regulation of security throughout the lifecycle. To protect medical devices against threats a risk-based framework that continually manages and assesses security risks along with their proactive addressing is highly recommended. In this paper, we model a multi-modal design approach for risk assessment in medical devices and propose an adaptive remediation scheme to mitigate security threats. Our multi-modal approach is integrated into the hardware-software development with a middleware for interaction between the modes. This provides an effective premarket risk management while the adaptive remediation scheme pro-actively mitigate risk during postmarket deployment. We model our approaches in detail and demonstrate them in a pacemaker design model and deployment scenario.},
booktitle = {Proceedings of the Symposium on Modeling and Simulation in Medicine},
articleno = {9},
numpages = {10},
keywords = {security threats, risk management, medical device security, hardware-software design},
location = {Virginia Beach, Virginia},
series = {MSM '17}
}

@inproceedings{10.5555/3213032.3213049,
author = {Rao, Aakarsh and Rozenblit, Jerzy and Lysecky, Roman and Sametinger, Johannes},
title = {Trustworthy Multi-Modal Framework for Life-Critical Systems Security},
year = {2018},
isbn = {9781510860148},
publisher = {Society for Computer Simulation International},
address = {San Diego, CA, USA},
abstract = {With the advent of network connectivity and complex software applications, life-critical systems like medical devices are subject to a plethora of security risks and vulnerabilities. Security threats and attacks exploiting these vulnerabilities have been shown to compromise patient safety by hampering essential functionality. This necessitates incorporating security from the very design of software. Isolation of software functionality into different modes and switching between them based on risk assessment, while maintaining a fail-safe mode ensuring device's essential functionality is a compelling design. Formal modeling is an essential ingredient for verification of such a design. Hence, in this paper, we formally model a trustworthy multi-modal framework for life-critical systems security and in turn safety. We formalize a multiple mode based software design approach of operation with a fail-safe mode that maintains critical functionality. We ensure trustworthyness by formalizing a composite risk model incorporated into the design for run-time risk assessment and management.},
booktitle = {Proceedings of the Annual Simulation Symposium},
articleno = {17},
numpages = {9},
keywords = {multi-modal, risk assessment, formal modeling, life-critical system security},
location = {Baltimore, Maryland},
series = {ANSS '18}
}

@techreport{10.5555/3365136,
author = {Gu, Guofei and Ott, David and Sekar, Vyas and Sun, Kun},
title = {Programmable System Security in a Software-Defined World: Research Challenges and Opportunities},
year = {2018},
publisher = {National Science Foundation},
address = {USA},
abstract = {Recent years have seen a dramatic and rapid paradigm shift in computing from static control systems (often implemented in hardware), to dynamic, easily-reconfigurable, software-defined systems. The researchers and practitioners have just begun to scratch the surface of how the ever-increasing software-defined everything (SD-X) changes the landscape of cybersecurity. On one hand, a software-defined world adds potentially new attack surfaces that deserve new research investigation. On the other hand, considering the fact that everything can be defined by the software, now we can have a new playground to redesign the security mechanisms and services. With programmable security, we can also better embrace the new advances in big data and AI to provide more intelligent and adaptive security for the software-defined world. We believe the opportunity is ripe for academics to make foundational contributions, collaboratively with industry, to shape the next 5 years of research in this new space, SPS (Software-defined Programmable Security). Emerging data centers, cloud networks, IoT and edge computing also provide a fertile playground to consider disruptive software-defined programmable security designs.}
}

