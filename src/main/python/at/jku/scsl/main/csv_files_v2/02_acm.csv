"Item type","Authors","Title","Journal","Publication year","Volume","Issue","Pages","Publisher","Address","Proceedings title","Conference location","Date published","ISBN","ISSN","URLs","DOI","Abstract","Keywords","Notes","Sub-type","Series"
"Journal Article","Chandra S,Khan RA","Availability State Transition Model","SIGSOFT Softw. Eng. Notes","2011","36","3","1–3","Association for Computing Machinery","New York, NY, USA","","","2011-05","","0163-5948","https://doi.org/10.1145/1968587.1968603;http://dx.doi.org/10.1145/1968587.1968603","10.1145/1968587.1968603","Several security mechanisms such as digital signature, timestamp audits and trails, encryption, throttling, filtering, protect secrets etc. are available. These security mechanisms are not completely able to stop malicious attacks. For malicious hackers and attackers it is comparatively easy to exploit security loopholes at the user's end side. Behind such type of problem the main reason is bad software design and its implementation without proper risk analysis and mitigation. So, an idea to model availability states an Availability State Transition Model (ASTM) has been proposed in this article. In ASTM methodology, only design level details is required which can be easily retrieved from the software's design.","security metric, security quantification, software security","","",""
"Conference Paper","Pasquale L,Ghezzi C,Menghi C,Tsigkanos C,Nuseibeh B","Topology Aware Adaptive Security","","2014","","","43–48","Association for Computing Machinery","New York, NY, USA","Proceedings of the 9th International Symposium on Software Engineering for Adaptive and Self-Managing Systems","Hyderabad, India","2014","9781450328647","","https://doi.org/10.1145/2593929.2593939;http://dx.doi.org/10.1145/2593929.2593939","10.1145/2593929.2593939","Adaptive security systems aim to protect valuable assets in the face of changes in their operational environment. They do so by monitoring and analysing this environment, and deploying security functions that satisfy some protection (security, privacy, or forensic) requirements. In this paper, we suggest that a key characteristic for engineering adaptive security is the topology of the operational environment, which represents a physical and/or a digital space - including its structural relationships, such as containment, proximity, and reachability. For adaptive security, topology expresses a rich representation of context that can provide a system with both structural and semantic awareness of important contextual characteristics. These include the location of assets being protected or the proximity of potentially threatening agents that might harm them. Security-related actions, such as the physical movement of an actor from a room to another in a building, may be viewed as topological changes. The detection of a possible undesired topological change (such as an actor possessing a safe’s key entering the room where the safe is located) may lead to the decision to deploy a particular security control to protect the relevant asset. This position paper advocates topology awareness for more effective engineering of adaptive security. By monitoring changes in topology at runtime one can identify new or changing threats and attacks, and deploy adequate security controls accordingly. The paper elaborates on the notion of topology and provides a vision and research agenda on its role for systematically engineering adaptive security systems.","Topology, security, adaptation, digital forensics, privacy","","","SEAMS 2014"
"Conference Paper","Rao A,Rozenblit J,Lysecky R,Sametinger J","Trustworthy Multi-Modal Framework for Life-Critical Systems Security","","2018","","","","Society for Computer Simulation International","San Diego, CA, USA","Proceedings of the Annual Simulation Symposium","Baltimore, Maryland","2018","9781510860148","","","","With the advent of network connectivity and complex software applications, life-critical systems like medical devices are subject to a plethora of security risks and vulnerabilities. Security threats and attacks exploiting these vulnerabilities have been shown to compromise patient safety by hampering essential functionality. This necessitates incorporating security from the very design of software. Isolation of software functionality into different modes and switching between them based on risk assessment, while maintaining a fail-safe mode ensuring device's essential functionality is a compelling design. Formal modeling is an essential ingredient for verification of such a design. Hence, in this paper, we formally model a trustworthy multi-modal framework for life-critical systems security and in turn safety. We formalize a multiple mode based software design approach of operation with a fail-safe mode that maintains critical functionality. We ensure trustworthyness by formalizing a composite risk model incorporated into the design for run-time risk assessment and management.","risk assessment, life-critical system security, multi-modal, formal modeling","","","ANSS '18"
"Conference Paper","Zhao G,Ben-yosef G,Qiu J,Zhao Y,Janakaraj P,Boppana S,Schnore AR","Person Re-ID Testbed with Multi-Modal Sensors","","2021","","","526–531","Association for Computing Machinery","New York, NY, USA","Proceedings of the 19th ACM Conference on Embedded Networked Sensor Systems","Coimbra, Portugal","2021","9781450390972","","https://doi.org/10.1145/3485730.3494113;http://dx.doi.org/10.1145/3485730.3494113","10.1145/3485730.3494113","Person Re-ID is a challenging problem and is gaining more attention due to demands in security, intelligent system and other applications. Most person Re-ID works are vision-based, such as image, video, or broadly speaking, face recognition-based techniques. Recently, several multi-modal person Re-ID datasets were released, including RGB+IR, RGB+text, RGB+WiFi, which shows the potential of the multi-modal sensor-based person Re-ID approach. However, there are several common issues in public datasets, such as short time duration, lack of appearance change, and limited activities, resulting in un-robust models. For example, vision-based Re-ID models are sensitive to appearance change. In this work, a person Re-ID testbed with multi-modal sensors is created, allowing the collection of sensing modalities including RGB, IR, depth, WiFi, radar, and audio. This novel dataset will cover normal daily office activities with large time span over multi-seasons. Initial analytic results are obtained for evaluating different person Re-ID models, based on small datasets collected in this testbed.","Computer Vision, Deep Learning, WiFi, Neural Network, Person Re-ID, Multi-Modal, Face Recognition","","","SenSys '21"
"Conference Paper","Pasquale L","Topology Aware Adaptive Security","","2017","","","2","IEEE Press","Buenos Aires, Argentina","Proceedings of the 4th International Workshop on Software Engineering Research and Industrial Practice","","2017","9781538627976","","https://doi.org/10.1109/SER-IP.2017..21;http://dx.doi.org/10.1109/SER-IP.2017..21","10.1109/SER-IP.2017..21","Cyber-Physical Systems can be harmed through both cyber-enabled or physically-enabled attacks, particularly ones that exploit the often ignored interplay between the cyber and physical spaces characterizing a system operating environment. Awareness of the topology of the operating environment of systems as well as its dynamics can support adaptive security more effectively.In this talk I propose the use of Bigraphical Reactive Systems to represent the topology of cyber and physical spaces. I describe how to use this representation to reason about the consequences of the evolution of topological configurations on the satisfaction of security requirements. I also illustrate a planning technique to identify an adaptation strategy to be used at runtime, to circumvent, prevent, or mitigate security requirements violations previously identified. Finally I will describe how this approach has been integrated into an existing commercial access control software.","","","","SER&IP '17"
"Conference Paper","Evesti A,Abie H,Savola R","Security Measuring for Self-Adaptive Security","","2014","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2014 European Conference on Software Architecture Workshops","Vienna, Austria","2014","9781450327787","","https://doi.org/10.1145/2642803.2642808;http://dx.doi.org/10.1145/2642803.2642808","10.1145/2642803.2642808","Self-adaptive security is needed due to vast amount of changes in an execution environment and threat landscape, which all cannot be anticipated at software design-time. Self-adaptive security requires means for monitoring a security level and decision making capability to improve the current security level. In this paper, we describe how security metrics are able to support self-adaptive security. The paper analyses benefits and challenges of security measuring from the self-adaptive security perspective. Thus, five benefits and three challenges of security metrics in self-adaptive security are described. Furthermore, the paper derives requirements that measuring causes for self-adaptive security. Based on the derived requirements, extension components for the MAPE (Monitor, Analyse, Plan and Execute) reference model are proposed.","architecture, decision-making, security metric, Self-adaptive","","","ECSAW '14"
"Conference Paper","Berhanu Y,Abie H,Hamdi M","A Testbed for Adaptive Security for IoT in EHealth","","2013","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the International Workshop on Adaptive Security","Zurich, Switzerland","2013","9781450325431","","https://doi.org/10.1145/2523501.2523506;http://dx.doi.org/10.1145/2523501.2523506","10.1145/2523501.2523506","Wireless Body Area Sensor Networks (WBASNs) are networks of low-power sensing objects that collect and send vital signs of a patient using low-rate communication media. They have been originally created to improve the efficiency of e-health applications and they constitute now an important part of the Internet of Things (IoT) by bringing humans into the IoTs. The ASSET (Adaptive Security for Smart Internet of Things in eHealth) project [1] develops risk-based adaptive security methods and mechanisms for IoT in eHealth. The project requires a real-life testbed to evaluate accurately the adaptive security solutions in realistic simulation and use case scenarios. This paper describes the setup of a testbed for adaptive security for the IoT using current commercial off-the-shelf products and open source software. The particular features of the proposed testbed with regard to those published in the literature are underlined. The paper also discusses the validation of the setup through the study of the impact of antenna orientation on energy consumption. To this purpose, an estimation strategy of the energy consumption using the Holt-Winters prediction method has been developed. This will particularly be useful when studying the feasibility of the adaptive lightweight security solutions that will be part of the ASSET project.","testbed, adaptive security, IoT, wireless body area sensor networks, eHealth","","","ASPI '13"
"Conference Paper","Sartoli S,Namin AS","Reasoning Based on Imperfect Context Data in Adaptive Security","","2015","","","835–836","IEEE Press","Florence, Italy","Proceedings of the 37th International Conference on Software Engineering - Volume 2","","2015","","","","","Enabling software systems to adjust their protection in continuously changing environments with imperfect context information is a grand challenging problem. The issue of uncertain reasoning based on imperfect information has been overlooked in traditional logic programming with classical negation when applied to dynamic systems. This paper sketches a non-monotonic approach based on Answer Set Programming to reason with imperfect context data in adaptive security where there is little or no knowledge about certainty of the actions and events.","adaptive security, imperfect data, non-monotonic logic","","","ICSE '15"
"Journal Article","Rauf I,Petre M,Tun T,Lopez T,Lunn P,Van Der Linden D,Towse J,Sharp H,Levine M,Rashid A,Nuseibeh B","The Case for Adaptive Security Interventions","ACM Trans. Softw. Eng. Methodol.","2021","31","1","","Association for Computing Machinery","New York, NY, USA","","","2021-09","","1049-331X","https://doi.org/10.1145/3471930;http://dx.doi.org/10.1145/3471930","10.1145/3471930","Despite the availability of various methods and tools to facilitate secure coding, developers continue to write code that contains common vulnerabilities. It is important to understand why technological advances do not sufficiently facilitate developers in writing secure code. To widen our understanding of developers' behaviour, we considered the complexity of the security decision space of developers using theory from cognitive and social psychology. Our interdisciplinary study reported in this article (1) draws on the psychology literature to provide conceptual underpinnings for three categories of impediments to achieving security goals, (2) reports on an in-depth meta-analysis of existing software security literature that identified a catalogue of factors that influence developers' security decisions, and (3) characterises the landscape of existing security interventions that are available to the developer during coding and identifies gaps. Collectively, these show that different forms of impediments to achieving security goals arise from different contributing factors. Interventions will be more effective where they reflect psychological factors more sensitively and marry technical sophistication, psychological frameworks, and usability. Our analysis suggests “adaptive security interventions” as a solution that responds to the changing security needs of individual developers and a present a proof-of-concept tool to substantiate our suggestion.","Security decisions, security interventions, social psychology, adaptive software engineering, developers, security goals, cognitive psychology","","",""
"Conference Paper","Tun TT,Yang M,Bandara AK,Yu Y,Nhlabatsi A,Khan N,Khan KM,Nuseibeh B","Requirements and Specifications for Adaptive Security: Concepts and Analysis","","2018","","","161–171","Association for Computing Machinery","New York, NY, USA","Proceedings of the 13th International Conference on Software Engineering for Adaptive and Self-Managing Systems","Gothenburg, Sweden","2018","9781450357159","","https://doi.org/10.1145/3194133.3194155;http://dx.doi.org/10.1145/3194133.3194155","10.1145/3194133.3194155","In an adaptive security-critical system, security mechanisms change according to the type of threat posed by the environment. Specifying the behavior of these systems is difficult because conditions of the environment are difficult to describe until the system has been deployed and used for a length of time. This paper defines the problem of adaptation in security-critical systems, and outlines the RELAIS approach for expressing requirements and specifying the behavior in a way that helps identify the need for adaptation, and the appropriate adaptation behavior at runtime. The paper introduces the notion of adaptation via input approximation and proposes statistical machine learning techniques for realizing it. The approach is illustrated with a running example and is applied to a realistic security example from a cloud-based file-sharing application. Bayesian classification and logistic regression methods are used to implement adaptive specifications and these methods offer different levels of adaptive security and usability in the file-sharing application.","security requirements, self-adaptation","","","SEAMS '18"
"Conference Paper","Salehie M,Pasquale L,Omoronyia I,Nuseibeh B","Adaptive Security and Privacy in Smart Grids: A Software Engineering Vision","","2012","","","46–49","IEEE Press","Zurich, Switzerland","Proceedings of the First International Workshop on Software Engineering Challenges for the Smart Grid","","2012","9781467318648","","","","Despite the benefits offered by smart grids, energy producers, distributors and consumers are increasingly concerned about possible security and privacy threats. These threats typically manifest themselves at runtime as new usage scenarios arise and vulnerabilities are discovered. Adaptive security and privacy promise to address these threats by increasing awareness and automating prevention, detection and recovery from security and privacy requirements' failures at runtime by re-configuring system controls and perhaps even changing requirements. This paper discusses the need for adaptive security and privacy in smart grids by presenting some motivating scenarios. We then outline some research issues that arise in engineering adaptive security. We particularly scrutinize published reports by NIST on smart grid security and privacy as the basis for our discussions.","adaptive software, security and privacy, smart grid, security requirements","","","SE4SG '12"
"Conference Paper","Pasquale L,Salehie M,Ali R,Omoronyia I,Nuseibeh B","On the Role of Primary and Secondary Assets in Adaptive Security: An Application in Smart Grids","","2012","","","165–170","IEEE Press","Zurich, Switzerland","Proceedings of the 7th International Symposium on Software Engineering for Adaptive and Self-Managing Systems","","2012","9781467317870","","","","Adaptive security aims to protect valuable assets managed by a system, by applying a varying set of security controls. Engineering adaptive security is not an easy task. A set of effective security countermeasures should be identified. These countermeasures should not only be applied to (primary) assets that customers desire to protect, but also to other (secondary) assets that can be exploited by attackers to harm the primary assets. Another challenge arises when assets vary dynamically at runtime. To accommodate these variabilities, it is necessary to monitor changes in assets, and apply the most appropriate countermeasures at runtime. The paper provides three main contributions for engineering adaptive security. First, it proposes a modeling notation to represent primary and secondary assets, along with their variability. Second, it describes how to use the extended models in engineering security requirements and designing required monitoring functions. Third, the paper illustrates our approach through a set of adaptive security scenarios in the customer domain of a smart grid. We suggest that modeling secondary assets aids the deployment of countermeasures, and, in combination with a representation of assets variability, facilitates the design of monitoring functions.","adaptive security, assets, smart grid, adaptive software","","","SEAMS '12"
"Conference Paper","Sartoli S,Namin AS","A Semantic Model for Action-Based Adaptive Security","","2017","","","1130–1135","Association for Computing Machinery","New York, NY, USA","Proceedings of the Symposium on Applied Computing","Marrakech, Morocco","2017","9781450344869","","https://doi.org/10.1145/3019612.3019755;http://dx.doi.org/10.1145/3019612.3019755","10.1145/3019612.3019755","This paper presents a semantic model to represent topology-based security requirements, recommend measures to address any possible security violations, and thus make the underlying systems compliant with its security requirements. The proposed action-based model is capable of adaptively adjusting the topological model of a given system in response to changes in the structure of its operational environment. The proposed framework benefits from non-monotonic reasoning to reason about possible execution paths and hence recommend actions to prevent security requirements violations. The results of our case studies show that using the proposed approach to enforce security measures, not only can we detect possible security violations caused by changes in the structure of operational environment, but also recommend actions to address possible violations.","answer set programming, access control, formal methods, topology awareness, adaptive security","","","SAC '17"
"Conference Paper","Torjusen AB,Abie H,Paintsil E,Trcek D,Skomedal rasmund","Towards Run-Time Verification of Adaptive Security for IoT in EHealth","","2014","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2014 European Conference on Software Architecture Workshops","Vienna, Austria","2014","9781450327787","","https://doi.org/10.1145/2642803.2642807;http://dx.doi.org/10.1145/2642803.2642807","10.1145/2642803.2642807","This paper integrates run-time verification enablers in the feedback adaptation loop of the ASSET adaptive security framework for Internet of Things (IoT) in the eHealth settings and instantiates the resulting framework with Colored Petri Nets. The run-time enablers make machine-readable formal models of a system state and context available at run-time. In addition, they make requirements that define the objectives of verification available at run-time as formal specifications and enable dynamic context monitoring and adaptation. Run-time adaptive behavior that deviates from the normal mode of operation of the system represents a major threat to the sustainability of critical eHealth services. Therefore, the integration of run-time enablers into the ASSET adaptive framework could lead to a sustainable security framework for IoT in eHealth.","IoT, Formal Run-time Verification, eHealth, Adaptive Security","","","ECSAW '14"
"Conference Paper","Blasi L,Savola R,Abie H,Rotondi D","Applicability of Security Metrics for Adaptive Security Management in a Universal Banking Hub System","","2010","","","197–204","Association for Computing Machinery","New York, NY, USA","Proceedings of the Fourth European Conference on Software Architecture: Companion Volume","Copenhagen, Denmark","2010","9781450301794","","https://doi.org/10.1145/1842752.1842792;http://dx.doi.org/10.1145/1842752.1842792","10.1145/1842752.1842792","Banking applications require a high standard of security, resilience and adaptation. The results presented here were obtained from a case study of the deployment of the security metrics-driven adaptive security solutions of a distributed middleware in the context of monetary transfers. The focus of this study is on the analysis of the applicability of security metrics for adaptive authentication, authorization, and end-to-end confidentiality, and the applicability of trust metrics.","security measures, adaptive security, security metrics","","","ECSA '10"
"Conference Paper","Zeitz WA,Fairman B,Zeitz B","The Multi-State Information System: Frontend Processing and Data Security","","1974","","","696–704","Association for Computing Machinery","New York, NY, USA","Proceedings of the 1974 Annual ACM Conference - Volume 2","","1974","9781450378505","","https://doi.org/10.1145/1408800.1408885;http://dx.doi.org/10.1145/1408800.1408885","10.1145/1408800.1408885","The Multi-State Information System (MSIS), a patient oriented, clinical and administrative system designed for use in Psychiatric hospitals and Community Mental Health Centers, is currently in use in twelve states and several countries. The need to protect the confidentiality of the highly sensitive data stored by the users of this system and at the same time provide ease of access to a wide range of non-technical personnel actively engaged in the legitimate use of this data was mandatory. This paper describes the MSIS FRONTEND processing which was designed to accommodate authorized personnel who are not technically sophisticated, and at the same time, deny access to unauthorized personnel by combining the FRONTEND with internal OS and HASP modifications also described.","data security, job control, data management, information processing","","","ACM '74"
"Conference Paper","Chakravarthy SD,Kingsly PI,Sadhasivam M,Jayakumar C","Multi-Modal Biometric Approach to Enable High Security in Mobile Adhoc Network","","2012","","","1148–1154","Association for Computing Machinery","New York, NY, USA","Proceedings of the International Conference on Advances in Computing, Communications and Informatics","Chennai, India","2012","9781450311960","","https://doi.org/10.1145/2345396.2345580;http://dx.doi.org/10.1145/2345396.2345580","10.1145/2345396.2345580","The application of multi-modal biometric methods in securing mobile ad-hoc network has been addressed in this paper. A MANET is an infra structure less network for mobile devices connected by wireless link. The mobile network is often vulnerable to security attacks even though there are many traditional approaches, due to its features of open medium and dynamic changing topology. Multi-modal biometrics is deployed to work with intrusion detection systems (IDSs) to overcome the shortcomings of uni-modal biometric systems. The cluster head is elected in which Dempster-Shafer theory is evaluated in order to increase the observation accuracy to maintain high security and trusted MANET. Since each device in the network has measurement and estimated limitations, more than one device needs to be chosen, and observations can be fused to increase observation accuracy using Dempster--Shafer theory for data fusion.","artificial neural networks, decision tree, IDS- intrusion detection system, MANET- mobile adhoc network, Dempster Shafer theory, naive Bayes","","","ICACCI '12"
"Journal Article","Tziakouris G,Bahsoon R,Babar MA","A Survey on Self-Adaptive Security for Large-Scale Open Environments","ACM Comput. Surv.","2018","51","5","","Association for Computing Machinery","New York, NY, USA","","","2018-10","","0360-0300","https://doi.org/10.1145/3234148;http://dx.doi.org/10.1145/3234148","10.1145/3234148","Contemporary software systems operate in heterogeneous, dynamic, and distributed environments, where security needs change at runtime. The security solutions for such systems need to be adaptive for the continuous satisfaction of the software systems’ security goals. Whilst the existing research on self-adaptive security has made notable advancement towards designing and engineering self-adaptive security solutions, there exists little work on the taxonomic analysis of the architectures of the reported research and its applicability for open and ultra-large environments. We propose an architecture-centric taxonomy for mapping and comparing the current research and identifying the future research directions in this field. The proposed taxonomy has been used to review the representative work on the architectural characteristics that self-adaptive security systems must maintain for their effective application in large-scale open environments. We reflect on the findings from the taxonomic analysis and discuss the design principles, research challenges and limitations reported in the state of the art and practice. We outline the directions for the future research on architectural level support for self-adaptive security systems for large-scale open environments.","ultra-large environments, Self-adaptive systems","","",""
"Conference Paper","Shepherd C,Akram RN,Markantonakis K","Towards Trusted Execution of Multi-Modal Continuous Authentication Schemes","","2017","","","1444–1451","Association for Computing Machinery","New York, NY, USA","Proceedings of the Symposium on Applied Computing","Marrakech, Morocco","2017","9781450344869","","https://doi.org/10.1145/3019612.3019652;http://dx.doi.org/10.1145/3019612.3019652","10.1145/3019612.3019652","The emergence of powerful, sensor-rich devices has led to the development of continuous authentication (CA) schemes using off-the-shelf hardware, where user behaviour is compared to past experience to produce an authentication decision with the aim of addressing challenges with traditional authentication schemes. Current CA proposals, however, have largely neglected adversaries present in a real-world deployment, namely the ubiquity of mal ware and software attacks. This has particular importance when a device cannot be trusted by a third-party, such as a corporation, that controls access to assets based on that decision. A software compromise, either on the scheme implementation or platform, may enable an adversary to modify authentication scores to alter the status of the device in reality, give insights into user behaviour, or gain unauthorised access to restricted assets. Hence, for the first time, we examine two standardised constructs that offer isolated and trusted execution - Secure Elements (SEs) and Trusted Execution Environments (TEEs) - even when an adversary has root-level privileges, and propose measures for providing trusted CA while retaining deployability. Based on these, we implement the first system for evaluating TEE-based CA on a consumer mobile device using Intel SGX, thus providing confidentiality, integrity and trust while removing the main platform from the TCB. We present an empirical evaluation of TEE-and non-TEE performance using methods proposed in related CA schemes. Our results indicate that trusted CA can be provided with no significant performance penalty, and may even offer performance benefits.","trusted execution environments, continuous authentication, mobile security, trusted computing","","","SAC '17"
"Conference Paper","Jean E,Jiao Y,Hurson AR,Potok TE","Boosting-Based Distributed and Adaptive Security-Monitoring through Agent Collaboration","","2007","","","516–520","IEEE Computer Society","USA","Proceedings of the 2007 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology - Workshops","","2007","9780769530284","","","","The use of mobile agents to support the development of practical applications is limited primarily by the risks to which hosts in the system are subject to. This article introduces a distributed and adaptive security-monitoring framework to decrease such potential threats. The proposed framework is based on a modified version of the popular Boosting algorithm to classify malicious agents based on their execution patterns on current and prior hosts. Having implemented the framework for the Aglet platform, we herein present the results of our experiments showcasing the detection of agent entities in the system with intention deviating from that of their well-behaved counterparts.","","","","WI-IATW '07"
"Conference Paper","Saadatmand M,Cicchetti A,Sjödin M","Design of Adaptive Security Mechanisms for Real-Time Embedded Systems","","2012","","","121–134","Springer-Verlag","Berlin, Heidelberg","Proceedings of the 4th International Conference on Engineering Secure Software and Systems","Eindhoven, The Netherlands","2012","9783642281655","","https://doi.org/10.1007/978-3-642-28166-2_12;http://dx.doi.org/10.1007/978-3-642-28166-2_12","10.1007/978-3-642-28166-2_12","Introducing security features in a system is not free and brings along its costs and impacts. Considering this fact is essential in the design of real-time embedded systems which have limited resources. To ensure correct design of these systems, it is important to also take into account impacts of security features on other non-functional requirements, such as performance and energy consumption. Therefore, it is necessary to perform trade-off analysis among non-functional requirements to establish balance among them. In this paper, we target the timing requirements of real-time embedded systems, and introduce an approach for choosing appropriate encryption algorithms at runtime, to achieve satisfaction of timing requirements in an adaptive way, by monitoring and keeping a log of their behaviors. The approach enables the system to adopt a less or more time consuming (but presumably stronger) encryption algorithm, based on the feedback on previous executions of encryption processes. This is particularly important for systems with high degree of complexity which are hard to analyze statistically.","real-time embedded systems, trade-off, runtime adaptation, security","","","ESSoS'12"
"Conference Paper","AbdelRahim S,Ghoneimy S,Selim G","Adaptive Security Scheme for Real-Time VoIP Using Multi-Layer Steganography","","2018","","","106–110","Association for Computing Machinery","New York, NY, USA","Proceedings of the 7th International Conference on Software and Information Engineering","Cairo, Egypt","2018","9781450364690","","https://doi.org/10.1145/3220267.3220281;http://dx.doi.org/10.1145/3220267.3220281","10.1145/3220267.3220281","Nowadays Voice over Internet Protocol (VoIP) is one of the most widely used technologies to transmit the voice. With the widely spreading in such technology many counters attaches tried to apply different counter measure. In this paper we tried to build a counter countermeasure which increases the security of specific messages by performing a complicated three security stages. These stages are; embedding the selected voice into RGB image, hidden the image in voice signal and perform data integrity using real time protocol (RTP). Following such a proposed algorithm, the process of eavesdrop or counter attacks will not be able to break such a multi-layer security process. In this paper, we propose an Adaptive VoIP steganography approach to hide the audio information within images to enhance the security of the voice communications. The proposed system is completely implemented and developed using C++ in OPNET Modeler. Simulation results showed that the proposed system is robust enough to overcome many attacks such as denial of service, man-in-the-middle and eavesdrop without affecting network performance or quality of service.","Steganography, audio security, Least Significant Bit, Voice over Internet Protocol, Real Time Protocol","","","ICSIE '18"
"Conference Paper","Poslad S,Hamdi M,Abie H","Adaptive Security and Privacy Management for the Internet of Things (ASPI 2013)","","2013","","","373–378","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2013 ACM Conference on Pervasive and Ubiquitous Computing Adjunct Publication","Zurich, Switzerland","2013","9781450322157","","https://doi.org/10.1145/2494091.2499770;http://dx.doi.org/10.1145/2494091.2499770","10.1145/2494091.2499770","The Internet of Things (IoT) was initially proposed to connect specific things via the Internet using devices, such as RFID readers, to realise intelligent identification and management. This vision has since expanded to include a more diverse range of devices, services and networks to become an Internet of anything, anywhere, connected, anyhow. Security and privacy management for the IoT remains a core challenge.Many IoT devices maybe may have zero or minimal security by design because they are low resource, low power devices, designed to work as closed vertical services. Security threats and risks may be higher because devices are unattended, use local wireless communication that have no or weak encryption making them more susceptible to eavesdropping and because users find security too unusable to setup and operate and hence leave devices relatively unsecure. It may also be less problematic to reproduce and fake data sources, access nodes and data sinks that interact with IoT devices in order to attack devices or the services they access. Devices can be moved between or removed from private, communal, public and hostile physical spaces. There is a higher risk of a loss of privacy for human users and organisations because of an increased ability to eavesdrop, because of wireless networks with soft boundaries, and because embedded environment devices can sense smaller amounts of physical trails with a greater degree of sensitivity and accuracy. A specific focus is on the need for IoT security to adapt. The adaptation has multiple dimensions. We can adapt existing conventional security models to more effectively secure an IoT. We can adapt security pre-planned and unplanned context changes such as different moving around in different physical spaces. IoT systems can be designed to self-adapt. IoT systems need to adapt to the active (re) configuration and maintenance of IoT devices and systems of devices by users and by artificial agents.The proposed workshop intends to bring together researchers and practitioners from relevant fields to present and disseminate the latest on-going research focussing on adapting security, privacy & management for the Internet of Things. It aims to facilitate knowledge transfer and synergy, bridge gaps between different research communities and groups, to lay down foundation for common purposes, and to help identify opportunities and challenges for interested researchers and technology and system developers.","ubiquitous computing, internet of things, privacy, user centred management, security","","","UbiComp '13 Adjunct"
"Conference Paper","Pasquale L,Menghi C,Salehie M,Cavallaro L,Omoronyia I,Nuseibeh B","SecuriTAS: A Tool for Engineering Adaptive Security","","2012","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the ACM SIGSOFT 20th International Symposium on the Foundations of Software Engineering","Cary, North Carolina","2012","9781450316149","","https://doi.org/10.1145/2393596.2393618;http://dx.doi.org/10.1145/2393596.2393618","10.1145/2393596.2393618","This paper presents SecuriTAS, a tool to engineer adaptive security. It allows software designers to model security concerns together with the requirements of a system. This model is then used at runtime to analyze changes in security concerns and select the best set of security controls necessary to protect the system.","security, dynamic access control, goals, adaptive software","","","FSE '12"
"Conference Paper","Jiang K,Lifa A,Eles P,Peng Z,Jiang W","Energy-Aware Design of Secure Multi-Mode Real-Time Embedded Systems with FPGA Co-Processors","","2013","","","109–118","Association for Computing Machinery","New York, NY, USA","Proceedings of the 21st International Conference on Real-Time Networks and Systems","Sophia Antipolis, France","2013","9781450320580","","https://doi.org/10.1145/2516821.2516830;http://dx.doi.org/10.1145/2516821.2516830","10.1145/2516821.2516830","We approach the emerging area of energy efficient, secure real-time embedded systems design. Many modern embedded systems have to fulfill strict security constraints and are often required to meet stringent deadlines in different operation modes, where the number and nature of active tasks vary (dynamic task sets). In this context, the use of dynamic voltage/frequency scaling (DVFS) techniques and onboard field-programmable gate array (FPGA) co-processors offer new dimensions for energy savings and performance enhancement. We propose a novel design framework that provides the best security protection consuming the minimal energy for all operation modes of a system. Extensive experiments demonstrate the efficiency of our techniques.","","","","RTNS '13"
"Conference Paper","Tsigkanos C,Pasquale L,Ghezzi C,Nuseibeh B","Ariadne: Topology Aware Adaptive Security for Cyber-Physical Systems","","2015","","","729–732","IEEE Press","Florence, Italy","Proceedings of the 37th International Conference on Software Engineering - Volume 2","","2015","","","","","This paper presents Ariadne, a tool for engineering topology aware adaptive security for cyber-physical systems. It allows security software engineers to model security requirements together with the topology of the operational environment. This model is then used at runtime to perform speculative threat analysis to reason about the consequences that topological changes arising from the movement of agents and assets can have on the satisfaction of security requirements. Our tool also identifies an adaptation strategy that applies security controls when necessary to prevent potential security requirements violations.","","","","ICSE '15"
"Conference Paper","Roitzsch M,Miemietz T,Von Elm C,Asmussen N","Software-Defined CPU Modes","","2023","","","23–29","Association for Computing Machinery","New York, NY, USA","Proceedings of the 19th Workshop on Hot Topics in Operating Systems","Providence, RI, USA","2023","","","https://doi.org/10.1145/3593856.3595894;http://dx.doi.org/10.1145/3593856.3595894","10.1145/3593856.3595894","Our CPUs contain a compute instruction set, which regular applications use. But they also feature an intricate underworld of different CPU modes, combined with trap and exception handling to transition between these modes. These mechanisms are manifold and complex, yet the layering and functionality offered by the CPU modes is fixed. We have to take what CPU vendors provide, including potential security problems from unneeded modes. This paper explores the question, whether CPU modes could instead be defined entirely by software. We show how such a design would function and explore the advantages it enables. We believe that pushing all existing modes under a common design umbrella would enforce a cleaner structure and more control over exposed functionality. At the same time, the flexibility of software-defined modes enables interesting new use cases.","microcode, mode transitions, processor modes","","","HOTOS '23"
"Conference Paper","Yuan E,Malek S","A Taxonomy and Survey of Self-Protecting Software Systems","","2012","","","109–118","IEEE Press","Zurich, Switzerland","Proceedings of the 7th International Symposium on Software Engineering for Adaptive and Self-Managing Systems","","2012","9781467317870","","","","Self-protecting software systems are a class of autonomic systems capable of detecting and mitigating security threats at runtime. They are growing in importance, as the stovepipe static methods of securing software systems have shown inadequate for the challenges posed by modern software systems. While existing research has made significant progress towards autonomic and adaptive security, gaps and challenges remain. In this paper, we report on an extensive study and analysis of the literature in this area. The crux of our contribution is a comprehensive taxonomy to classify and characterize research efforts in this arena. We also describe our experiences with applying the taxonomy to numerous existing approaches. This has shed light on several challenging issues and resulted in interesting observations that could guide the future research.","autonomic systems, self-protection, adaptive security, self-management, taxonomy","","","SEAMS '12"
"Journal Article","Yuan E,Esfahani N,Malek S","A Systematic Survey of Self-Protecting Software Systems","ACM Trans. Auton. Adapt. Syst.","2014","8","4","","Association for Computing Machinery","New York, NY, USA","","","2014-01","","1556-4665","https://doi.org/10.1145/2555611;http://dx.doi.org/10.1145/2555611","10.1145/2555611","Self-protecting software systems are a class of autonomic systems capable of detecting and mitigating security threats at runtime. They are growing in importance, as the stovepipe static methods of securing software systems have been shown to be inadequate for the challenges posed by modern software systems. Self-protection, like other self-* properties, allows the system to adapt to the changing environment through autonomic means without much human intervention, and can thereby be responsive, agile, and cost effective. While existing research has made significant progress towards autonomic and adaptive security, gaps and challenges remain. This article presents a significant extension of our preliminary study in this area. In particular, unlike our preliminary study, here we have followed a systematic literature review process, which has broadened the scope of our study and strengthened the validity of our conclusions. By proposing and applying a comprehensive taxonomy to classify and characterize the state-of-the-art research in this area, we have identified key patterns, trends and challenges in the existing approaches, which reveals a number of opportunities that will shape the focus of future research efforts.","self-* properties, autonomic computing, Self-protection, self-adaptive systems, adaptive security","","",""
"Conference Paper","Gerhorst L,Herzog B,Reif S,Schröder-Preikschat W,Hönig T","AnyCall: Fast and Flexible System-Call Aggregation","","2021","","","1–8","Association for Computing Machinery","New York, NY, USA","Proceedings of the 11th Workshop on Programming Languages and Operating Systems","Virtual Event, Germany","2021","9781450387071","","https://doi.org/10.1145/3477113.3487267;http://dx.doi.org/10.1145/3477113.3487267","10.1145/3477113.3487267","Operating systems rely on system calls to allow the controlled communication of isolated processes with the kernel and other processes. Every system call includes a processor mode switch from the unprivileged user mode to the privileged kernel mode. Although processor mode switches are the essential isolation mechanism to guarantee the system's integrity, they induce direct and indirect performance costs as they invalidate parts of the processor state. In recent years, high-performance networks and storage hardware has made the user/kernel transition overhead the bottleneck for IO-heavy applications. To make matters worse, security vulnerabilities in modern processors (e.g., Meltdown) have prompted kernel mitigations that further increase the transition overhead. To decouple system calls from user/kernel transitions we propose AnyCall, which uses an in-kernel compiler to execute safety-checked user bytecode in kernel mode. This allows for very fast system calls interleaved with error checking and processing logic using only a single user/kernel transition. We have implemented AnyCall based on the Linux kernel's extended Berkeley Packet Filter (eBPF) subsystem. Our evaluation demonstrates that system call bursts are up to 55 times faster using AnyCall and that real-world applications can be sped up by 24 % even if only a minimal part of their code is run by AnyCall.","","","","PLOS '21"
"Conference Paper","Giuffrida C,Kuijsten A,Tanenbaum AS","Safe and Automatic Live Update for Operating Systems","","2013","","","279–292","Association for Computing Machinery","New York, NY, USA","Proceedings of the Eighteenth International Conference on Architectural Support for Programming Languages and Operating Systems","Houston, Texas, USA","2013","9781450318709","","https://doi.org/10.1145/2451116.2451147;http://dx.doi.org/10.1145/2451116.2451147","10.1145/2451116.2451147","Increasingly many systems have to run all the time with no downtime allowed. Consider, for example, systems controlling electric power plants and e-banking servers. Nevertheless, security patches and a constant stream of new operating system versions need to be deployed without stopping running programs. These factors naturally lead to a pressing demand for live update---upgrading all or parts of the operating system without rebooting. Unfortunately, existing solutions require significant manual intervention and thus work reliably only for small operating system patches.In this paper, we describe an automated system for live update that can safely and automatically handle major upgrades without rebooting. We have implemented our ideas in Proteos, a new research OS designed with live update in mind. Proteos relies on system support and nonintrusive instrumentation to handle even very complex updates with minimal manual effort. The key novelty is the idea of state quiescence, which allows updates to happen only in safe and predictable system states. A second novelty is the ability to automatically perform transactional live updates at the process level, ensuring a safe and stable update process. Unlike prior solutions, Proteos supports automated state transfer, state checking, and hot rollback. We have evaluated Proteos on 50 real updates and on novel live update scenarios. The results show that our techniques can effectively support both simple and complex updates, while outperforming prior solutions in terms of flexibility, security, reliability, and stability of the update process.","live update, state transfer, update safety, automatic updates, operating systems, state checking","","","ASPLOS '13"
"Journal Article","Giuffrida C,Kuijsten A,Tanenbaum AS","Safe and Automatic Live Update for Operating Systems","SIGARCH Comput. Archit. News","2013","41","1","279–292","Association for Computing Machinery","New York, NY, USA","","","2013-03","","0163-5964","https://doi.org/10.1145/2490301.2451147;http://dx.doi.org/10.1145/2490301.2451147","10.1145/2490301.2451147","Increasingly many systems have to run all the time with no downtime allowed. Consider, for example, systems controlling electric power plants and e-banking servers. Nevertheless, security patches and a constant stream of new operating system versions need to be deployed without stopping running programs. These factors naturally lead to a pressing demand for live update---upgrading all or parts of the operating system without rebooting. Unfortunately, existing solutions require significant manual intervention and thus work reliably only for small operating system patches.In this paper, we describe an automated system for live update that can safely and automatically handle major upgrades without rebooting. We have implemented our ideas in Proteos, a new research OS designed with live update in mind. Proteos relies on system support and nonintrusive instrumentation to handle even very complex updates with minimal manual effort. The key novelty is the idea of state quiescence, which allows updates to happen only in safe and predictable system states. A second novelty is the ability to automatically perform transactional live updates at the process level, ensuring a safe and stable update process. Unlike prior solutions, Proteos supports automated state transfer, state checking, and hot rollback. We have evaluated Proteos on 50 real updates and on novel live update scenarios. The results show that our techniques can effectively support both simple and complex updates, while outperforming prior solutions in terms of flexibility, security, reliability, and stability of the update process.","update safety, state checking, state transfer, automatic updates, live update, operating systems","","",""
"Journal Article","Giuffrida C,Kuijsten A,Tanenbaum AS","Safe and Automatic Live Update for Operating Systems","SIGPLAN Not.","2013","48","4","279–292","Association for Computing Machinery","New York, NY, USA","","","2013-03","","0362-1340","https://doi.org/10.1145/2499368.2451147;http://dx.doi.org/10.1145/2499368.2451147","10.1145/2499368.2451147","Increasingly many systems have to run all the time with no downtime allowed. Consider, for example, systems controlling electric power plants and e-banking servers. Nevertheless, security patches and a constant stream of new operating system versions need to be deployed without stopping running programs. These factors naturally lead to a pressing demand for live update---upgrading all or parts of the operating system without rebooting. Unfortunately, existing solutions require significant manual intervention and thus work reliably only for small operating system patches.In this paper, we describe an automated system for live update that can safely and automatically handle major upgrades without rebooting. We have implemented our ideas in Proteos, a new research OS designed with live update in mind. Proteos relies on system support and nonintrusive instrumentation to handle even very complex updates with minimal manual effort. The key novelty is the idea of state quiescence, which allows updates to happen only in safe and predictable system states. A second novelty is the ability to automatically perform transactional live updates at the process level, ensuring a safe and stable update process. Unlike prior solutions, Proteos supports automated state transfer, state checking, and hot rollback. We have evaluated Proteos on 50 real updates and on novel live update scenarios. The results show that our techniques can effectively support both simple and complex updates, while outperforming prior solutions in terms of flexibility, security, reliability, and stability of the update process.","update safety, automatic updates, state checking, operating systems, live update, state transfer","","",""
"Conference Paper","Fidge CJ,Corney D","Integrating Hardware and Software Information Flow Analyses","","2009","","","157–166","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2009 ACM SIGPLAN/SIGBED Conference on Languages, Compilers, and Tools for Embedded Systems","Dublin, Ireland","2009","9781605583563","","https://doi.org/10.1145/1542452.1542474;http://dx.doi.org/10.1145/1542452.1542474","10.1145/1542452.1542474","Security-critical communications devices must be evaluated to the highest possible standards before they can be deployed. This process includes tracing potential information flow through the device's electronic circuitry, for each of the device's operating modes. Increasingly, however, security functionality is being entrusted to embedded software running on microprocessors within such devices, so new strategies are needed for integrating information flow analyses of embedded program code with hardware analyses. Here we show how standard compiler principles can augment high-integrity security evaluations to allow seamless tracing of information flow through both the hardware and software of embedded systems. This is done by unifying input/output statements in embedded program execution paths with the hardware pins they access, and by associating significant software states with corresponding operating modes of the surrounding electronic circuitry.","communications devices, embedded software, information security evaluation","","","LCTES '09"
"Journal Article","Fidge CJ,Corney D","Integrating Hardware and Software Information Flow Analyses","SIGPLAN Not.","2009","44","7","157–166","Association for Computing Machinery","New York, NY, USA","","","2009-06","","0362-1340","https://doi.org/10.1145/1543136.1542474;http://dx.doi.org/10.1145/1543136.1542474","10.1145/1543136.1542474","Security-critical communications devices must be evaluated to the highest possible standards before they can be deployed. This process includes tracing potential information flow through the device's electronic circuitry, for each of the device's operating modes. Increasingly, however, security functionality is being entrusted to embedded software running on microprocessors within such devices, so new strategies are needed for integrating information flow analyses of embedded program code with hardware analyses. Here we show how standard compiler principles can augment high-integrity security evaluations to allow seamless tracing of information flow through both the hardware and software of embedded systems. This is done by unifying input/output statements in embedded program execution paths with the hardware pins they access, and by associating significant software states with corresponding operating modes of the surrounding electronic circuitry.","information security evaluation, embedded software, communications devices","","",""
"Report","Gu G,Ott D,Sekar V,Sun K","Programmable System Security in a Software-Defined World: Research Challenges and Opportunities","","2018","","","","National Science Foundation","USA","","","2018","","","","","Recent years have seen a dramatic and rapid paradigm shift in computing from static control systems (often implemented in hardware), to dynamic, easily-reconfigurable, software-defined systems. The researchers and practitioners have just begun to scratch the surface of how the ever-increasing software-defined everything (SD-X) changes the landscape of cybersecurity. On one hand, a software-defined world adds potentially new attack surfaces that deserve new research investigation. On the other hand, considering the fact that everything can be defined by the software, now we can have a new playground to redesign the security mechanisms and services. With programmable security, we can also better embrace the new advances in big data and AI to provide more intelligent and adaptive security for the software-defined world. We believe the opportunity is ripe for academics to make foundational contributions, collaboratively with industry, to shape the next 5 years of research in this new space, SPS (Software-defined Programmable Security). Emerging data centers, cloud networks, IoT and edge computing also provide a fertile playground to consider disruptive software-defined programmable security designs.","","","",""
"Journal Article","Almohri H,Watson L,Evans D,Billups S","Dynamic System Diversification for Securing Cloud-Based IoT Subnetworks","ACM Trans. Auton. Adapt. Syst.","2022","17","1–2","","Association for Computing Machinery","New York, NY, USA","","","2022-09","","1556-4665","https://doi.org/10.1145/3547350;http://dx.doi.org/10.1145/3547350","10.1145/3547350","Remote exploitation attacks use software vulnerabilities to penetrate through a network of Internet of Things (IoT) devices. This work addresses defending against remote exploitation attacks on vulnerable IoT devices. As an attack mitigation strategy, we assume it is not possible to fix all the vulnerabilities and propose to diversify the open-source software used to manage IoT devices. Our approach is to deploy dynamic cloud-based virtual machine proxies for physical IoT devices. Our architecture leverages virtual machine proxies with diverse software configurations to mitigate vulnerable and static software configurations on physical devices. We develop an algorithm for selecting new configurations based on network anomaly detection signals to learn vulnerable software configurations on IoT devices, automatically shifting towards more secure configurations. Cloud-based proxy machines mediate requests between application clients and vulnerable IoT devices, facilitating a dynamic diversification system. We report on simulation experiments to evaluate the dynamic system. Two models of powerful adversaries are introduced and simulated against the diversified defense strategy. Our experiments show that a dynamically diversified IoT architecture can be invulnerable to large classes of attacks that would succeed against a static architecture.","network security, Diversity, optimization, adaptive security","","",""
"Conference Paper","Savola RM,Kanstrén T,Evesti A","First International Workshop on Measurability of Security in Software Architectures -- MeSSa 2010","","2010","","","151–154","Association for Computing Machinery","New York, NY, USA","Proceedings of the Fourth European Conference on Software Architecture: Companion Volume","Copenhagen, Denmark","2010","9781450301794","","https://doi.org/10.1145/1842752.1842785;http://dx.doi.org/10.1145/1842752.1842785","10.1145/1842752.1842785","The growing complexity of service-centric systems has increased the need for pertinent and reliable software security and trusted system solutions. Systematic approaches to measuring security in software architectures are needed in order to obtain sufficient and credible proactive evidence of the security level or performance of a system, service or product. The systematic definition of security metrics and security assurance metrics is a young field that still lacks widely accepted definitions of metrics and applicable measuring techniques for design-time and run-time security monitoring. MeSSa 2010 workshop contributes on the following issues:• Security, trust and privacy metrics• Security assurance metrics• Security, trust and privacy measurement systems and associated data gathering• Metrics for adaptive security systems• Taxonomical and ontological research on security metrics• Experimental results from security measurements• Security measurability-increasing mechanisms for software architectures• The relationship and differences between security metrics and security assurance metrics• Trade-off analysis and decision-making at design-time and at run-time.","metrics, trust, assurance, security, assessment, measurement, evaluation, privacy","","","ECSA '10"
"Conference Paper","Montanari M,Campbell RH","Multi-Aspect Security Configuration Assessment","","2009","","","1–6","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2nd ACM Workshop on Assurable and Usable Security Configuration","Chicago, Illinois, USA","2009","9781605587783","","https://doi.org/10.1145/1655062.1655064;http://dx.doi.org/10.1145/1655062.1655064","10.1145/1655062.1655064","Evaluating the security of a computer network system is a challenging task. Configurations of large systems are complex entities in continuous evolution. The installation of new software, a change in the firewall rules, or the discovery of a software vulnerability can be exploited by a malicious user to gain unauthorized control of the integrity, availability and confidentiality of the assets of an organization.This paper presents a framework for building security assessment tools able to perform online verification of the security of a system configuration. Heterogeneous data generated from multiple sources are integrated into a homogeneous RDF representation using domain-specific ontologies and used for assessing the security of a configuration toward known attack vectors. Different vocabularies can be defined to express configurations, policies and attacks for each aspect of the security of an organization (e.g., network security, physical security and application level security) in a modular way. By automatically extracting part of the configuration from the network system, the tool is able to detect in near real-time security threats created by configuration changes.","attack tree, security, network management, security assessment","","","SafeConfig '09"
"Conference Paper","Gasmi Y,Sadeghi AR,Stewin P,Unger M,Asokan N","Beyond Secure Channels","","2007","","","30–40","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2007 ACM Workshop on Scalable Trusted Computing","Alexandria, Virginia, USA","2007","9781595938886","","https://doi.org/10.1145/1314354.1314363;http://dx.doi.org/10.1145/1314354.1314363","10.1145/1314354.1314363","A Trusted Channel is a secure communication channel which is cryptographically bound to the state of the hardware and software configurations of the endpoints. In this paper, we describe secure and flexible mechanisms to establish and maintain Trusted Channels which do not have the deficiencies of previous proposals. We also present a concrete implementation proposal based on Transport Layer Security (TLS) protocol, and Trusted Computing technology. We use Subject Key Attestation Evidence extensions to X.509v3 certificates to convey configuration information during key agreement (TLS handshake). The resulting session key is kept within the Trusted Computing Base, and is updated in a predetermined manner to reflect any detected change in the local configuration. This allows an endpoint to detect changes in the configuration of the peer endpoint while the Trusted Channel is in place, and to decide according to a local policy whether to maintain or tear down the Trusted Channel","hypervisor, trusted computing, relay attack, state changes, trusted channel, TLS, virtualization, microkernel, remote attestation","","","STC '07"
"Conference Paper","Nuseibeh B","Crossing Boundaries: On the Inevitable Intertwining of Digital, Physical, and Social Spaces","","2017","","","2","IEEE Press","Buenos Aires, Argentina","Proceedings of the 3rd International Workshop on Software Engineering for Smart Cyber-Physical Systems","","2017","9781538640432","","","","""Having Divided to Conquer We Must Reunite [to] Rule"" [3]. Decomposition of problems and systems into smaller, more manageable units has been at the heart of software engineering practice for decades. ""Separation of concerns"" gives software engineers the conceptual and practical tools to focus their attention, and their tools, on the parts of the problem or solution to which they are best suited. Perhaps one of the earliest boundaries used to separate concerns is that which exists between hardware and software - once that boundary is drawn, software engineers were able to focus their attention on the development of software within the hardware boundaries chosen. There has however, been a steady erosion of such boundaries: digital and physical connectivity have become the norm, and increasingly such connectivity can be ad hoc, spontaneous, and often unplanned (perhaps best exemplified by the Internet of Things paradigm). Moreover, the fluid and disappearing boundaries between technology and people have radically affected social behaviours (again, perhaps well exemplified by the proliferation of mobile and ubiquitous computing such as wearable and 'smart' technologies used in variety of personal and community settings). Such convergence between digital, physical, and social spaces has provided exciting opportunities for software engineers to, literally, 'cross boundaries', and, as a result, to have an impact on the physical and social worlds in which the software they build will operate. But in this brave new world with porous boundaries, security engineering and privacy management challenges abound. Effective security depends on the ability to control access to assets protected by boundaries [2]. Effective privacy management depends on informed, consensual sharing of information across boundaries [4]. Our thesis is that, although increasingly invisible, and rightly so, explicit awareness and sometimes representation of boundaries in cyber-physical-social systems facilitate good old fashioned separation of concerns, which in turn enables more effective software engineering of secure, privacy-aware software [5, 6]. We support our thesis with examples from our research in adaptive security [7] and privacy [1].","cyber-physical-social systems, adaptive security and privacy","","","SEsCPS '17"
"Conference Paper","Zalewski J,Drager S,McKeever W,Kornecki AJ","Threat Modeling for Security Assessment in Cyberphysical Systems","","2013","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the Eighth Annual Cyber Security and Information Intelligence Research Workshop","Oak Ridge, Tennessee, USA","2013","9781450316873","","https://doi.org/10.1145/2459976.2459987;http://dx.doi.org/10.1145/2459976.2459987","10.1145/2459976.2459987","In this paper, threat modeling issues in cyberphysical systems are discussed. First a generic model of a cyberphysical system is outlined, with an attack surface suitable for security analysis. Then, a case study of network communication in a road vehicle is presented, with its behavior modeled by a discrete time Markov chain, under the assumption that security violations can cause gradual degradation of functionality. Finally, two ways of numerical assessment of vulnerabilities are analyzed, to help better estimate probabilities of state changes in a Markov model.","security, simulation, security assessment, software assurance","","","CSIIRW '13"
"Conference Paper","Brookes S,Taylor S","Rethinking Operating System Design: Asymmetric Multiprocessing for Security and Performance","","2016","","","68–79","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2016 New Security Paradigms Workshop","Granby, Colorado, USA","2016","9781450348133","","https://doi.org/10.1145/3011883.3011886;http://dx.doi.org/10.1145/3011883.3011886","10.1145/3011883.3011886","Developers and academics are constantly seeking to increase the speed and security of operating systems. Unfortunately, an increase in either one often comes at the cost of the other. In this paper, we present an operating system design that challenges a long-held tenet of multicore operating systems in order to produce an alternative architecture that has the potential to deliver both increased security and faster performance. In particular, we propose decoupling the operating system kernel from user processes by running each on completely separate processor cores instead of at different privilege levels within shared cores. Without using the hardware's privilege modes, virtualization and virtual memory contexts enforce the security policies necessary to maintain process isolation and protection. Our new kernel design paradigm offers the opportunity to simultaneously increase both performance and security; utilizing the hardware facilities for inter-core communication in place of those for privilege mode switching offers the opportunity for increased system call performance, while the hard separation between user processes and the kernel provides several strong security properties.","","","","NSPW '16"
"Conference Paper","Libert B,Joye M,Yung M","Born and Raised Distributively: Fully Distributed Non-Interactive Adaptively-Secure Threshold Signatures with Short Shares","","2014","","","303–312","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2014 ACM Symposium on Principles of Distributed Computing","Paris, France","2014","9781450329446","","https://doi.org/10.1145/2611462.2611498;http://dx.doi.org/10.1145/2611462.2611498","10.1145/2611462.2611498","Threshold cryptography is a fundamental distributed computational paradigm for enhancing the availability and the security of cryptographic public-key schemes. It does it by dividing private keys into n shares handed out to distinct servers. In threshold signature schemes, a set of at least t+1 ≤ n servers is needed to produce a valid digital signature. Availability is assured by the fact that any subset of t+1 servers can produce a signature when authorized. At the same time, the scheme should remain robust (in the fault tolerance sense) and unforgeable (cryptographically) against up to t corrupted servers; i.e., it adds quorum control to traditional cryptographic services and introduces redundancy. Originally, most practical threshold signatures have a number of demerits: They have been analyzed in a static corruption model (where the set of corrupted servers is fixed at the very beginning of the attack), they require interaction, they assume a trusted dealer in the key generation phase (so that the system is not fully distributed), or they suffer from certain overheads in terms of storage (large share sizes). In this paper, we construct practical fully distributed (the private key is born distributed), non-interactive schemes --- where the servers can compute their partial signatures without communication with other servers--- with adaptive security (i.e., the adversary corrupts servers dynamically based on its full view of the history of the system). Our schemes are very efficient in terms of computation, communication, and scalable storage (with private key shares of size O(1), where certain solutions incur O(n) storage costs at each server). Unlike other adaptively secure schemes, our schemes are erasure-free (reliable erasure is a hard to assure and hard to administer property in actual systems).To the best of our knowledge, such a fully distributed highly constrained scheme has been an open problem in the area. In particular, and of special interest, is the fact that Pedersen's traditional distributed key generation (DKG) protocol can be safely employed in the initial key generation phase when the system is born -- although it is well-known not to ensure uniformly distributed public keys. An advantage of this is that this protocol only takes one round optimistically (in the absence of faulty player).","distributed key generation, fault tolerance, non-interactivity, erasure-free schemes, adaptive security, threshold signature schemes, fully distributed systems, availability, efficiency","","","PODC '14"
"Conference Paper","Reddy VR,Deshpande P,Pal A","Simultaneous Measurement and Correlation of PPG Signals Taken from Two Different Body Parts for Enhanced Biometric Security via Two-Level Authentication","","2017","","","32–37","Association for Computing Machinery","New York, NY, USA","Proceedings of the 1st ACM Workshop on the Internet of Safe Things","Delft, Netherlands","2017","9781450355452","","https://doi.org/10.1145/3137003.3137004;http://dx.doi.org/10.1145/3137003.3137004","10.1145/3137003.3137004","In this paper we present a novel, multi-mode physiological photoplethysmogram (PPG) signal based biometric security system to be deployed in conjunction with existing face and finger recognition systems for enhanced security. We propose a two-level authentication system and use two PPG signals collected through face and finger of the subject for cross-correlation. PPG signals are generated due to involuntary body processes and therefore cannot be mimicked. Conventional face and finger print recognition is performed as the first-level security clearance. However, both these can be breached by wearing 3D printed finger tips or masking the face by undergoing surgery or 3D printed wearable face masks. Therefore, a second level security based on involuntary PPG signals is employed for enhanced security. This simultaneous measurement of these heart signals and their correlation is used as a biometric criterion for second level authentication and corresponding results are presented in this paper.","Multi-mode biometric, Person authentication via dual heart signal measurements, two level authentication, Enhanced security, Heart signal waveforms or blood flow waveforms correlation, Simultaneous measurement of HR waveforms at two separate body points / parts, Two sources for detecting Heart Rate (HR)","","","SafeThings'17"
"Conference Paper","Meng L,Schaffer S","A Reporting Assistant for Railway Security Staff","","2020","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2nd Conference on Conversational User Interfaces","Bilbao, Spain","2020","9781450375443","","https://doi.org/10.1145/3405755.3406164;http://dx.doi.org/10.1145/3405755.3406164","10.1145/3405755.3406164","In this paper, we introduce RARSS, a reporting assistant for railway security staff. RARSS is a demonstration application with a multi-modal interface based on the Mobile Multimodal Interaction and Rendering (MMIR) framework. The system should support the security staff at railway premises (stations, trains, etc.) in Germany and inform about security relevant information about the travel of football fans or a group of people on their way to a major event. In the application we leverage multi keyword spotting (KWS) for detecting of the actual context and a grammar with specific voice commands to improve the semantic interpretation. The results of friendly user testing showed that the multimodal conversational interface was positively rated according the simplicity and the efficiency to make security reports by the security staff.","conversational interface, mobile multimodal, chatbot","","","CUI '20"
"Conference Paper","Bennaceur A,Bandara AK,Jackson M,Liu W,Montrieux L,Tun TT,Yu Y,Nuseibeh B","Requirements-Driven Mediation for Collaborative Security","","2014","","","37–42","Association for Computing Machinery","New York, NY, USA","Proceedings of the 9th International Symposium on Software Engineering for Adaptive and Self-Managing Systems","Hyderabad, India","2014","9781450328647","","https://doi.org/10.1145/2593929.2593938;http://dx.doi.org/10.1145/2593929.2593938","10.1145/2593929.2593938","Security is concerned with the protection of assets from intentional harm. Secure systems provide capabilities that enable such protection to satisfy some security requirements. In a world increasingly populated with mobile and ubiquitous computing technology, the scope and boundary of security systems can be uncertain and can change. A single functional component, or even multiple components individually, are often insufficient to satisfy complex security requirements on their own. Adaptive security aims to enable systems to vary their protection in the face of changes in their operational environment. Collaborative security, which we propose in this paper, aims to exploit the selection and deployment of multiple, potentially heterogeneous, software-intensive components to collaborate in order to meet security requirements in the face of changes in the environment, changes in assets under protection and their values, and the discovery of new threats and vulnerabilities. However, the components that need to collaborate may not have been designed and implemented to interact with one another collaboratively. To address this, we propose a novel framework for collaborative security that combines adaptive security, collaborative adaptation and an explicit representation of the capabilities of the software components that may be needed in order to achieve collaborative security. We elaborate on each of these framework elements, focusing in particular on the challenges and opportunities afforded by (1) the ability to capture, represent, and reason about the capabilities of different software components and their operational context, and (2) the ability of components to be selected and mediated at runtime in order to satisfy the security requirements. We illustrate our vision through a collaborative robotic implementation, and suggest some areas for future work.","collaborative adaptation, Security requirements, mediation","","","SEAMS 2014"
"Journal Article","Inoue H,Abe T,Ishizaka K,Sakai J,Edahiro M","Dynamic Security Domain Scaling on Embedded Symmetric Multiprocessors","ACM Trans. Des. Autom. Electron. Syst.","2009","14","2","","Association for Computing Machinery","New York, NY, USA","","","2009-04","","1084-4309","https://doi.org/10.1145/1497561.1497567;http://dx.doi.org/10.1145/1497561.1497567","10.1145/1497561.1497567","We propose a method for dynamic security-domain scaling on SMPs that offers both highly scalable performance and high security for future high-end embedded systems. Its most important feature is its highly efficient use of processor resources, accomplished by dynamically changing the number of processors within a security-domain (i.e., dynamically yielding processors to other security-domains) in response to application load requirements. Two new technologies make this scaling possible without any virtualization software: (1) self-transition management and (2) unified virtual address mapping. Evaluations show that this domain control provides highly scalable performance and incurs almost no performance overhead in security-domains. The increase in OSs in binary code size is less than 1.5%, and the time required for individual state transitions is on the order of a single millisecond. This scaling is the first in the world to make possible the dynamic changing of the number of processors within a security-domain on an ARM SMP.","SMP, dynamic security-domain scaling, AMP","","",""
"Conference Paper","Bailey C,Montrieux L,de Lemos R,Yu Y,Wermelinger M","Run-Time Generation, Transformation, and Verification of Access Control Models for Self-Protection","","2014","","","135–144","Association for Computing Machinery","New York, NY, USA","Proceedings of the 9th International Symposium on Software Engineering for Adaptive and Self-Managing Systems","Hyderabad, India","2014","9781450328647","","https://doi.org/10.1145/2593929.2593945;http://dx.doi.org/10.1145/2593929.2593945","10.1145/2593929.2593945","Self-adaptive access control, in which self-* properties are applied to protecting systems, is a promising solution for the handling of malicious user behaviour in complex infrastructures. A major challenge in self-adaptive access control is ensuring that chosen adaptations are valid, and produce a satisfiable model of access. The contribution of this paper is the generation, transformation and verification of Role Based Access Control (RBAC) models at run-time, as a means for providing assurances that the adaptations to be deployed are valid. The goal is to protect the system against insider threats by adapting at run-time the access control policies associated with system resources, and access rights assigned to users. Depending on the type of attack, and based on the models from the target system and its environment, the adapted access control models need to be evaluated against the RBAC metamodel, and the adaptation constraints related to the application. The feasibility of the proposed approach has been demonstrated in the context of a fully working prototype using malicious scenarios inspired by a well documented case of insider attack.","rbac, self-adaptation, model verification, adaptive security","","","SEAMS 2014"
"Conference Paper","Mondal S,Sural S,Atluri V","Towards Formal Security Analysis of GTRBAC Using Timed Automata","","2009","","","33–42","Association for Computing Machinery","New York, NY, USA","Proceedings of the 14th ACM Symposium on Access Control Models and Technologies","Stresa, Italy","2009","9781605585376","","https://doi.org/10.1145/1542207.1542214;http://dx.doi.org/10.1145/1542207.1542214","10.1145/1542207.1542214","An access control system is often viewed as a state transition system. Given a set of access control policies, a general safety requirement in such a system is to determine whether a desirable property is satisfied in all the reachable states. Such an analysis calls for formal verification. While formal analysis on traditional RBAC has been done to some extent, the extensions of RBAC lack such an analysis. In this paper, we propose a formal technique to perform security analysis on the Generalized Temporal RBAC (GTRBAC) model which can be used to express a wide range of temporal constraints on different RBAC components like role, user and permission. In the proposed approach, at first the GTRBAC system is mapped to a state transition system built using timed automata. Characteristics of each role, user and permission are captured with the help of timed automata. A single global clock is used to express the various temporal constraints supported in a GTRBAC model. Next, a set of safety and liveness properties is specified using computation tree logic (CTL). Model checking based formal verification is then done to verify the properties against the model to determine if the system is secure with respect to a given set of access control policies. Both time and space analysis has been done for studying the performance of the approach under different configurations.","model checking, security analysis, ctl, GTRBAC, timed automata","","","SACMAT '09"
"Conference Paper","Zoubi OA,Awad M","Toward a Continuous Authentication System Using a Biologically Inspired Machine Learning Approach: A Case Study","","2019","","","1362–1364","Association for Computing Machinery","New York, NY, USA","Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing","Limassol, Cyprus","2019","9781450359337","","https://doi.org/10.1145/3297280.3297588;http://dx.doi.org/10.1145/3297280.3297588","10.1145/3297280.3297588","Smartphones have recently seen massive growth in usage and become a repository for many types of personal information. The privacy and security are primary concerns for their usage, where there is a need to provide seamless and continuous authentication systems(CASs) for smartphones. We introduce in this work a proof-of-concept design and a case study for using a biologically-inspired and hardware-friendly CAS. Our proposed design adopts a hybrid Liquid State Machine (LSM) approach to perform automatic features extraction and multi-modal fusion scheme for users' interaction. Our work establishes the design concepts for future on-chip and explains why LSM can be a promising approach for fast, adaptive and reliable hardware CASs. The experimental part reveals our proof-of-concept testing results against the golden standard features. Furthermore, The results indicate a promising future for such design and a potential biologically-inspired CASs.","security, continuous authentication, smartphones, liquid state machine, biologically-inspired computational methods","","","SAC '19"
"Conference Paper","Rao A,Rozenblit J,Lysecky R,Sametinger J","Composite Risk Modeling for Automated Threat Mitigation in Medical Devices","","2017","","","","Society for Computer Simulation International","San Diego, CA, USA","Proceedings of the Symposium on Modeling and Simulation in Medicine","Virginia Beach, Virginia","2017","9781510838253","","","","Medical device security is a growing concern with increasing incorporation of complex software and hardware. Security threats exploiting vulnerabilities in medical devices may directly impact patient safety. Standardization and federal organizations are hence, actively involved in setting up new paradigms for guidance and regulation of security throughout the lifecycle. To protect medical devices against threats a risk-based framework that continually manages and assesses security risks along with their proactive addressing is highly recommended. In this paper, we model a multi-modal design approach for risk assessment in medical devices and propose an adaptive remediation scheme to mitigate security threats. Our multi-modal approach is integrated into the hardware-software development with a middleware for interaction between the modes. This provides an effective premarket risk management while the adaptive remediation scheme pro-actively mitigate risk during postmarket deployment. We model our approaches in detail and demonstrate them in a pacemaker design model and deployment scenario.","security threats, hardware-software design, risk management, medical device security","","","MSM '17"
"Conference Paper","Savola R,Abie H,Kanstrén T","Session Details: Fourth International Workshop on Measurability of Security in Software Architectures (MeSSa 2017)","","2017","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 11th European Conference on Software Architecture: Companion Proceedings","Canterbury, United Kingdom","2017","9781450352178","","https://doi.org/10.1145/3258045;http://dx.doi.org/10.1145/3258045","10.1145/3258045","Cybersecurity incidents are increasing, and at the same time, our society depends more and more on cyber-physical systems. Systematic approaches to measure cybersecurity are needed in order to support efficient construction and maintenance of secure software systems. Security measurement of software architectures is needed to produce sufficient evidence of security level as early as in the design phase. Design-time security measuring should support ""security by design"" approach. Moreover, software architectures have to support runtime security measurement to obtain up-to-date security information from an online software system, service or product. Security metrics and measurements are exploited in situational awareness monitoring and self-adaptive security solutions. The area of security metrics and security assurance metrics research is evolving, but still lacks widely accepted metrics definitions and applicable measuring techniques. Strong collaboration between security experts, software architects and system developers is needed to address this. MeSSa2017 workshop addresses these and other related topics to increase the importance of the overall picture, requiring sets of design patterns, measurements, metrics, best practices, and means to integrate this cost-effectively in the overall design and operational profiles.The outcome of the workshop will be an increased shared understanding of challenges and opportunities in systematic approaches to measure cybersecurity, which are needed in order to support efficient construction and maintenance of secure software systems.","","","","ECSA '17"
"Conference Paper","Inoue H,Ikeno A,Abe T,Sakai J,Edahiro M","Dynamic Security Domain Scaling on Symmetric Multiprocessors for Future High-End Embedded Systems","","2007","","","39–44","Association for Computing Machinery","New York, NY, USA","Proceedings of the 5th IEEE/ACM International Conference on Hardware/Software Codesign and System Synthesis","Salzburg, Austria","2007","9781595938244","","https://doi.org/10.1145/1289816.1289830;http://dx.doi.org/10.1145/1289816.1289830","10.1145/1289816.1289830","We propose a method for dynamic security domain scaling on SMPs that offers both highly scalable performance and high security for future high-end embedded systems. Its most important feature is its highly efficient use of processor resources, accomplished by dynamically changing the number of processors within a security domain in response to application load requirements. Two new technologies make this scaling possible without any virtualization software: 1) self-transition management and 2) unified virtual address mapping. Evaluations show that this domain control provides highly scalable performance and incurs almost no performance overhead in security domains. The increase in binary code size is less than 40KB, and the time required for individual state transitions is of a single-millisecond order. This scaling is the first in the world to make possible dynamic changing of the number of processors within a security domain on an ARM SMP.","AMP, SMP, dynamic security domain scaling","","","CODES+ISSS '07"
"Conference Paper","Masoumzadeh A","Security Analysis of Relationship-Based Access Control Policies","","2018","","","186–195","Association for Computing Machinery","New York, NY, USA","Proceedings of the Eighth ACM Conference on Data and Application Security and Privacy","Tempe, AZ, USA","2018","9781450356329","","https://doi.org/10.1145/3176258.3176323;http://dx.doi.org/10.1145/3176258.3176323","10.1145/3176258.3176323","Relationship-based access control (ReBAC) policies can express intricate protection requirements in terms of relationships among users and resources (which can be modeled as a graph). Such policies are useful in domains beyond online social networks. However, given the updating graph of user and resources in a system and expressive conditions in access control policy rules, it can be very challenging for security administrators to envision what can (or cannot) happen as the protection system evolves.In this paper, we introduce the security analysis problem for this class of policies, where we seek to answer security queries about future states of the system graph and authorizations that are decided accordingly. Towards achieving this goal, we propose a state-transition model of a ReBAC protection system, called RePM. We discuss about formulation of security analysis queries in RePM and present our initial results for a limited version of this model.","safety, relationship-based access control, security analysis","","","CODASPY '18"
"Journal Article","Skandylas C,Khakpour N,Andersson J","AT-DIFC+: Toward Adaptive and Trust-Aware Decentralized Information Flow Control","ACM Trans. Auton. Adapt. Syst.","2021","15","4","","Association for Computing Machinery","New York, NY, USA","","","2021-12","","1556-4665","https://doi.org/10.1145/3487292;http://dx.doi.org/10.1145/3487292","10.1145/3487292","Modern software systems and their corresponding architectures are increasingly decentralized, distributed, and dynamic. As a consequence, decentralized mechanisms are required to ensure security in such architectures. Decentralized Information Flow Control (DIFC) is a mechanism to control information flow in distributed systems. This article presents and discusses several improvements to an adaptive decentralized information flow approach that incorporates trust for decentralized systems to provide security. Adaptive Trust-Aware Decentralized Information Flow (AT-DIFC+) combines decentralized information flow control mechanisms, trust-based methods, and decentralized control architectures to control and enforce information flow in an open, decentralized system. We strengthen our approach against newly discovered attacks and provide additional information about its reconfiguration, decentralized control architectures, and reference implementation. We evaluate the effectiveness and performance of AT-DIFC+ on two case studies and perform additional experiments and to gauge the mitigations’ effectiveness against the identified attacks.","decentralized feedback loop, decentralized information flow control, Adaptive security, adaptive trust","","",""
"Conference Paper","Conklin A","The Use of a Collegiate Cyber Defense Competition in Information Security Education","","2005","","","16–18","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2nd Annual Conference on Information Security Curriculum Development","Kennesaw, Georgia","2005","9781595932617","","https://doi.org/10.1145/1107622.1107627;http://dx.doi.org/10.1145/1107622.1107627","10.1145/1107622.1107627","A Collegiate Cyber Defense Competition was conducted this spring with five universities fielding teams. This event was designed to provide student led teams a simulated operational business environment in which they could test their skills at information security and system operation. This three day event included external hackers attacking the student networks, as well as business users placing operational and administrative demands on the teams. Teams were scored based on their ability to maintain mandated business services, keeping hackers out and answering business scenario injects. The objective was to provide an environment where the teams could exercise their information technology abilities and do so in an operational mode where most information was not freely provided, but must be uncovered and discovered by the students in real time. Issues such as prioritization, resource allocation and technical skill application were tested using real world examples on a known instrumented network. The objective of providing feedback to each team as to its skill level and abilities was achieved and then some over the course of this successful event. Lessons were learned which are being used to move this local event to a national level event.","information security, competition, education","","","InfoSecCD '05"
"Conference Paper","Elkhodary A,Whittle J","A Survey of Approaches to Adaptive Application Security","","2007","","","16","IEEE Computer Society","USA","Proceedings of the 2007 International Workshop on Software Engineering for Adaptive and Self-Managing Systems","","2007","9780769529738","","https://doi.org/10.1109/SEAMS.2007.2;http://dx.doi.org/10.1109/SEAMS.2007.2","10.1109/SEAMS.2007.2","Adaptive systems dynamically change their behavior or structure at runtime to respond to environmental changes. This paper considers one class of adaptive systems-those that adapt application-level security mechanisms. Nowadays, adaptive software security is gaining greater attention as a way to balance the tradeoff between systems security and IT infrastructure overhead. Several adaptive security systems have been developed recently supporting hardware-level to application-level reconfiguration. This paper surveys four adaptive application-level security systems and evaluates them in terms of how well they support critical security services (i.e. authentication, authorization, and tolerance) and what level of adaptation they achieve. Based on our evaluation results, we provide recommendations for future research.","","","","SEAMS '07"
"Conference Paper","Chang X,Franke H,Ge Y,Liu T,Wang K,Xenidis J,Chen F,Zhang Y","Improving Virtualization in the Presence of Software Managed Translation Lookaside Buffers","","2013","","","120–129","Association for Computing Machinery","New York, NY, USA","Proceedings of the 40th Annual International Symposium on Computer Architecture","Tel-Aviv, Israel","2013","9781450320795","","https://doi.org/10.1145/2485922.2485933;http://dx.doi.org/10.1145/2485922.2485933","10.1145/2485922.2485933","Virtualization has become an important technology that is used across many platforms, particularly servers, to increase utilization, multi-tenancy and security. Virtualization introduces additional overhead that often relates to memory management, interrupt handling and hypervisor mode switching. Among those, memory management and translation lookaside buffer (TLB) management have been shown to have a significant impact on the performance of systems. Two principal mechanisms for TLB management exist in today's systems, namely software and hardware managed TLBs. In this paper, we analyze and quantify the overhead of a pure software virtualization that is implemented over a software managed TLB. We then describe our design of hardware extensions to support virtualization in systems with software managed TLBs to remove the most dominant overheads. These extensions were implemented in the Power embedded A2 core, which is used in the PowerEN and in the Blue Gene/Q processors. They were used to implement a KVM port. We evaluate each of these hardware extensions to determine their overall contributions to performance and efficiency. Collectively these extensions demonstrate an average improvement of 232% over a pure software implementation.","","","","ISCA '13"
"Journal Article","Chang X,Franke H,Ge Y,Liu T,Wang K,Xenidis J,Chen F,Zhang Y","Improving Virtualization in the Presence of Software Managed Translation Lookaside Buffers","SIGARCH Comput. Archit. News","2013","41","3","120–129","Association for Computing Machinery","New York, NY, USA","","","2013-06","","0163-5964","https://doi.org/10.1145/2508148.2485933;http://dx.doi.org/10.1145/2508148.2485933","10.1145/2508148.2485933","Virtualization has become an important technology that is used across many platforms, particularly servers, to increase utilization, multi-tenancy and security. Virtualization introduces additional overhead that often relates to memory management, interrupt handling and hypervisor mode switching. Among those, memory management and translation lookaside buffer (TLB) management have been shown to have a significant impact on the performance of systems. Two principal mechanisms for TLB management exist in today's systems, namely software and hardware managed TLBs. In this paper, we analyze and quantify the overhead of a pure software virtualization that is implemented over a software managed TLB. We then describe our design of hardware extensions to support virtualization in systems with software managed TLBs to remove the most dominant overheads. These extensions were implemented in the Power embedded A2 core, which is used in the PowerEN and in the Blue Gene/Q processors. They were used to implement a KVM port. We evaluate each of these hardware extensions to determine their overall contributions to performance and efficiency. Collectively these extensions demonstrate an average improvement of 232% over a pure software implementation.","","","",""
"Book","","SIN '13: Proceedings of the 6th International Conference on Security of Information and Networks","","2013","","","","Association for Computing Machinery","New York, NY, USA","","Aksaray, Turkey","2013","9781450324984","","","","The main theme of the SIN 2013 conference is security of information and networks. The theme includes the following topics: Access control and intrusion detection; Cyber physical systems; Autonomous and adaptive security; Security tools and development platforms; Computational intelligence techniques in security; Security ontology, models, protocols & policies; Computer network defense; Standards, guidelines and certification; Cryptographic techniques and key management; Security-aware software engineering; Industrial applications of security; Trust and privacy; Information assurance; Cyber Warfare (attacks and defenses); Next generation network architectures; Malware analysis; Network security and protocols; Security challenges in mobile/embedded systems.","","","Proceedings",""
"Journal Article","Dwivedi AK,Rath SK","Incorporating Security Features in Service-Oriented Architecture Using Security Patterns","SIGSOFT Softw. Eng. Notes","2015","40","1","1–6","Association for Computing Machinery","New York, NY, USA","","","2015-02","","0163-5948","https://doi.org/10.1145/2693208.2693229;http://dx.doi.org/10.1145/2693208.2693229","10.1145/2693208.2693229","Service-Oriented Architecture is an architectural style where different heterogeneous components share information with each other by using special types of messages based on the protocol known as Simple Object Access Protocol. Various technologies, such as Common Object Request Broker Architecture, Java 2 Platform, Enterprise Edition, Java Message Service etc. are applied to realize Service-Oriented Architecture for different applications. Besides these approaches, two other techniques, REpresentational State Transfer, and web services are applied for the realization of Service-Oriented Architecture. Web services provide a platform independent communication scheme between applications. The security preservation among the composition of services is an important task for Service-Oriented Architecture. In this study, an attempt is made to incorporate security features in Service- Oriented Architecture with the help of software security patterns. This scheme is described by developing an architectural model integrated with security goals and security patterns. The structural and behavioral aspects of composition of web services incorporated with security features are presented using a Unified Modeling Language class diagram and a sequence diagram respectively. At the end of this study, an evaluation is performed between identified security patterns and critical security properties along with Service-Oriented Architecture design principles. A case study of an online banking system is considered to explain the use of security patterns.","Security Patterns, Web Services, SOA, Service Composition","","",""
"Journal Article","Benson GS,Akyildiz IF,Appelbe WF","A Formal Protection Model of Security in Centralized, Parallel, and Distributed Systems","ACM Trans. Comput. Syst.","1990","8","3","183–213","Association for Computing Machinery","New York, NY, USA","","","1990-08","","0734-2071","https://doi.org/10.1145/99926.99928;http://dx.doi.org/10.1145/99926.99928","10.1145/99926.99928","One way to show that a system is not secure is to demonstrate that a malicious or mistake-prone user or program can break security by causing the system to reach a nonsecure state. A fundamental aspect of a security model is a proof that validates that every state reachable from a secure initial state is secure. A sequential security model assumes that every command that acts as a state transition executes sequentially, while a concurrent security model assumes that multiple commands execute concurrently. This paper presents a security model called the Centralized-Parallel-Distributed model (CPD model) that defines security for logically, or physically centralized, parallel, and distributed systems. The purpose of the CPD model is to define concurrency conditions that guarentee that a concurrent system cannot reach a state in which privileges are configured in a nonsecure manner. As an example, the conditions are used to construct a representation of a distributed system.","distributed system security, operating system security, concurrency control, access control, protection model","","",""
"Conference Paper","Cheng L,Zhang Y","Model Checking Security Policy Model Using Both UML Static and Dynamic Diagrams","","2011","","","159–166","Association for Computing Machinery","New York, NY, USA","Proceedings of the 4th International Conference on Security of Information and Networks","Sydney, Australia","2011","9781450310208","","https://doi.org/10.1145/2070425.2070451;http://dx.doi.org/10.1145/2070425.2070451","10.1145/2070425.2070451","An operating system relies heavily on its security model to defend against malicious attacks. It has been one of the hottest research domains for decades to validate security models' correctness by formal methods during the development of security operating systems. However, current studies on the formal verification of security models are sometimes too sophisticated for the developers of operating systems, who are usually not experts in mathematical reasoning and proving. So representing a security model in UML becomes a compromise choice for the developers' verification work during system developing. In this paper, we propose a new method to verify the security policy model against the security goals using model checker SPIN and UML modeling language. Given a security policy model and the security property to be validated, our approach leverages UML class diagrams and statechart diagrams to specify its state model and its state transitions respectively. Then we translate these UML diagrams into the input language of SPIN automatically, as well as the security property. The conformance between the security goal and security model can finally be analyzed by SPIN. We proved the effectiveness of our approach by checking the violation of confidentiality of the DBLP model.","formal verification, model checking, security model, uml","","","SIN '11"
"Conference Paper","Zhilin IV,Bushnaq OM,De Masi G,Natalizio E,Akyildiz IF","A Universal Multimode (Acoustic, Magnetic Induction, Optical, RF) Software Defined Radio Architecture for Underwater Communication","","2022","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 15th International Conference on Underwater Networks & Systems","Shenzhen, Guangdong, China","2022","9781450395625","","https://doi.org/10.1145/3491315.3491327;http://dx.doi.org/10.1145/3491315.3491327","10.1145/3491315.3491327","Various underwater communication applications are proposed to maintain different economic, environmental, and security gains. To support the high quality of service (QoS) requirements of the involved communication tasks, one solution is to rely on multi-mode (i.e., acoustic, optical, magnetic induction (MI), and radio frequency (RF)) communication systems. Such a multi-mode communication system can take advantage of the complementary modes’ features, to obtain QoS requirements per transmission flow. However, challenges including high system cost and coordination between different modes need to be addressed. Therefore, in this paper a Universal Underwater Software Defined Radio (UniSDR) architecture is proposed that realizes joint operation of different modes, in order to deal with the latest use cases demands. Detailed description of the UniSDR architecture is presented. Novelty of the architecture provides flexibility, allowing designer to build a radio that includes any set of modes, which can operate jointly by exchanging data, control and synchronization. A numerical evaluation is conducted to assess the performance of the proposed UniSDR architecture. It clearly shows that the utilization of UniSDR allows to decrease the transmission latency and improve energy efficiency, while maintaining the reliability and robustness.","","","","WUWNet '21"
"Conference Paper","Tongshen H,Xiamin,Qingzhang C,Kezhen Y","Design and Implement of Firewall-Log-Based Online Attack Detection System","","2004","","","146–149","Association for Computing Machinery","New York, NY, USA","Proceedings of the 3rd International Conference on Information Security","Shanghai, China","2004","9781581139556","","https://doi.org/10.1145/1046290.1046320;http://dx.doi.org/10.1145/1046290.1046320","10.1145/1046290.1046320","This paper presents a firewall-log-based online attack detection system, giving its inner logic, composing, detecting method and realization. The system is up to firewall-log's online analysis, between-log relevancy checking, and automatic audit by the way of state transition of finite state machine. Test shows the system will provide firewall with not only network attack detection ability but also the ability to scan network addresses, scan communication ports and deny service.","network security, log analysis, firewall","","","InfoSecu '04"
"Conference Paper","Juhola A,Ahola T,Ahola K","Adaptive Risk Management with Ontology Linked Evidential Statistics and SDN","","2014","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2014 European Conference on Software Architecture Workshops","Vienna, Austria","2014","9781450327787","","https://doi.org/10.1145/2642803.2642805;http://dx.doi.org/10.1145/2642803.2642805","10.1145/2642803.2642805","New technologies have increased the dynamism of distributed systems; advances such as Software Defined Networking (SDN) and cloud computing enable unprecedented service flexibility and scalability. By their nature, they are in a constant state of flux, presenting tough challenges for system security. Here an adaptive -- in real time - risk management system capable of keeping abreast of these developments is considered. This paper presents an on-going work on combining a hierarchical threat ontology, real-time risk analysis, and SDN to an efficient whole. The main contribution of this paper is on finding the suitable architectures, components, necessary requirements, and favorable modifications on the systems and system modelling (including the models involving the security analysis) to reach this goal.","Neural Network inspired Fuzzy C-means, SDN, Adaptive security, Threat ontology, Dempster-Schafer, Dezert-Smarandache","","","ECSAW '14"
"Conference Paper","Gonzalez-Granadillo G,Rubio-Hernan J,Garcia-Alfaro J","A Pyramidal-Based Model to Compute the Impact of Cyber Security Events","","2018","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 13th International Conference on Availability, Reliability and Security","Hamburg, Germany","2018","9781450364485","","https://doi.org/10.1145/3230833.3230847;http://dx.doi.org/10.1145/3230833.3230847","10.1145/3230833.3230847","This paper presents a geometrical model that projects malicious and benign events (e.g., attacks, security countermeasures) as pyramidal instances in a multidimensional coordinate system. The approach considers internal event data related to the target system (e.g., users, physical, and logical resources, IP addresses, port numbers, etc.), and external event data related to the attacker (e.g., knowledge, motivation, skills, etc.) that can be obtained a priori and a posteriori. Internal data is used to model the base of the pyramid, whereas external data is used to model its height. In addition, the approach considers state transitions taken by the attacker to model the steps of a multi-stage attack to reach to its final goal. As a result, for each modeled state, new countermeasures are evaluated and the attacker's knowledge a posteriori changes accordingly, making it possible to evaluate the impact of the attack at time Ti, where i denotes the stage at which the attack is executed. A graphical representation of the impact of each evaluated event is depicted for visualization purposes. A use case of a cyber-physical system is proposed at the end of the paper to illustrate the applicability of the proposed geometrical model.","Pyramidal Model, Decision Support Tool, Geometrical Model, Countermeasure Selection, Event Impact Representation, Visualization","","","ARES 2018"
"Conference Paper","Wang X,Madaan A,Siow E,Tiropanis T","Sharing Databases on the Web with Porter Proxy","","2017","","","1673–1676","International World Wide Web Conferences Steering Committee","Republic and Canton of Geneva, CHE","Proceedings of the 26th International Conference on World Wide Web Companion","Perth, Australia","2017","9781450349147","","https://doi.org/10.1145/3041021.3051694;http://dx.doi.org/10.1145/3041021.3051694","10.1145/3041021.3051694","With large number of datasets now available through the Web, data-sharing ecosystems such as the Web Observatory have emerged. The Web Observatory provides an active decentralised ecosystem for datasets and applications based on a number Web Observatory sites, each of which can run in a different administrative domain. On a Web Observatory site users can publish and securely access datasets across domains via a harmonised API and reverse proxies for access control. However, that API provides a different interface to that of the databases on which datasets are stored and, consequently, existing applications that consume data from specific databases require major modification to be added to the Web Observatory ecosystem. In this paper we propose a lightweight architecture called Porter Proxy to address this concern. Porter Proxy exposes the same interfaces as databases as requested by the users while enforcing access control. Characteristics of the proposed Porter Proxy architecture are evaluated based on adversarial scenario-handling in Web Observatory eco-system.","proxy, access control, security, web observatory, data sharing","","","WWW '17 Companion"
"Conference Paper","Van Laerhoven K,Wenzel M,Geelen A,Hübel C,Wolters M,Hebestreit A,Andersen LF,van't Veer P,Kubiak T","Experiences from a Wearable-Mobile Acquisition System for Ambulatory Assessment of Diet and Activity","","2017","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 4th International Workshop on Sensor-Based Activity Recognition and Interaction","Rostock, Germany","2017","9781450352239","","https://doi.org/10.1145/3134230.3134239;http://dx.doi.org/10.1145/3134230.3134239","10.1145/3134230.3134239","Public health trends are currently monitored and diagnosed based on large studies that often rely on pen-and-paper data methods that tend to require a large collection campaign. With the pervasiveness of smart-phones and -watches throughout the general population, we argue in this paper that such devices and their built-in sensors can be used to capture such data more accurately with less of an effort. We present a system that targets a pan-European and harmonised architecture, using smartphones and wrist-worn activity loggers to enable the collection of data to estimate sedentary behavior and physical activity, plus the consumption of sugar-sweetened beverages. We report on a unified pilot study across three countries and four cities (with different languages, locale formats, and data security and privacy laws) in which 83 volunteers were asked to log beverages consumption along with a series of surveys and longitudinal accelerometer data. Our system is evaluated in terms of compliance, obtained data, and first analyses.","beverage consumption logging, barcode scanning, activity recognition, multi-modal data collection and presentation","","","iWOAR '17"
"Conference Paper","Radwan M,Heckel R","Prediction of the Domain Name System (DNS) Quality Attributes","","2017","","","578–585","Association for Computing Machinery","New York, NY, USA","Proceedings of the Symposium on Applied Computing","Marrakech, Morocco","2017","9781450344869","","https://doi.org/10.1145/3019612.3019728;http://dx.doi.org/10.1145/3019612.3019728","10.1145/3019612.3019728","The Domain Name System (DNS) has a direct impact on the performance and dependability of nearly all aspects of interactions on the Internet. DNS relies on a delegation-based architecture, where resolution of a name to its IP address requires resolving the names of the servers responsible for that name. The graphs of the inter-dependencies that exist between name servers associated with each zone are called Dependency Graphs. We constructed a DNS Dependency Model as a unified representation of these Dependency Graphs. We utilize a set of Structural Metrics defined over this model as indicators of external quality attributes of the domain name system. We explore the inter-metric and inter-quality relations further in order to quantify the indicative power of each metric. We apply some machine learning algorithms in order to construct Prediction Models of the perceived quality attributes of the operational system out of the structural metrics of the model. Assessing these quality attributes at an early stage of the design/deployment enables us to avoid the implications of defective and low-quality designs and deployment choices and identify configuration changes that might improve the availability, security, stability and resiliency postures of the DNS.","domain name system, dependency graphs, DNS qualities, predictive models","","","SAC '17"
"Conference Paper","Hong YP,Kim Y","A Study on Unified Security Mechanism and Platform for Centralized Business Contents","","2016","","","45–48","Association for Computing Machinery","New York, NY, USA","Proceedings of the 9th International Conference on Security of Information and Networks","Newark, NJ, USA","2016","9781450347648","","https://doi.org/10.1145/2947626.2951955;http://dx.doi.org/10.1145/2947626.2951955","10.1145/2947626.2951955","As business is getting sensitive to knowledge, the importance of the business contents that has business information and knowledge is rapidly increasing. Moreover, this business information includes diverse sensitive data, which should be handled in secured way.In sociological terms and information technical terms, it is important to have attention for the phenomenon that occurred in South Korea. Over the last decade in South Korea, many firms have been trying to equip some specialized security system for their internal content, which is known as 'Document (Contents) Centralization System'.This 'Document Centralization System' business became one of the biggest and hottest businesses in the area of Enterprise Contents Management Business and Contents Security Business in South Korea. Surprisingly, this system doesn't have any specialized security technologies. Moreover, it is not limited to digital security technology, but also some industrial security consideration based on business behavior. Additionally, this system needs the concept of serviced security.In order to understand this phenomenon and system effectively, it is not enough only to study information technology and security. Except for individual security technologies, we need to study other many sub themes, such as knowledge contents business, business behavior pattern in terms of industrial security, smart work business and knowledge product service system.Finally, this paper presented the adaptive security system in terms of management of technology, which means that security need to be managed, not installed.. This system has diverse characteristics, such as the convergence capability of digital security technologies, flexible system mechanism corresponding to business behavior and effective cloud system which is capable of servicing of knowledge contents.","MOT, Information Governance, Security MOT, Management of Technology, Centralized Business Contents, Contents Security, Contents Centralizing System","","","SIN '16"
"Conference Paper","Ikbal Nacer M,Prakoonwit S,Prakash E","TheCoin: Privacy and Security Considerations within Blockchain Transactions","","2021","","","10–17","Association for Computing Machinery","New York, NY, USA","2021 2nd Asia Service Sciences and Software Engineering Conference","Macau, Macao","2021","9781450389082","","https://doi.org/10.1145/3456126.3456127;http://dx.doi.org/10.1145/3456126.3456127","10.1145/3456126.3456127","TheChain is a solution to many problems such as monopoly, heavy state transition, and security vulnerabilities. TheChain solves these problems by introducing the intersection of regions as an incentive before allowing validators to nest a client directory. Intersecting their operating territories forces them to keep a watch over each other. The definition of privacy can take many forms, starting from the right to be forgotten beside being away from public attention. Although the pseudonymity of the user within the network can enhance the user's privacy, several pieces of research have studied the techniques to take advantage of the network structure to identify the users of pseudonyms. Moreover, two models have been used to record the updated exchange of values within the blockchain system, which are the unspent transaction output (UTXO) and the balance model. The UTXO suffers from duplication of information and the balance model suffers from having a single point of entry. This paper introduces TheCoin model that defines the protocol of the exchange of valuable datum within TheChain system. The solution has introduced a novel approach of initiating the transaction from the receiver side by taking advantage of mobile agents empowering a topology hiding to the network. Billing within the platform has been introduced to allow advanced contractual logic to be adopted into the system on the information level. Moreover, traceable fuzziness has been used to eliminate duplication. The paper presents an evaluation of the TheCoin model in terms of system security, block size, and search performance.","","","","ASSE '21"
"Conference Paper","Niu Z,Dong L,Zhu Y","The Runtime Model Checking Method for Zero Trust Security Policy","","2022","","","8–12","Association for Computing Machinery","New York, NY, USA","Proceedings of the 7th International Conference on Cyber Security and Information Engineering","Brisbane, QLD, Australia","2022","9781450397414","","https://doi.org/10.1145/3558819.3558821;http://dx.doi.org/10.1145/3558819.3558821","10.1145/3558819.3558821","The policy administrator is a zero trust dynamic authority determination component, which is mainly responsible for the management, storage and evaluation of policies. Aiming at the evaluation of the security and effectiveness of the policies in the policy administrator, this paper proposes to introduce the policy model online service verification component in the policy administrator. First, the policy file is formalized into a policy instance logic specification through logical abstraction, and then the policy instance logic specification Perform model check with the policy abstract logic specification developed by the policy designer to realize the pre-check verification of the consistency of the police file. After the completion of the pre-check and verification, the policy will be executed for the policy manager to make a decision on the execution point of the policy. At this time, the system operating state data intercepted by the policy enforcement point and the embedded system's security, compliance, and legal treaty form process specifications are used to perform model post-check to achieve the security and alarm after the implementation of the policy. Through the combination of pre-check and post-check, the evaluation and testing of the policy and effectiveness of the zero-trust security policy are finally realized.","","","","ICCSIE '22"
"Conference Paper","Jiang N,Song B,Chai Q,Hu L,Li Y","Study on the Influence of Power Grid Operation Mode on Wind Power Consumption in CHP System","","2021","","","183–189","Association for Computing Machinery","New York, NY, USA","Proceedings of the 3rd International Conference on Information Technologies and Electrical Engineering","Changde City, Hunan, China","2021","9781450388665","","https://doi.org/10.1145/3452940.3452976;http://dx.doi.org/10.1145/3452940.3452976","10.1145/3452940.3452976","With the wind power grid-connected capacity and the amount of curtailment continue to increase, influence factor analysis of wind power consumption becomes more active. Firstly, this paper analyzes the wind power curtailment mechanism affected by power grid operation mode in CHP system. Then, an optimal dispatch model of the CHP system is established. It includes power and heat network security constraints, units' operating states, power network topological changes and the penalty cost of electric & heat load loss. Finally, this paper analyzes the influences of power grid operation mode on wind power consumption by case simulations. Study shows the reason for wind power curtailment is not always single in a dispatch cycle. The CHP unit ""thermo-electric coupling"" constraints and power network safety constraints may alternately or simultaneously cause wind power curtailment. The unit startup plan and the power network topology all affect the reasons, the periods and the rate of wind power curtailment. In addition, the changes of grid operation mode due to quit equipment in different periods also affect the wind power curtailment rate. Meanwhile, the amount can be reduced by prioritized starting standby units in plant which occurs unit shutdown, and putting in standby transmission lines near the wind farm","Wind power consumption, Grid, Cogeneration system","","","ICITEE '20"
"Conference Paper","Srivastava D,Narasimhan P","Architectural Support for Mode-Driven Fault Tolerance in Distributed Applications","","2005","","","1–7","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2005 Workshop on Architecting Dependable Systems","St. Louis, Missouri","2005","9781595931245","","https://doi.org/10.1145/1083217.1083226;http://dx.doi.org/10.1145/1083217.1083226","10.1145/1083217.1083226","Many distributed applications exhibit different types of system behaviors, or modes, during the course of their operation. Each such mode may have different functional and non-functional requirements (such as fault tolerance, availability, and security). A static software fault-tolerance solution can not cater to the needs of every mode, and also does not utilize system resources intelligently. A flexible architecture is required to provide dependability that can be tailored for such applications. We propose a novel mode-driven fault-tolerance approach that includes: (i) a generic framework to extend the specification of modes with fault-tolerance requirements, and (ii) a software architecture that uses this description to provide the appropriate fault tolerance for each mode at runtime. We also present a case study using a distributed multi-modal CORBA application to demonstrate the effectiveness of our approach.","distributed systems, replication, software architecture, fault tolerance, CORBA, modes, COTS systems","","","WADS '05"
"Journal Article","Srivastava D,Narasimhan P","Architectural Support for Mode-Driven Fault Tolerance in Distributed Applications","SIGSOFT Softw. Eng. Notes","2005","30","4","1–7","Association for Computing Machinery","New York, NY, USA","","","2005-05","","0163-5948","https://doi.org/10.1145/1082983.1083226;http://dx.doi.org/10.1145/1082983.1083226","10.1145/1082983.1083226","Many distributed applications exhibit different types of system behaviors, or modes, during the course of their operation. Each such mode may have different functional and non-functional requirements (such as fault tolerance, availability, and security). A static software fault-tolerance solution can not cater to the needs of every mode, and also does not utilize system resources intelligently. A flexible architecture is required to provide dependability that can be tailored for such applications. We propose a novel mode-driven fault-tolerance approach that includes: (i) a generic framework to extend the specification of modes with fault-tolerance requirements, and (ii) a software architecture that uses this description to provide the appropriate fault tolerance for each mode at runtime. We also present a case study using a distributed multi-modal CORBA application to demonstrate the effectiveness of our approach.","software architecture, fault tolerance, COTS systems, CORBA, replication, modes, distributed systems","","",""
"Conference Paper","Brawerman A,Blough D,Bing B","Securing the Download of Radio Configuration Files for Software Defined Radio Devices","","2004","","","98–105","Association for Computing Machinery","New York, NY, USA","Proceedings of the Second International Workshop on Mobility Management & Wireless Access Protocols","Philadelphia, PA, USA","2004","9781581139204","","https://doi.org/10.1145/1023783.1023802;http://dx.doi.org/10.1145/1023783.1023802","10.1145/1023783.1023802","Radio configuration (R-CFG) files for software defined radio (SDR) devices can be downloaded over the air, allowing these devices to support multi-mode functionality using a single transceiver. SDR device manufacturers are likely to provide the R-CFGs, which may contain proprietary information. In such cases, it is necessary to secure the server/SDR device connection during the R-CFG download. Therefore, a protocol to securely connect manufacturer's server and SDR devices, called LSSL, is proposed. The LSSL is a lightweight protocol based on the SSL protocol, but it takes up less bandwidth, thus, it is more suitable for SDR handheld devices operating under low-capabilities, low-bandwidth and error-prone wireless links. However, securing the R-CFG download connection does not guarantee that a valid R-CFG, that is, an R-CFG that has been approved by the regulatory agency, has been downloaded. In order to install only valid R-CFGs, a secure download protocol is presented. The secure protocol includes, besides the LSSL, steps of mutual authentication, public/private key mechanisms for data encryption and decryption, and fingerprint calculations to check data integrity. Finally, the secure protocol is analyzed and shown to be deadlock and livelock-free, and to properly terminate. Experiments using Java 2 Micro Edition (J2ME) are performed to compare the LSSL and the SSL, and to demonstrate the feasibility of the secure protocol.","analysis of protocols, security and privacy issues and software, radio configuration","","","MobiWac '04"
"Conference Paper","Mochizuki S,Takada T","Client-Oriented Web Alteration Detection System Using Link Change State of a Web Page Based on Past and Current Page Content","","2015","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 17th International Conference on Information Integration and Web-Based Applications & Services","Brussels, Belgium","2015","9781450334914","","https://doi.org/10.1145/2837185.2837260;http://dx.doi.org/10.1145/2837185.2837260","10.1145/2837185.2837260","In this paper, we propose a client-oriented web alteration detection system that uses the changed state of links between the past and current versions of a browsing web page. Some measures against malicious web page alterations have been developed, such as URL-blacklist based access control. The limitations of such measures, however, are the coverage and timeliness. It is very difficult to capture all maliciously altered web page data on the Internet. A time delay from when an attacker alters a web page to when a browser blocks access to the web page is unavoidable. We focus on a page alteration such as a code injection or a page modification without a change in the visual layout. Such an alteration may lead users to experience further security threats. To detect altered web pages, whenever a user views a web page, our system extracts the link-based feature data from the page and stores it in a database. In addition, if the database has the feature data of a browsing web page from a previous access time, the system extracts the change in state of all links on the web page based on both the previous and current page content. Moreover, the results are provided to the users through a visual representation. Our system assists web-browsing users to remain aware of malicious alterations to a browsing web page. We believe that our system can engage web-browsing users to monitor web page alterations.","web page alteration, alteration detection, web browser extension, web link state change, web deface, drive-by download attack, information visualization","","","iiWAS '15"
"Conference Paper","Tinnel L,Cochrane M","Getting to the HART of the Matter: An Evaluation of Real-World Safety System OT/IT Interfaces, Attacks, and Countermeasures","","2021","","","27–35","Association for Computing Machinery","New York, NY, USA","Proceedings of the 14th Cyber Security Experimentation and Test Workshop","Virtual, CA, USA","2021","9781450390651","","https://doi.org/10.1145/3474718.3474726;http://dx.doi.org/10.1145/3474718.3474726","10.1145/3474718.3474726","This paper discusses our experience evaluating attack paths and security controls in commonly used, real-world ICS safety system architectures. Specifically, we sought to determine if an SIS-mediated architecture could provide better protection against unauthorized and malicious safety instrument configuration changes than could a MUX-mediated architecture. An assessment question-driven approach was layered on top of standard penetration assessment methods. Test cases were planned around the questions and a sample set of vendor products typically used in the oil and gas sector. Four systems were composed from different product subsets and were assessed using the test cases. We analyzed results from the four assessments to illuminate issues that existed regardless of system composition. Analysis revealed recurring vulnerabilities that exist in all safety systems due to issues in the design of safety instruments and the HART protocol. We found that device-native hardware write-protections provide the best defense, followed by SIS write protections. We concluded that, when using SIS security controls, an SIS-mediated system can protect against unauthorized device reconfigurations better than can a MUX-based system. When SIS security controls are not used, there is no added security benefit. We present lessons learned for ICS stakeholders and for people who are interested in conducting this kind of evaluation.","asset management, HART, countermeasures, safety instrumented system, cyberattack, Industrial control system, safety instruments, assessment methodology, security controls","","","CSET '21"
"Conference Paper","Zaffar F,Kedem G","Cooperative Forensics Sharing","","2006","","","26–es","Association for Computing Machinery","New York, NY, USA","Proceedings of the 1st International Conference on Bio Inspired Models of Network, Information and Computing Systems","Cavalese, Italy","2006","9781424404636","","https://doi.org/10.1145/1315843.1315875;http://dx.doi.org/10.1145/1315843.1315875","10.1145/1315843.1315875","Having timely and credible security information is becoming critical to network and security management. Most current sources of threat information and detection techniques suffer from having a limited view of the global threat scenario. In this paper, we present Foresight, an internet scale threat analysis, indication, early warning and response architecture. We describe the design of an incentive based cooperation scheme to create a global trusted community which is more accountable and hence less vulnerable to attacks and abuse. Foresight utilizes this infrastructure to share a global threat view in order to detect unknown threats and isolate them. We describe a novel behavioral signature scheme to extract a generalized footprint for multi-modal threats. System performance analysis through trace-based simulations show significant benefits for sharing forensics across cooperating domains.","","","","BIONETICS '06"
"Conference Paper","Lowe-Power J,Akella V,Farrens MK,King ST,Nitta CJ","Position Paper: A Case for Exposing Extra-Architectural State in the ISA","","2018","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 7th International Workshop on Hardware and Architectural Support for Security and Privacy","Los Angeles, California","2018","9781450365000","","https://doi.org/10.1145/3214292.3214300;http://dx.doi.org/10.1145/3214292.3214300","10.1145/3214292.3214300","The recent Meltdown and Spectre attacks took the community by surprise. Rather than exploiting an incorrect implementation of the ISA, these attacks leverage the undocumented implementation-specific speculation behavior of high-performance microarchitectures to affect the extra-architectural state of the machine (e.g., caches).Inspired by these novel speculation-based attacks, we argue it is time to rethink the traditional ISA layers. Programmers and security professionals need a framework to reason about the effects of speculation and other microarchitectural performance optimizations. We propose judiciously extending the ISA to include the extra-architectural state so that an ISA implementation either completely squashes all system state changes caused by mis-speculated instructions or the potential changes are rigorously documented. We hope this new framework will give architects and security researchers tools to reduce the likelihood of future surprise vulnerabilities.","ISA, speculation, security","","","HASP '18"
"Conference Paper","Anwer F,Nazir M,Mustafa K","Automatic Testing of Inconsistency Caused by Improper Error Handling: A Safety and Security Perspective","","2014","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2014 International Conference on Information and Communication Technology for Competitive Strategies","Udaipur, Rajasthan, India","2014","9781450332163","","https://doi.org/10.1145/2677855.2677898;http://dx.doi.org/10.1145/2677855.2677898","10.1145/2677855.2677898","Object oriented programming language provides structured way of handling error through Exception handling mechanism. Exception handling must be carefully programmed, it may leave the application in inconsistent state. Inconsistency happens when state change by the program is not reverted to its consistent state in case of exceptions. Inconsistent state can have serious side effects, it may corrupt the system or may lead to software crashes. It may be misused by the attacker to make the system down or intentionally corrupt the system. Researchers have proposed several methods to protect inconsistency developed due to exceptions. Very few techniques have been developed to test the inconsistencies in the system. In this paper we have proposed a method to automatically detect the inconsistency in the system.","Symbolic execution, Atomic method, Exception handling","","","ICTCS '14"
"Conference Paper","Reitblatt M,Foster N,Rexford J,Schlesinger C,Walker D","Abstractions for Network Update","","2012","","","323–334","Association for Computing Machinery","New York, NY, USA","Proceedings of the ACM SIGCOMM 2012 Conference on Applications, Technologies, Architectures, and Protocols for Computer Communication","Helsinki, Finland","2012","9781450314190","","https://doi.org/10.1145/2342356.2342427;http://dx.doi.org/10.1145/2342356.2342427","10.1145/2342356.2342427","Configuration changes are a common source of instability in networks, leading to outages, performance disruptions, and security vulnerabilities. Even when the initial and final configurations are correct, the update process itself often steps through intermediate configurations that exhibit incorrect behaviors. This paper introduces the notion of consistent network updates---updates that are guaranteed to preserve well-defined behaviors when transitioning mbetween configurations. We identify two distinct consistency levels, per-packet and per-flow, and we present general mechanisms for implementing them in Software-Defined Networks using switch APIs like OpenFlow. We develop a formal model of OpenFlow networks, and prove that consistent updates preserve a large class of properties. We describe our prototype implementation, including several optimizations that reduce the overhead required to perform consistent updates. We present a verification tool that leverages consistent updates to significantly reduce the complexity of checking the correctness of network control software. Finally, we describe the results of some simple experiments demonstrating the effectiveness of these optimizations on example applications.","planned change, consistency, openflow, software-defined networking, frenetic, network programming languages","","","SIGCOMM '12"
"Journal Article","Reitblatt M,Foster N,Rexford J,Schlesinger C,Walker D","Abstractions for Network Update","SIGCOMM Comput. Commun. Rev.","2012","42","4","323–334","Association for Computing Machinery","New York, NY, USA","","","2012-08","","0146-4833","https://doi.org/10.1145/2377677.2377748;http://dx.doi.org/10.1145/2377677.2377748","10.1145/2377677.2377748","Configuration changes are a common source of instability in networks, leading to outages, performance disruptions, and security vulnerabilities. Even when the initial and final configurations are correct, the update process itself often steps through intermediate configurations that exhibit incorrect behaviors. This paper introduces the notion of consistent network updates---updates that are guaranteed to preserve well-defined behaviors when transitioning mbetween configurations. We identify two distinct consistency levels, per-packet and per-flow, and we present general mechanisms for implementing them in Software-Defined Networks using switch APIs like OpenFlow. We develop a formal model of OpenFlow networks, and prove that consistent updates preserve a large class of properties. We describe our prototype implementation, including several optimizations that reduce the overhead required to perform consistent updates. We present a verification tool that leverages consistent updates to significantly reduce the complexity of checking the correctness of network control software. Finally, we describe the results of some simple experiments demonstrating the effectiveness of these optimizations on example applications.","software-defined networking, openflow, frenetic, network programming languages, consistency, planned change","","",""
"Conference Paper","Rauter T,Höller A,Iber J,Kreiner C","Static and Dynamic Integrity Properties Patterns","","2016","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 21st European Conference on Pattern Languages of Programs","Kaufbeuren, Germany","2016","9781450340748","","https://doi.org/10.1145/3011784.3011798;http://dx.doi.org/10.1145/3011784.3011798","10.1145/3011784.3011798","Integrity is a crucial property in current computing systems. Due to natural or human-made (malicious and non-malicious) faults this property can be violated. Therefore, many methodologies and patterns that check or verify the integrity of systems or data have been introduced. However, integrity as a property cannot be identified directly. Existing methodologies tackle this problem by identifying other, computable, properties of the system and use a policy that describes how these properties reflect the integrity of the overall system. It is thus a critical task to select the right properties that reflect the integrity of a system in such a way that given integrity requirements are met. To ease this process, we introduce two new patterns, Static Integrity Properties and Dynamic Integrity Properties to classify the properties. Static Integrity Properties are used to ensure the integrity of a component prior it's use (e.g., the integrity of an executable binary), while Dynamic Integrity Properties are used to ensure the integrity of a component during run-time (e.g., properties that reflect the component's behavior or state transitions). Based on an exemplary embedded control system, we show typical use cases to help the system or software architect to choose the right class of integrity properties for the targeted system.","software integrity, security patterns","","","EuroPlop '16"
"Conference Paper","Li D","Poster: Toward a Theoretical Privacy Framework for Electronic Locks in Context of Home Security Monitoring System for Clouds of Things","","2015","","","393–394","Association for Computing Machinery","New York, NY, USA","Proceedings of the 16th ACM International Symposium on Mobile Ad Hoc Networking and Computing","Hangzhou, China","2015","9781450334891","","https://doi.org/10.1145/2746285.2764870;http://dx.doi.org/10.1145/2746285.2764870","10.1145/2746285.2764870","Current popular schemes e.g. homomorphic cryptography are extensively deployed to preserve privacy in a limited level but without a formal privacy model, we can neither offer privacy guarantee nor quantify the privacy loss. In this paper, we raise a few privacy-related questions, one after another, with the e-Lock state changes in a smart home as an example. In a novel privacy framework we proposed, the questions are partially addressed with the utilization of a set of theoretical models e.g. hidden markov model, differential privacy and information flow with belief. Since our paper is still at its start phase, we plan to accomplish the framework and wish can inspire colleagues' interests in this area.","electronic lock, formal privacy model, privacy preservation","","","MobiHoc '15"
"Conference Paper","Sartakov VA,Brenner S,Ben Mokhtar S,Bouchenak S,Thomas G,Kapitza R","EActors: Fast and Flexible Trusted Computing Using SGX","","2018","","","187–200","Association for Computing Machinery","New York, NY, USA","Proceedings of the 19th International Middleware Conference","Rennes, France","2018","9781450357029","","https://doi.org/10.1145/3274808.3274823;http://dx.doi.org/10.1145/3274808.3274823","10.1145/3274808.3274823","Novel trusted execution support, as offered by Intel's Software Guard eXtensions (SGX), embeds seamlessly into user space applications by establishing regions of encrypted memory, called enclaves. Enclaves comprise code and data that is executed under special protection of the CPU and can only be accessed via an enclave defined interface. To facilitate the usability of this new system abstraction, Intel offers a software development kit (SGX SDK). While the SDK eases the use of SGX, it misses appropriate programming support for inter-enclave interaction, and demands to hardcode the exact use of trusted execution into applications, which restricts flexibility.This paper proposes EActors, an actor framework that is tailored to SGX and offers a more seamless, flexible and efficient use of trusted execution -- especially for applications demanding multiple enclaves. EActors disentangles the interaction with enclaves and, among them, from costly execution mode transitions. It features lightweight fine-grained parallelism based on the concept of actors, thereby avoiding costly SGX SDK provided synchronisation constructs. Finally, EActors offers a high degree of freedom to execute actors, either untrusted or trusted, depending on security requirements and performance demands. We implemented two use cases on top of EActors: (i) a secure instant messaging service, and (ii) a secure multi-party computation service. Both illustrate the ability of EActors to seamlessly and effectively build secure applications. Furthermore, our performance evaluation results show that securing the messaging service with EActors improves performance compared to the vanilla versions of JabberD2 and ejabberd by up to 40x.","Trusted Execution, Intel SGX, Actors","","","Middleware '18"
"Conference Paper","Meza A,Kastner R","Automated Generation, Verification, and Ranking of Secure SoC Access Control Policies","","2023","","","198–202","Association for Computing Machinery","New York, NY, USA","Proceedings of Cyber-Physical Systems and Internet of Things Week 2023","San Antonio, TX, USA","2023","","","https://doi.org/10.1145/3576914.3587508;http://dx.doi.org/10.1145/3576914.3587508","10.1145/3576914.3587508","Modern System-on-chip (SoC) architectures are a heterogeneous mix of microprocessors, custom accelerators, memories, interfaces, peripherals, and other resources. These resources communicate using complex on-chip interconnect networks that attempt to quickly and efficiently arbitrate memory transactions whose behaviors can vary drastically depending on the current mode of operation and system operating state. Security- and safety-critical applications require access control policies that define how these resources interact to ensure that malicious and unsafe behaviors do not occur. The process of defining and then verifying the security of these access control policies relies heavily on manual effort. This paper describes an automated methodology to generate, verify, and rank secure SoC access control policies. Our methodology targets access control policies for AKER access control systems.","Security Verification, Access Control, System-on-Chip","","","CPS-IoT Week '23"
"Conference Paper","Guo Y,Zigerelli A,Zhang Y,Yang J","IVcache: Defending Cache Side Channel Attacks via Invisible Accesses","","2021","","","403–408","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2021 on Great Lakes Symposium on VLSI","Virtual Event, USA","2021","9781450383936","","https://doi.org/10.1145/3453688.3461481;http://dx.doi.org/10.1145/3453688.3461481","10.1145/3453688.3461481","The sharing of last-level cache (LLC) among different CPU cores makes cache vulnerable to side channel attacks. An attacker can get private information about co-running applications (victims) by monitoring their accesses in LLC. Cache side channel attacks can be mitigated by partitioning cache between the victim and attacker. However, previous partition works either make weak assumptions about the attacker's strength or force their security mechanisms and thus overhead to every user on the system, regardless of their security requirement.We argue that offering security protection as a service is a better choice for secure cache design. To achieve this, we propose Invisible-Victim cache (IVcache), a new cache partition design targeting both the original LLC attack and the new variant. IVcache classifies all security domains on the system as protected and unprotected. For LLC accesses from protected domains, IVcache handles cache state changes in a slightly different way to make those accesses invisible to any other security domains. We implement and evaluate IVcache in Gem5. The experimental results show that IVcache can defend against real-world attacks, and that it introduces negligible performance overhead to protected domains and no overhead to unprotected domains.","security, cache, side channel","","","GLSVLSI '21"
"Conference Paper","Zhang T,Lee RB","New Models of Cache Architectures Characterizing Information Leakage from Cache Side Channels","","2014","","","96–105","Association for Computing Machinery","New York, NY, USA","Proceedings of the 30th Annual Computer Security Applications Conference","New Orleans, Louisiana, USA","2014","9781450330053","","https://doi.org/10.1145/2664243.2664273;http://dx.doi.org/10.1145/2664243.2664273","10.1145/2664243.2664273","Side-channel attacks try to breach confidentiality and retrieve critical secrets through the side channels. Cache memories are a potential source of information leakage through side-channel attacks, many of which have been proposed. Meanwhile, different cache architectures have also been proposed to defend against these attacks. However, there are currently no means for comparing and evaluating the effectiveness of different defense solutions against these attacks.In this paper, we propose a novel method to evaluate a system's vulnerability to side-channel attacks. We establish side-channel leakage models based on the non-interference property. Then we define how the security aspects of a cache architecture can be modeled as a finite-state machine (FSM) with state transitions that cause interference. We use mutual information to quantitatively reveal potential side-channel leakage of the architectures, and allow comparison of these architectures for their relative vulnerabilities to side-channel attacks. We use real attacks to validate our results.","","","","ACSAC '14"
"Conference Paper","Hively LM,McDonald JT","Theorem-Based, Data-Driven, Cyber Event Detection","","2013","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the Eighth Annual Cyber Security and Information Intelligence Research Workshop","Oak Ridge, Tennessee, USA","2013","9781450316873","","https://doi.org/10.1145/2459976.2460041;http://dx.doi.org/10.1145/2459976.2460041","10.1145/2459976.2460041","Nonlinear dynamics and graph theory may provide a theorem-based path to improve design security and aid detection of anomalous events in cyber applications. Using side-channel information such as power taken from underlying computer components and analyzing noisy data such as timing, we ask the question of whether such data can reveal anomalous activity or verify the changing dynamics of an underlying computer system. Takens' theorem in nonlinear dynamics allows reconstruction of topologically invariant, time-delay-embedding states from the computer dynamics in a sufficiently high-dimensional space. The resultant dynamical states are vertices, and the state-to-state transitions are edges in a graph. Graph theorems guarantee topologically invariant measures to quantify the dynamical changes, based on the applications that are executing. This paper highlights recent applications of the phase-space analysis technique in the non-cyber realm (forewarning of biomedical events and equipment failures), and proposes new applications that would bolster cyber event detection.","phasespace analysis, graph theory, nonlinear dynamics, cyber anomaly detection, power measurement","","","CSIIRW '13"
"Conference Paper","John DJ,Smith RW,Turkett WH,Cañas DA,Fulp EW","Evolutionary Based Moving Target Cyber Defense","","2014","","","1261–1268","Association for Computing Machinery","New York, NY, USA","Proceedings of the Companion Publication of the 2014 Annual Conference on Genetic and Evolutionary Computation","Vancouver, BC, Canada","2014","9781450328814","","https://doi.org/10.1145/2598394.2605437;http://dx.doi.org/10.1145/2598394.2605437","10.1145/2598394.2605437","A Moving Target (MT) defense constantly changes a system's attack surface, in an attempt to limit the usefulness of the reconnaissance the attacker has collected. One approach to this defense strategy is to intermittently change a system's configuration. These changes must maintain functionality and security, while also being diverse. Finding suitable configuration changes that form a MT defense is challenging. There are potentially a large number of individual configurations' settings to consider, without a full understanding of the settings' interdependencies.Evolution-based algorithms, which formulate better solutions from good solutions, can be used to create a MT defense. New configurations are created based on the security of previous configurations and can be periodically implemented to change the system's attack surface. This approach not only has the ability to discover new, more secure configurations, but is also proactive and resilient since it can continually adapt to the current environment in a fashion similar to systems found in nature.This article presents and compares two genetic algorithms to create a MT defense. The primary difference between the two is based on their approaches to mutation. One mutates values, and the other modifies the domains from which values are chosen.","directed mutation, moving target defense, computer security","","","GECCO Comp '14"
"Conference Paper","Morelli A,Stefanelli C,Tortonesi M,Lenzi R,Suri N","A Proxy Gateway Solution to Provide QoS in Tactical Networks and Disaster Recovery Scenarios","","2015","","","43–50","Association for Computing Machinery","New York, NY, USA","Proceedings of the 11th ACM Symposium on QoS and Security for Wireless and Mobile Networks","Cancun, Mexico","2015","9781450337571","","https://doi.org/10.1145/2815317.2815318;http://dx.doi.org/10.1145/2815317.2815318","10.1145/2815317.2815318","Many important public services, such as security and public health, as well as the modern tactical military scenarios, rely on Service-oriented Architectures (SoAs) and commercial off-the-shelf (COTS) components to enable the quick development and deployment of distributed services to respond quickly, reduce costs, and ease system integration. However, SoAs make use of verbose networking technologies and require reliable and relatively high bandwidth communications. Tactical scenarios normally cannot rely on such infrastructure and events like natural disasters can severely damage the network infrastructure in rural and urban environments. Thus, there is a need to develop solutions that provide SoA-based application and services running on heterogeneous and often constrained devices that compose tactical and mobile ad-hoc networks with Quality of Service (QoS) levels that meet their requirements. This paper presents the QoS-enabling features and the gateway operational mode (GM) of ACM NetProxy, the network proxy component of a communications middleware specifically developed to support applications in challenged networks. GM allows nodes in an ad-hoc wireless network to be quickly organized and to shape outbound communications to reduce bandwidth consumption and provide QoS. Experimental results obtained during a test in a field demonstration event show its efficiency.","qos, network proxy, disaster recovery, communications middleware, tactical networks","","","Q2SWinet '15"
"Conference Paper","Fielding RT,Taylor RN","Principled Design of the Modern Web Architecture","","2000","","","407–416","Association for Computing Machinery","New York, NY, USA","Proceedings of the 22nd International Conference on Software Engineering","Limerick, Ireland","2000","9781581132069","","https://doi.org/10.1145/337180.337228;http://dx.doi.org/10.1145/337180.337228","10.1145/337180.337228","The World Wide Web has succeeded in large part because its software architecture has been designed to meet the needs of an Internet-scale distributed hypermedia system. The modern Web architecture emphasizes scalability of component interactions, generality of interfaces, independent deployment of components, and intermediary components to reduce interaction latency, enforce security, and encapsulate legacy systems. In this paper, we introduce the Representational State Transfer (REST) architectural style, developed as an abstract model of the Web architecture to guide our redesign and definition of the Hypertext Transfer Protocol and Uniform Resource Identifiers. We describe the software engineering principles guiding REST and the interaction constraints chosen to retain those principles, contrasting them to the constraints of other architectural styles. We then compare the abstract model to the currently deployed Web architecture in order to elicit mismatches between the existing protocols and the applications they are intended to support.","software architecture, software architectural style, WWW","","","ICSE '00"
"Conference Paper","Speicher P,Steinmetz M,Hoffmann J,Backes M,Künnemann R","Towards Automated Network Mitigation Analysis","","2019","","","1971–1978","Association for Computing Machinery","New York, NY, USA","Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing","Limassol, Cyprus","2019","9781450359337","","https://doi.org/10.1145/3297280.3297473;http://dx.doi.org/10.1145/3297280.3297473","10.1145/3297280.3297473","Penetration testing is a well-established practical concept for the identification of potentially exploitable security weaknesses and an important component of a security audit. Providing a holistic security assessment for networks consisting of several hundreds hosts is hardly feasible though without some sort of mechanization. Mitigation, prioritizing counter-measures subject to a given budget, currently lacks a solid theoretical understanding and is hence more art than science. In this work, we propose the first approach for conducting comprehensive what-if analyses in order to reason about mitigation in a conceptually well-founded manner. To evaluate and compare mitigation strategies, we use simulated penetration testing, i.e., automated attack-finding, based on a network model to which a subset of a given set of mitigation actions, e.g., changes to the network topology, system updates, configuration changes etc. is applied. Using Stackelberg planning, we determine optimal combinations that minimize the maximal attacker success (similar to a Stackelberg game), and thus provide a well-founded basis for a holistic mitigation strategy. We show that these Stackelberg planning models can largely be derived from network scan, public vulnerability databases and manual inspection with various degrees of automation and detail, and we simulate mitigation analysis on networks of different size and vulnerability.","simulated penetration testing, planning, network security","","","SAC '19"
"Conference Paper","Oliveira AL,Delicato FC,Pirmez M","JanioS: Um Serviço de SSH Para o Prometheus","","2008","","","173–175","Association for Computing Machinery","New York, NY, USA","Companion Proceedings of the XIV Brazilian Symposium on Multimedia and the Web","Vila Velha, Espírito Santo, Brazil","2008","9788576691990","","https://doi.org/10.1145/1809980.1810030;http://dx.doi.org/10.1145/1809980.1810030","10.1145/1809980.1810030","The recent proliferation of portable devices with increasing computational power as well as the advent of new wireless network technologies has enabled the realization of the ubiquitous computing vision. The paradigm of ubiquitous computing raises new challenges and requirements, such as the need of applications to adapt in the face of context changes while providing a suitable level of security to the user. This paper presents JanioS, an implementation of a new version to a library that provides SSH tunnel connections (Secure Shell) between applications. JanioS will be part of Prometheus, a system for provision of a service for adaptive security target to ubiquitous environment. JanioS will be able to dynamically adapt security parameters, such as cryptographic and data compression algorithms, according to the current execution context.","","","","WebMedia '08"
"Conference Paper","Payer M,Gross TR","Protecting Applications against TOCTTOU Races by User-Space Caching of File Metadata","","2012","","","215–226","Association for Computing Machinery","New York, NY, USA","Proceedings of the 8th ACM SIGPLAN/SIGOPS Conference on Virtual Execution Environments","London, England, UK","2012","9781450311762","","https://doi.org/10.1145/2151024.2151052;http://dx.doi.org/10.1145/2151024.2151052","10.1145/2151024.2151052","Time Of Check To Time Of Use (TOCTTOU) race conditions for file accesses in user-space applications are a common problem in Unix-like systems. The mapping between filename and inode and device is volatile and can provide the necessary preconditions for an exploit. Applications use filenames as the primary attribute to identify files but the mapping between filenames and inode and device can be changed by an attacker.DynaRace is an approach that protects unmodified applications from file-based TOCTTOU race conditions. DynaRace uses a transparent mapping cache that keeps additional state and metadata for each accessed file in the application. The combination of file state and the current system call type are used to decide if (i) the metadata is updated or (ii) the correctness of the metadata is enforced between consecutive system calls.DynaRace uses user-mode path resolution internally to resolve individual file atoms. Each file atom is verified or updated according to the associated state in the mapping cache. More specifically, DynaRace protects against race conditions for all file-based system calls, by replacing the unsafe system calls with a set of safe system calls that utilize the mapping cache. The system call is executed only if the state transition is allowed and the information in the mapping cache matches.DynaRace deterministically solves the problem of file-based race conditions for unmodified applications and removes an attacker's ability to exploit the TOCTTOU race condition. DynaRace detects injected alternate inode and device pairs and terminates the application.","file-based TOCTTOU race protection, TOCTTOU races, virtualization, race protection, dynamic protection, security","","","VEE '12"
"Journal Article","Payer M,Gross TR","Protecting Applications against TOCTTOU Races by User-Space Caching of File Metadata","SIGPLAN Not.","2012","47","7","215–226","Association for Computing Machinery","New York, NY, USA","","","2012-03","","0362-1340","https://doi.org/10.1145/2365864.2151052;http://dx.doi.org/10.1145/2365864.2151052","10.1145/2365864.2151052","Time Of Check To Time Of Use (TOCTTOU) race conditions for file accesses in user-space applications are a common problem in Unix-like systems. The mapping between filename and inode and device is volatile and can provide the necessary preconditions for an exploit. Applications use filenames as the primary attribute to identify files but the mapping between filenames and inode and device can be changed by an attacker.DynaRace is an approach that protects unmodified applications from file-based TOCTTOU race conditions. DynaRace uses a transparent mapping cache that keeps additional state and metadata for each accessed file in the application. The combination of file state and the current system call type are used to decide if (i) the metadata is updated or (ii) the correctness of the metadata is enforced between consecutive system calls.DynaRace uses user-mode path resolution internally to resolve individual file atoms. Each file atom is verified or updated according to the associated state in the mapping cache. More specifically, DynaRace protects against race conditions for all file-based system calls, by replacing the unsafe system calls with a set of safe system calls that utilize the mapping cache. The system call is executed only if the state transition is allowed and the information in the mapping cache matches.DynaRace deterministically solves the problem of file-based race conditions for unmodified applications and removes an attacker's ability to exploit the TOCTTOU race condition. DynaRace detects injected alternate inode and device pairs and terminates the application.","dynamic protection, security, virtualization, file-based TOCTTOU race protection, TOCTTOU races, race protection","","",""
"Journal Article","Johansen NS,Kær LB,Madsen AL,Nielsen KØ,Srba J,Tollund RG","Kaki: Efficient Concurrent Update Synthesis for SDN","Form. Asp. Comput.","2023","","","","Association for Computing Machinery","New York, NY, USA","","","2023-06","","0934-5043","https://doi.org/10.1145/3605952;http://dx.doi.org/10.1145/3605952","10.1145/3605952","Modern computer networks based on the software-defined networking (SDN) paradigm are becoming increasingly complex and often require frequent configuration changes in order to react to traffic fluctuations. It is essential that forwarding policies are preserved not only before and after the configuration update but also at any moment during the inherently distributed execution of such an update. We present Kaki, a Petri game based tool for automatic synthesis of switch batches which can be updated in parallel without violating a given (regular) forwarding policy like waypointing or service chaining. Kaki guarantees to find the minimum number of concurrent batches and supports both splittable and nonsplittable flow forwarding. In order to achieve optimal performance, we introduce two novel optimisation techniques based on static analysis: decomposition into independent subproblems and identification of switches that can be collectively updated in the same batch. These techniques considerably improve the performance of our tool Kaki, relying on TAPAAL’s verification engine for Petri games as its backend. Experiments on a large benchmark of real networks from the Internet Topology Zoo database demonstrate that Kaki outperforms the state-of-the-art tools Netstack and FLIP. Kaki computes concurrent update synthesis significantly faster than Netstack and compared to FLIP, it provides shorter (and provably optimal) concurrent update sequences at similar runtimes.","computer networks, security policies, software defined networking, concurrent update synthesis","Just Accepted","",""
"Conference Paper","Kumar A,Lee LH,Chauhan J,Su X,Hoque MA,Pirttikangas S,Tarkoma S,Hui P","PassWalk: Spatial Authentication Leveraging Lateral Shift and Gaze on Mobile Headsets","","2022","","","952–960","Association for Computing Machinery","New York, NY, USA","Proceedings of the 30th ACM International Conference on Multimedia","Lisboa, Portugal","2022","9781450392037","","https://doi.org/10.1145/3503161.3548252;http://dx.doi.org/10.1145/3503161.3548252","10.1145/3503161.3548252","Secure and usable user authentication on mobile headsets is a challenging problem. The miniature-sized touchpad on such devices becomes a hurdle to user interactions that impact usability. However, the most common authentication methods, i.e., the standard QWERTY virtual keyboard or mid-air inputs to enter passwords are highly vulnerable to shoulder surfing attacks. In this paper, we present PassWalk, a keyboard-less authentication system leveraging multi-modal inputs on mobile headsets. PassWalk demonstrates the feasibility of user authentication driven by the user's gaze and lateral shifts (i.e., footsteps) simultaneously. The keyboard-less authentication interface in PassWalk enables users to accomplish highly mobile inputs of graphical passwords, containing digital overlays and physical objects. We conduct an evaluation with 22 recruited participants (15 legitimate users and 7 attackers). Our results show that PassWalk provides high security (only 1.1% observation attacks were successful) with a mean authentication time of 8.028s, which outperforms the commercial method of using the QWERTY virtual keyboard (21.5% successful attacks) and a research prototype LookUnLock (5.5% successful attacks). Additionally, PassWalk entails a significantly smaller workload on the user than the current commercial methods.","authentication, AR/VR, immersive reality, mobile headsets, metaverse","","","MM '22"
"Conference Paper","AlAhmadi BA,Mariconti E,Spolaor R,Stringhini G,Martinovic I","BOTection: Bot Detection by Building Markov Chain Models of Bots Network Behavior","","2020","","","652–664","Association for Computing Machinery","New York, NY, USA","Proceedings of the 15th ACM Asia Conference on Computer and Communications Security","Taipei, Taiwan","2020","9781450367509","","https://doi.org/10.1145/3320269.3372202;http://dx.doi.org/10.1145/3320269.3372202","10.1145/3320269.3372202","Botnets continue to be a threat to organizations, thus various machine learning-based botnet detectors have been proposed. However, the capability of such systems in detecting new or unseen botnets is crucial to ensure its robustness against the rapid evolution of botnets. Moreover, it prolongs the effectiveness of the system in detecting bots, avoiding frequent and time-consuming classifier re-training. We present BOTection, a privacy-preserving bot detection system that models the bot network flow behavior as a Markov Chain. The Markov Chain state transitions capture the bots' network behavior using high-level flow features as states, producing content-agnostic and encryption resilient behavioral features. These features are used to train a classifier to first detect flows produced by bots, and then identify their bot families. We evaluate our system on a dataset of over 7M malicious flows from 12 botnet families, showing its capability of detecting bots' network traffic with 99.78% F-measure and classifying it to a malware family with a 99.09% F-measure. Notably, due to the modeling of general bot network behavior by the Markov Chains, BOTection can detect traffic belonging to unseen bot families with an F-measure of 93.03% making it robust against malware evolution.","malware detection, malware, network security, botnet","","","ASIA CCS '20"
"Conference Paper","Mao Y,Zhang Y,Zhong S","Stemming Downlink Leakage from Training Sequences in Multi-User MIMO Networks","","2016","","","1580–1590","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security","Vienna, Austria","2016","9781450341394","","https://doi.org/10.1145/2976749.2978412;http://dx.doi.org/10.1145/2976749.2978412","10.1145/2976749.2978412","Multi-User MIMO has attracted much attention due to its significant advantage of increasing the utilization ratio of wireless channels. Recently a serious eavesdropping attack, which exploits the CSI feedback of the FDD system, is discovered in MU-MIMO networks. In this paper, we firstly show a similar eavesdropping attack for the TDD system is also possible by proposing a novel, feasible attack approach. Following it, a malicious user can eavesdrop on other users' downloads by transforming training sequences. To prevent this attack, we propose a secure CSI estimation scheme for instantaneous CSI. Furthermore, we extend this scheme to achieve adaptive security when CSI is relatively statistical. We have implemented our scheme for both uplink and downlink of MU-MIMO and performed a series of experiments. Results show that our secure CSI estimation scheme is highly effective in preventing downlink leakage against malicious users.","multi-user mimo, physical security, channel state information, eavesdropping","","","CCS '16"
"Conference Paper","Pan L,Tomlinson A,Koloydenko AA","Time Pattern Analysis of Malware by Circular Statistics","","2017","","","119–130","IEEE Press","Beijing, China","Proceedings of the Symposium on Architectures for Networking and Communications Systems","","2017","9781509063864","","https://doi.org/10.1109/ANCS.2017.26;http://dx.doi.org/10.1109/ANCS.2017.26","10.1109/ANCS.2017.26","Circular statistics present a new technique to analyse the time patterns of events in the field of cyber security. We apply this technique to analyse incidents of malware infections detected by network monitoring. In particular we are interested in the daily and weekly variations of these events.Based on ""live"" data provided by Spamhaus, we examine the hypothesis that attacks on four countries are distributed uniformly over 24 hours. Specifically, we use Rayleigh and Watson tests. While our results are mainly exploratory, we are able to demonstrate that the attacks are not uniformly distributed, nor do they follow a Poisson distribution as reported in other research. Our objective in this is to identify a distribution that can be used to establish risk metrics.Moreover, our approach provides a visual overview of the time patterns' variation, indicating when attacks are most likely. This will assist decision makers in cyber security to allocate resources or estimate the cost of system monitoring during high risk periods.Our results also reveal that the time patterns are influenced by the total number of attacks. Networks subject to a large volume of attacks exhibit bimodality while one case, where attacks were at relatively lower rate, showed a multi-modal daily variation.","time patterns, uniformity hypothesis test, Circular statistics, malware","","","ANCS '17"
"Conference Paper","Li A,Li J,Han D,Zhang Y,Li T,Zhang Y","WearRF-CLA: Continuous Location Authentication with Wrist Wearables and UHF RFID","","2022","","","508–520","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2022 ACM on Asia Conference on Computer and Communications Security","Nagasaki, Japan","2022","9781450391405","","https://doi.org/10.1145/3488932.3517426;http://dx.doi.org/10.1145/3488932.3517426","10.1145/3488932.3517426","Continuous location authentication (CLA) seeks to continuously and automatically verify the physical presence of legitimate users in a protected indoor area. CLA can play an important role in contexts where access to electrical or physical resources must be limited to physically present legitimate users. In this paper, we present WearRF-CLA, a novel CLA scheme built upon increasingly popular wrist wearables and UHF RFID systems. WearRF-CLA explores the observation that human daily routines in a protected indoor area comprise a sequence of human-states (e.g., walking and sitting) that follow predictable state transitions. Each legitimate WearRF-CLA user registers his/her RFID tag and also wrist wearable during system enrollment. After the user enters a protected area, WearRF-CLA continuously collects and processes the gyroscope data of the wrist wearable and the phase data of the RFID tag signals to verify three factors to determine the user's physical presence/absence without explicit user involvement: (1) the tag ID as in a traditional RFID authentication system, (2) the validity of the human-state chain, and (3) the continuous coexistence of the paired wrist wearable and RFID tag with the user. The user passes CLA if and only if all three factors can be validated. Extensive user experiments on commodity smartwatches and UHF RFID devices confirm the very high security and low authentication latency of WearRF-CLA.","wireless security, wrist wearables, deep learning, rfid, continuous location authentication (cla)","","","ASIA CCS '22"
"Journal Article","Agarwal R,Bilokhatniuk S","Android Authentication and Device Administration API","J. Comput. Sci. Coll.","2012","27","5","187–195","Consortium for Computing Sciences in Colleges","Evansville, IN, USA","","","2012-05","","1937-4771","","","This paper examines security capabilities of Android open source operating system based on GNU/Linux and components developed by Google. The focus of this paper is analysis of Android screen-locker and login applications. Many default Android applications can be replaced by new applications, which can offer different interface or add new functionality. Screen-locker is an integral part of Android, and while it cannot be replaced directly, there are ways to implement applications to offer same functionality, and possibly more features. Android 2.2 Device Administration API is tightly coupled with the native screen-locker and login mechanism, allowing for development of robust and adaptive security applications and centralized policy management tools. A new screen-locker and authentication app was created using Device Administration API and is discussed in this paper.","","","",""
"Conference Paper","Fertig T,Braun P","Model-Driven Testing of RESTful APIs","","2015","","","1497–1502","Association for Computing Machinery","New York, NY, USA","Proceedings of the 24th International Conference on World Wide Web","Florence, Italy","2015","9781450334730","","https://doi.org/10.1145/2740908.2743045;http://dx.doi.org/10.1145/2740908.2743045","10.1145/2740908.2743045","In contrast to the increasing popularity of REpresentational State Transfer (REST), systematic testing of RESTful Application Programming Interfaces (API) has not attracted much attention so far. This paper describes different aspects of automated testing of RESTful APIs. Later, we focus on functional and security tests, for which we apply a technique called model-based software development. Based on an abstract model of the RESTful API that comprises resources, states and transitions a software generator not only creates the source code of the RESTful API but also creates a large number of test cases that can be immediately used to test the implementation. This paper describes the process of developing a software generator for test cases using state-of-the-art tools and provides an example to show the feasibility of our approach.","measurement, languages, verification","","","WWW '15 Companion"
"Journal Article","Frappier M,Gervais F,Laleau R,Milhau J","Refinement Patterns for ASTDs","Form. Asp. Comput.","2014","26","5","919–941","Springer-Verlag","Berlin, Heidelberg","","","2014-09","","0934-5043","https://doi.org/10.1007/s00165-013-0286-3;http://dx.doi.org/10.1007/s00165-013-0286-3","10.1007/s00165-013-0286-3","This paper introduces three refinement patterns for algebraic state-transition diagrams (astds): state refinement, transition refinement and loop-transition refinement. These refinement patterns are derived from practice in using astds for specifying information systems and security policies in two industrial research projects. Two refinement relations used in these patterns are formally defined. For each pattern, proof obligations are proposed to ensure preservation of behaviour through refinement. The proposed refinement relations essentially consist in preserving scenarios by replacing abstract events with concrete events, or by introducing new events. Deadlocks cannot be introduced; divergence over new events is allowed in one of the refinement relation. We prove congruence-like properties for these three patterns, in order to show that they can be applied to a subpart of a specification while preserving global properties. These three refinement patterns are illustrated with a simple case study of a complaint management system.","astd, Refinement, Patterns, Information systems","","",""
"Conference Paper","Kim J,Susilo W,Guo F,Au MH,Nepal S","An Efficient KP-ABE with Short Ciphertexts in Prime OrderGroups under Standard Assumption","","2017","","","823–834","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security","Abu Dhabi, United Arab Emirates","2017","9781450349444","","https://doi.org/10.1145/3052973.3053003;http://dx.doi.org/10.1145/3052973.3053003","10.1145/3052973.3053003","We introduce an efficient Key-Policy Attribute-Based Encryption (KP-ABE) scheme in prime order groups. Our scheme is semi-adaptively secure under the decisional linear assumption and supports a large universe of attributes and multi-use of attributes. Those properties are critical for real applications of KP-ABE schemes since they enable an efficient and flexible access control. Prior to our work, existing KP-ABE schemes with short ciphertexts were in composite order groups or utilized either Dual Pairing Vector Spaces (DPVS) or Dual System Groups (DSG) in prime order groups. However, those techniques brought an efficiency loss. In this work, we utilize a nested dual system encryption which is a variant of Waters' dual system encryption (Crypto' 09) to achieve semi-adaptively secure KP-ABE. As a result, we obtain a new scheme having better efficiency compared to existing schemes while it keeps a semi-adaptive security under the standard assumption. We implement our scheme and compare its efficiency with the previous best work.","prime order groups, dual system encryption, standard assumption, short ciphertexts, attribute based encryption","","","ASIA CCS '17"
"Conference Paper","Shakarami M,Sandhu R","Role-Based Administration of Role-Based Smart Home IoT","","2021","","","49–58","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2021 ACM Workshop on Secure and Trustworthy Cyber-Physical Systems","Virtual Event, USA","2021","9781450383196","","https://doi.org/10.1145/3445969.3450426;http://dx.doi.org/10.1145/3445969.3450426","10.1145/3445969.3450426","Using role-based access control (RBAC) to manage RBAC is among RBAC's attractive benefits, contributing to its long-standing dominance in practice. Administrative models facilitate management of (mostly configuration) changes in the underlying operational models. Overall system security is crucially dependent on both the administrative and operational models. In this paper, we develop an RBAC administrative model to manage authorization assignments in the EGRBAC (enhanced generalized role-based access control) operational model for smart home IoT. We design the administrative model based on pairwise disjoint Administrative Units, each of which contains a uniquely assigned administrative role and a set of administrative tasks. Administrative tasks determine the administrative permissions available to manage the operational model assignments. We begin with a model containing a single administrative unit and then extend it to include additional units. Multiple administrative units enable decentralized administration which could be adapted to provide scalability in inherently distributed and large-scale environments beyond smart home, such as smart buildings or smart campuses. We provide formalism of our proposed model and illustrate it by specifying operational and administrative use cases. Although, the model is proposed based on a specific smart home operational model, our approach could be applied to environments with similar dynamics.","decentralized administration, smart home, RBAC administrative model","","","SAT-CPS '21"
"Journal Article","Fielding RT,Taylor RN","Principled Design of the Modern Web Architecture","ACM Trans. Internet Technol.","2002","2","2","115–150","Association for Computing Machinery","New York, NY, USA","","","2002-05","","1533-5399","https://doi.org/10.1145/514183.514185;http://dx.doi.org/10.1145/514183.514185","10.1145/514183.514185","The World Wide Web has succeeded in large part because its software architecture has been designed to meet the needs of an Internet-scale distributed hypermedia application. The modern Web architecture emphasizes scalability of component interactions, generality of interfaces, independent deployment of components, and intermediary components to reduce interaction latency, enforce security, and encapsulate legacy systems. In this article we introduce the Representational State Transfer (REST) architectural style, developed as an abstract model of the Web architecture and used to guide our redesign and definition of the Hypertext Transfer Protocol and Uniform Resource Identifiers. We describe the software engineering principles guiding REST and the interaction constraints chosen to retain those principles, contrasting them to the constraints of other architectural styles. We then compare the abstract model to the currently deployed Web architecture in order to elicit mismatches between the existing protocols and the applications they are intended to support.","World Wide Web, REST, Network-based applications","","",""
"Conference Paper","Lim JH,Zhan A,Goldschmidt E,Ko J,Chang M,Terzis A","HealthOS: A Platform for Pervasive Health Applications","","2012","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the Second ACM Workshop on Mobile Systems, Applications, and Services for HealthCare","Toronto, Ontario, Canada","2012","9781450317641","","https://doi.org/10.1145/2396276.2396281;http://dx.doi.org/10.1145/2396276.2396281","10.1145/2396276.2396281","Pervasive health applications that compose longitudinal information streams to infer people's health and encourage lifestyle changes have the potential to substantially benefit public health. Off-the-shelf medical and wellness sensors meet the sensing requirements of such applications but their closed and vertically-integrated designs impede composability and complicate unified management. Furthermore, the lack of security and privacy controls discourages individuals from sharing their data. This paper presents HealthOS, a development and execution framework for pervasive health applications. HealthOS addresses the sensor and system incompatibility challenge through a set of adapters. Moreover, pipeline modules translate custom formats and protocols to the requirements of target applications/systems. These modules execute in HealthOS servers, programmable devices that expose Representational State Transfer (REST) interfaces for data retrieval and sensor management. HealthOS servers can store data locally or push them to untrusted, third party services. Finally, HealthOS leverages attribute-based encryption to offer sophisticated role-based and content-based access controls for users' data.","RESTful API, pervasive health applications, platform","","","mHealthSys '12"
"Conference Paper","Nahiyan A,Xiao K,Yang K,Jin Y,Forte D,Tehranipoor M","AVFSM: A Framework for Identifying and Mitigating Vulnerabilities in FSMs","","2016","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 53rd Annual Design Automation Conference","Austin, Texas","2016","9781450342360","","https://doi.org/10.1145/2897937.2897992;http://dx.doi.org/10.1145/2897937.2897992","10.1145/2897937.2897992","A finite state machine (FSM) is responsible for controlling the overall functionality of most digital systems and, therefore, the security of the whole system can be compromised if there are vulnerabilities in the FSM. These vulnerabilities can be created by improper designs or by the synthesis tool which introduces additional don't-care states and transitions during the optimization and synthesis process. An attacker can utilize these vulnerabilities to perform fault injection attacks or insert malicious hardware modifications (Trojan) to gain unauthorized access to some specific states. To our knowledge, no systematic approaches have been proposed to analyze these vulnerabilities in FSM. In this paper, we develop a framework named Analyzing Vulnerabilities in FSM (AVFSM) which extracts the state transition graph (including the don't-care states and transitions) from a gate-level netlist using a novel Automatic Test Pattern Generation (ATPG) based approach and quantifies the vulnerabilities of the design to fault injection and hardware Trojan insertion. We demonstrate the applicability of the AVFSM framework by analyzing the vulnerabilities in the FSM of AES and RSA encryption module. We also propose a low-cost mitigation technique to make FSM more secure against these attacks.","","","","DAC '16"
"Conference Paper","Zhang K,Gong J,Tang S,Chen J,Li X,Qian H,Cao Z","Practical and Efficient Attribute-Based Encryption with Constant-Size Ciphertexts in Outsourced Verifiable Computation","","2016","","","269–279","Association for Computing Machinery","New York, NY, USA","Proceedings of the 11th ACM on Asia Conference on Computer and Communications Security","Xi'an, China","2016","9781450342339","","https://doi.org/10.1145/2897845.2897858;http://dx.doi.org/10.1145/2897845.2897858","10.1145/2897845.2897858","In cloud computing, computationally weak users are always willing to outsource costly computations to a cloud, and at the same time they need to check the correctness of the result provided by the cloud. Such activities motivate the occurrence of verifiable computation (VC). Recently, Parno, Raykova and Vaikuntanathan showed any VC protocol can be constructed from an attribute-based encryption (ABE) scheme for a same class of functions. In this paper, we propose two practical and efficient semi-adaptively secure key-policy attribute-based encryption (KP-ABE) schemes with constant-size ciphertexts. The semi-adaptive security requires that the adversary designates the challenge attribute set after it receives public parameters but before it issues any secret key query, which is stronger than selective security guarantee. Our first construction deals with small universe while the second one supports large universe. Both constructions employ the technique underlying the prime-order instantiation of nested dual system groups, which are based on the $d$-linear assumption including SXDH and DLIN assumptions. In order to evaluate the performance, we implement our ABE schemes using $textsfPython$ language in Charm. Compared with previous KP-ABE schemes with constant-size ciphertexts, our constructions achieve shorter ciphertext and secret key sizes, and require low computation costs, especially under the SXDH assumption.","charm, dual system encryption, verifiable computation, outsourced computation, attribute-based encryption","","","ASIA CCS '16"
"Conference Paper","Franzen F,Holl T,Andreas M,Kirsch J,Grossklags J","Katana: Robust, Automated, Binary-Only Forensic Analysis of Linux Memory Snapshots","","2022","","","214–231","Association for Computing Machinery","New York, NY, USA","Proceedings of the 25th International Symposium on Research in Attacks, Intrusions and Defenses","Limassol, Cyprus","2022","9781450397049","","https://doi.org/10.1145/3545948.3545980;http://dx.doi.org/10.1145/3545948.3545980","10.1145/3545948.3545980","The development and research of tools for forensically analyzing Linux memory snapshots have stalled in recent years as they cannot deal with the high degree of configurability and fail to handle security advances like structure layout randomization. Existing tools such as Volatility and Rekall require a pre-generated profile of the operating system, which is not always available, and can be invalidated by the smallest source code or configuration changes in the kernel. In this paper, we create a reference model of the control and data flow of selected representative Linux kernels. Using this model, ABI properties, and Linux’s own runtime information, we apply a configuration- and instruction-set-agnostic structural matching between the reference model and the loaded kernel to obtain enough information to drive all practically relevant forensic analyses. We implemented our approach in Katana 1, and evaluated it against Volatility. Katana is superior where no perfect profile information is available. Furthermore, we show correct functionality on an extensive set of 85 kernels with different configurations and 45 realistic snapshots taken while executing popular Linux distributions or recent versions of Android from version 8.1 to 11. Our approach translates to other CPU architectures in the Internet-of-Things (IoT) device domain such as MIPS and ARM64 as we show by analyzing a TP-Link router and a smart camera. We also successfully generalize to modified Linux kernels such as Android.","binary analysis, automated profile generation, memory forensics","","","RAID '22"
"Conference Paper","Pîrlea G,Sergey I","Mechanising Blockchain Consensus","","2018","","","78–90","Association for Computing Machinery","New York, NY, USA","Proceedings of the 7th ACM SIGPLAN International Conference on Certified Programs and Proofs","Los Angeles, CA, USA","2018","9781450355865","","https://doi.org/10.1145/3167086;http://dx.doi.org/10.1145/3167086","10.1145/3167086","We present the first formalisation of a blockchain-based distributed consensus protocol with a proof of its consistency mechanised in an interactive proof assistant. Our development includes a reference mechanisation of the block forest data structure, necessary for implementing provably correct per-node protocol logic. We also define a model of a network, implementing the protocol in the form of a replicated state-transition system. The protocol's executions are modeled via a small-step operational semantics for asynchronous message passing, in which packages can be rearranged or duplicated. In this work, we focus on the notion of global system safety, proving a form of eventual consistency. To do so, we provide a library of theorems about a pure functional implementation of block forests, define an inductive system invariant, and show that, in a quiescent system state, it implies a global agreement on the state of per-node transaction ledgers. Our development is parametric with respect to implementations of several security primitives, such as hash-functions, a notion of a proof object, a Validator Acceptance Function, and a Fork Choice Rule. We precisely characterise the assumptions, made about these components for proving the global system consensus, and discuss their adequacy. All results described in this paper are formalised in Coq.","protocol verification, consensus, blockchain, Coq","","","CPP 2018"
"Journal Article","Venkataramani G,Doudalis I,Solihin Y,Prvulovic M","MemTracker: An Accelerator for Memory Debugging and Monitoring","ACM Trans. Archit. Code Optim.","2009","6","2","","Association for Computing Machinery","New York, NY, USA","","","2009-07","","1544-3566","https://doi.org/10.1145/1543753.1543754;http://dx.doi.org/10.1145/1543753.1543754","10.1145/1543753.1543754","Memory bugs are a broad class of bugs that is becoming increasingly common with increasing software complexity, and many of these bugs are also security vulnerabilities. Existing software and hardware approaches for finding and identifying memory bugs have a number of drawbacks including considerable performance overheads, target only a specific type of bug, implementation cost, and inefficient use of computational resources.This article describes MemTracker, a new hardware support mechanism that can be configured to perform different kinds of memory access monitoring tasks. MemTracker associates each word of data in memory with a few bits of state, and uses a programmable state transition table to react to different events that can affect this state. The number of state bits per word, the events to which MemTracker reacts, and the transition table are all fully programmable. MemTracker's rich set of states, events, and transitions can be used to implement different monitoring and debugging checkers with minimal performance overheads, even when frequent state updates are needed. To evaluate MemTracker, we map three different checkers onto it, as well as a checker that combines all three. For the most demanding (combined) checker with 8 bits state per memory word, we observe performance overheads of only around 3%, on average, and 14.5% worst-case across different benchmark suites. Such low overheads allow continuous (always-on) use of MemTracker-enabled checkers, even in production runs.","memory access monitoring, Accelerator, debugging","","",""
"Conference Paper","Ramli AK,Djemame K","Autonomic Management for Convergent Networks to Support Robustness of Appliance Technologies","","2014","","","47–51","Association for Computing Machinery","New York, NY, USA","Proceedings of the 7th International Conference on Security of Information and Networks","Glasgow, Scotland, UK","2014","9781450330336","","https://doi.org/10.1145/2659651.2660516;http://dx.doi.org/10.1145/2659651.2660516","10.1145/2659651.2660516","Autonomic management within autonomic computing framework is considered as the future and viable solution for many appliances, either in software or hardware. Nevertheless, its current research application in computer networks is mainly visible in the intra domain space, and less attention is given to inter domain between one core network and another. This paper reviews some of the work on autonomic management and presents a framework that can be extended to a global and universal solution, such as fulfilling demand on bandwidth management, Quality of Service (QOS), and Service Level Agreements (SLA). The autonomic computing self- features are considered to show the viability of the proposed framework.","Next generation Networks, Autonomous and Adaptive Security, Adaptive Architecture, Bandwidth Management, Autonomic Management, Service Level Agreements, Information Assurance","","","SIN '14"
"Journal Article","Xu Z,Chen L","L2chain: Towards High-Performance, Confidential and Secure Layer-2 Blockchain Solution for Decentralized Applications","Proc. VLDB Endow.","2022","16","4","986–999","VLDB Endowment","","","","2022-12","","2150-8097","https://doi.org/10.14778/3574245.3574278;http://dx.doi.org/10.14778/3574245.3574278","10.14778/3574245.3574278","With the rapid development of blockchain, the concept of decentralized applications (DApps), built upon smart contracts, has attracted much attention in academia and industry. However, significant issues w.r.t. system throughput, transaction confidentiality, and the security guarantee of the DApp transaction execution and order correctness hinder the border adoption of blockchain DApps.To address these issues, we propose L2chain, a novel blockchain framework aiming to scale the system through a layer-2 network where DApps process transactions in the layer-2 network and only the system state digest, acting as the state integrity proof, is maintained on-chain. To achieve high performance, we introduce the split-execute-merge (SEM) transaction processing workflow with the help of the RSA accumulator, allowing DApps to lock and update a part of the state digest in parallel. We also design a witness cache mechanism for DApp executors to reduce the transaction processing latency. To fulfill confidentiality, we leverage the trusted execution environment (TEE) for DApps to execute encrypted transactions off-chain. To ensure transaction execution and order correctness, we propose a two-step execution process for DApps to prevent attacks (i.e., rollback attacks) from subverting the state transition. Extensive experiments have demonstrated that L2chain can achieve 1.5X to 42.2X and 7.1X to 8.9X throughput improvements in permissioned and permissionless settings respectively.","","","",""
"Conference Paper","Barry BI,Chan HA","On the Performance of a Hybrid Intrusion Detection Architecture for Voice over IP Systems","","2008","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 4th International Conference on Security and Privacy in Communication Netowrks","Istanbul, Turkey","2008","9781605582412","","https://doi.org/10.1145/1460877.1460902;http://dx.doi.org/10.1145/1460877.1460902","10.1145/1460877.1460902","Voice over IP (VoIP) environments pose challenging threats to Intrusion Detection Systems (IDSs). Services over VoIP systems are provided by multiple interacting protocols, each with its own vulnerabilities. This scheme could result in novel and more complex attacks, and requires cross-protocol aware IDSs. Furthermore, VoIP devices may suffer a full or partial service loss if the syntax or semantics of the aforementioned protocols are violated. Usually, a single detection approach is suited to identify a subset of the security violations to which a system is subject in VoIP environments. Therefore, a hybrid approach that combines the strengths and avoids the weaknesses of various approaches is needed. In this paper, we discuss the performance and the detection accuracy of a hybrid, host-based intrusion detection system suitable for VoIP environments. Our system has two combined detection modules, namely, a specification-based and a signature-based module. Both modules use State Machines and State Transition Analysis Techniques to model proper protocols' behaviors and potential attacks. Both modules address the issues related to syntax and semantics anomaly detection for the monitored protocols. In addition, our architecture provides a cross-protocol framework for various protocols to exchange useful detection information in real time. We implement our proposed architecture in a network simulator, alongside implementing a variety of attacks to test the credibility of the design. The implemented IDS shows an excellent detection accuracy, and low runtime impact on the performance of the VoIP system.","hybrid detection, intrusion detection, VoIP, performance","","","SecureComm '08"
"Conference Paper","Jin X,Krishnan R,Sandhu R","Reachability Analysis for Role-Based Administration of Attributes","","2013","","","73–84","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2013 ACM Workshop on Digital Identity Management","Berlin, Germany","2013","9781450324939","","https://doi.org/10.1145/2517881.2517891;http://dx.doi.org/10.1145/2517881.2517891","10.1145/2517881.2517891","Attribute-based access control (ABAC) is well-known and increasingly prevalent. Nonetheless, administration of attributes is not well-studied so far. Recently, the Generalized User-Role Assignment model (GURA) was proposed to provide ARBAC97-style (administrative role-based access control) administration of user attributes. An attribute is simply a name-value pair, examples of which include clearance, group and affiliations. In GURA, user attributes are collectively administered by different administrative roles to enable distributed administration. Given an administrative policy that specifies the conditions under which administrative roles can modify user attributes, it is useful to understand whether an attribute of a particular user can reach a specific value because user attributes are used for security-sensitive activities such as authentication, authorization and audit. In this paper, we study the user-attribute reachability problems in a restricted GURA model called rGURA. We formalize rGURA as a state transition system and show that the reachability problems for its general cases are PSPACE-complete. However, we do find polynomial-time solutions to reachability problems for limited versions of rGURA that are still useful in practice. The algorithms not only answer reachability problem but also provide a plan of sequential attribute updates by one or more administrators in order to reach particular values for user attributes. rGURA is relatively simple and practical. It is likely that other proposals will subsume the functionality of rGURA and thereby subsume its complexity results.","attributes, administration, reachability analysis","","","DIM '13"
"Journal Article","Zhang X,Parisi-Presicce F,Sandhu R,Park J","Formal Model and Policy Specification of Usage Control","ACM Trans. Inf. Syst. Secur.","2005","8","4","351–387","Association for Computing Machinery","New York, NY, USA","","","2005-11","","1094-9224","https://doi.org/10.1145/1108906.1108908;http://dx.doi.org/10.1145/1108906.1108908","10.1145/1108906.1108908","The recent usage control model (UCON) is a foundation for next-generation access control models with distinguishing properties of decision continuity and attribute mutability. A usage control decision is determined by combining authorizations, obligations, and conditions, presented as UCONABC core models by Park and Sandhu. Based on these core aspects, we develop a formal model and logical specification of UCON with an extension of Lamport's temporal logic of actions (TLA). The building blocks of this model include: (1) a set of sequences of system states based on the attributes of subjects, objects, and the system, (2) authorization predicates based on subject and object attributes, (3) usage control actions to update attributes and accessing status of a usage process, (4) obligation actions, and (5) condition predicates based on system attributes. A usage control policy is defined as a set of temporal logic formulas that are satisfied as the system state changes. A fixed set of scheme rules is defined to specify general UCON policies with the properties of soundness and completeness. We show the flexibility and expressive capability of this formal model by specifying the core models of UCON and some applications.","security policy, Access control, formal specification, usage control","","",""
"Conference Paper","Zhang W,Wei L,Li S,Liu Y,Cheung SC","ÐArcher: Detecting on-Chain-off-Chain Synchronization Bugs in Decentralized Applications","","2021","","","553–565","Association for Computing Machinery","New York, NY, USA","Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering","Athens, Greece","2021","9781450385626","","https://doi.org/10.1145/3468264.3468546;http://dx.doi.org/10.1145/3468264.3468546","10.1145/3468264.3468546","Since the emergence of Ethereum, blockchain-based decentralized applications (DApps) have become increasingly popular and important. To balance the security, performance, and costs, a DApp typically consists of two layers: an on-chain layer to execute transactions and store crucial data on the blockchain and an off-chain layer to interact with users. A DApp needs to synchronize its off-chain layer with the on-chain layer proactively. Otherwise, the inconsistent data in the off-chain layer could mislead users and cause undesirable consequences, e.g., loss of transaction fees. However, transactions sent to the blockchain are not guaranteed to be executed and could even be reversed after execution due to chain reorganization. Such non-determinism in the transaction execution is unique to blockchain. DApp developers may fail to perform the on-chain-off-chain synchronization accurately due to their lack of familiarity with the complex transaction lifecycle. In this work, we investigate the challenges of synchronizing on-chain and off-chain data in Ethereum-based DApps. We present two types of bugs that could result in inconsistencies between the on-chain and off-chain layers. To help detect such on-chain-off-chain synchronization bugs, we introduce a state transition model to guide the testing of DApps and propose two effective oracles to facilitate the automatic identification of bugs. We build the first testing framework, ÐArcher, to detect on-chain-off-chain synchronization bugs in DApps. We have evaluated ÐArcher on 11 popular real-world DApps. ÐArcher achieves high precision (99.3%), recall (87.6%), and accuracy (89.4%) in bug detection and significantly outperforms the baseline methods. It has found 15 real bugs in the 11 DApps. So far, six of the 15 bugs have been confirmed by the developers, and three have been fixed. These promising results demonstrate the usefulness of ÐArcher.","Software testing, Blockchain, Decentralized applications, DApps","","","ESEC/FSE 2021"
"Conference Paper","Bando M,Artan NS,Chao HJ","LaFA: Lookahead Finite Automata for Scalable Regular Expression Detection","","2009","","","40–49","Association for Computing Machinery","New York, NY, USA","Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems","Princeton, New Jersey","2009","9781605586304","","https://doi.org/10.1145/1882486.1882496;http://dx.doi.org/10.1145/1882486.1882496","10.1145/1882486.1882496","Although Regular Expressions (RegExes) have been widely used in network security applications, their inherent complexity often limits the total number of RegExes that can be detected using a single chip for a reasonable throughput. This limit on the number of RegExes impairs the scalability of today's RegEx detection systems. The scalability of existing schemes is generally limited by the traditional per character state processing and state transition detection paradigm. The main focus of existing schemes is in optimizing the number of states and the required transitions, but not the suboptimal character-based detection method. Furthermore, the potential benefits of reduced number of operations and states using out-of-sequence detection methods have not been explored. In this paper, we propose Looka-head Finite Automata (LaFA) to perform scalable RegEx detection using very small amount of memory. LaFA's memory requirement is very small due to the following three areas of effort described in this paper: (1) Different parts of a RegEx, namely RegEx components, are detected using different detectors, each of which is specialized and optimized for the detection of a certain RegEx component. (2) We systematically reorder the RegEx component detection sequence, which provides us with new possibilities for memory optimization. (3) Many redundant states in classical finite automata are identified and eliminated in LaFA. Our simulations show that LaFA requires an order of magnitude less memory compared to today's state-of-the-art RegEx detection systems. A single commodity Field Programmable Gate Array (FPGA) chip can accommodate up to twenty-five thousand (25k) RegExes. Based on the throughput of our LaFA prototype on FPGA, we estimated that a 34-Gbps throughput can be achieved.","finite automation, deep packet inspection, regular expressions, network intrusion detection system, FPGA, LaFA","","","ANCS '09"
"Conference Paper","Benard V,Richard P,Vanderhaegen F,Caulier P","Contribution to the Characterization and Identification of Human Stability with Regard to Safety: Application to Guided Transport Systems","","2012","","","13–20","Australian Computer Society, Inc.","AUS","Proceedings of the Australian System Safety Conference - Volume 145","Brisbane, Australia","2012","9781921770159","","","","This paper presents an original contribution based on the concept of human stability by identifying the associated risks as part of the safety system assessment. The difficulties to take into account human factors in safety studies are first highlighted and definitions of new ways for the integration of human factors based on the existing concepts of stability and resilience are proposed. Although the stability concept is usually defined around a sustainable equilibrium point that induces a feeling of safety control during normal operation, it appears that the stable behaviour of a human operator can lead to risk in certain situations or contexts such as hypo-vigilance, inattention and so on. The core of this paper lays the foundation of human stability for risks assessment. Here, Human stability is defined as the ability of the operator to stay in a stable operating state under specified conditions. This concept is formalized and 3 modes of stability are developed (time, frequency and sequential modes) in order to identify states and change of states of the human stability. The concept of human stability is then applied in the framework of ERTMS/ETCS and shows that sequences of Human stability states and changes of Human stability states may be precursors of risk. Finally, some perspectives highlight the interest of human stability for the definition of risk indicators to assess system safety, by considering the Human operator as a safety/security multi-criteria sensor for the supervision of human-machine systems.","safety, transportation application, resilience, human stability","","","ASSC '12"
"Conference Paper","Ortiz A","A Bottom-Up Approach to Teaching Server-Side Web Development Skills (Abstract Only)","","2015","","","678","Association for Computing Machinery","New York, NY, USA","Proceedings of the 46th ACM Technical Symposium on Computer Science Education","Kansas City, Missouri, USA","2015","9781450329668","","https://doi.org/10.1145/2676723.2691922;http://dx.doi.org/10.1145/2676723.2691922","10.1145/2676723.2691922","When dealing with the topic of back-end programming many CS web development courses typically focus on how to use a popular web framework, for example Spring MVC or Ruby on Rails. The problem with this approach is that students will most likely end up using some other different framework or technology if ever they decide to become professional web developers. Our students need to learn concepts and skills that serve as a foundation to learn whatever different technologies are used now or happen to appear in the future. This poster presents the author's experience on using a bottom-up approach to teach the fundamental aspects of how the HTTP protocol works, and how this knowledge can be used to get a deep understanding of the inner workings of the web by building a simple yet complete server-side web framework. Using Node.js as the development platform, students are able to take TCP sockets as the building blocks for higher-level web abstractions. This approach allows covering a variety of specific topics that are essential for a professional web developer: request and response structure and headers, HTTP methods, form processing, cookies and sessions, text encodings, MVC software architectural pattern, database integration using ORM (Object-Relational Mapping), REST (Representational State Transfer) architecture, security issues (HTTPS protocol, common web vulnerabilities), and client-side integration using AJAX (Asynchronous JavaScript and XML). Anecdotal evidence shows that students with this knowledge repertoire are better suited for learning, using and debugging new and existing web technologies.","web development, server-side programming, node.js, javascript","","","SIGCSE '15"
"Journal Article","Kang L,Shen H","Detection and Mitigation of Sensor and CAN Bus Attacks in Vehicle Anti-Lock Braking Systems","ACM Trans. Cyber-Phys. Syst.","2022","6","1","","Association for Computing Machinery","New York, NY, USA","","","2022-01","","2378-962X","https://doi.org/10.1145/3495534;http://dx.doi.org/10.1145/3495534","10.1145/3495534","For a modern vehicle, if the sensor in a vehicle anti-lock braking system (ABS) or controller area network (CAN) bus is attacked during a brake process, the vehicle will lose driving direction control and the driver’s life will be highly threatened. However, current methods for detecting attacks are not sufficiently accurate, and no method can provide attack mitigation. To ensure vehicle ABS security, we propose an attack detection method to accurately detect both sensor attack (SA) and CAN bus attack in a vehicle ABS, and an attack mitigation strategy to mitigate their negative effects on the vehicle ABS. In our attack detection method, we build a vehicle state space equation that considers the real-time road friction coefficient to predict vehicle states (i.e., wheel speed and longitudinal brake force) with their previous values. Based on sets of historical measured vehicle states, we develop a search algorithm to find out attack changes (vehicle state changes because of attack) by minimizing errors between the predicted vehicle states and the measured vehicle states. In our attack mitigation strategy, attack changes are subtracted from the measured vehicle states to generate correct vehicle states for a vehicle ABS. We conducted the first real SA experiments to show how a magnet affects sensor readings. Our simulation results demonstrate that our attack detection method can detect SA and CAN bus attack more accurately compared with existing methods, and also that our attack mitigation strategy almost eliminates the attack’s effects on a vehicle ABS.","attack mitigation, Vehicle ABS, attack detection, CAN bus attack, sensor attack","","",""
"Book","","ANC '13: Proceedings of the Second ACM MobiHoc Workshop on Airborne Networks and Communications","","2013","","","","Association for Computing Machinery","New York, NY, USA","","Bangalore, India","2013","9781450322089","","","","On behalf of the organizers, we extend a warm welcome to the second ACM MobiHoc workshop on ""Airborne Networks and Communications"" to all participants. An airborne network is a mobile network consisting of manned and unmanned air vehicles as well as ground vehicles. The ability of ground and air vehicles to communicate voice, video, and data offers enhanced safety and efficiency for the next generation (NextGen) air transportation systems. Airborne networks can benefit many civilian applications such as air-traffic control, border patrol, and search and rescue missions.This workshop is a result of the ideas that emerged from the meetings held over the past few years on topics that focused on cyber-physical systems (CPS) for air transportation as well as NextGen aviation systems. We believe that this workshop is an opportunity for researchers engaged in airborne networking and communications to discuss state-of-the-art, share their research results with their peers, and develop directions for future research in this emerging field.Airborne networking is a cyber-physical system. While computation, communication and networking elements form the cyber components of the system, flight-paths, maneuver geometries, and multi-mode resources including ground-based nodes and control stations form the physical components of the CPS. The synergy between the cyber and physical components, if explored and exploited, will significantly enhance the safety and security capabilities of Next Generation air transportation systems. However, fundamental design principles which are needed to explore this synergy do not exist and experimental datasets which are needed to develop such design principles are beyond the reach of academic community.During this workshop, we will hear from experienced speakers coming from the industry, universities, and federal laboratories on topics covering theoretical foundations and models for mobility, connectivity, and coverage, cyber-physical system perspective of airborne networks, airborne/satellite communication and networking platforms and strategies, protocols for secure information sharing, swarming, collaboration, and self-organization, network trials, test-beds, experiments, and measurements and applications of airborne networking to real world domains such as border patrol, air-traffic control, search and rescue missions, and unmanned cargo. We look forward to your active participation in this workshop.","","","Proceedings",""
"Conference Paper","Sakalis C,Kaxiras S,Ros A,Jimborean A,Själander M","Efficient Invisible Speculative Execution through Selective Delay and Value Prediction","","2019","","","723–735","Association for Computing Machinery","New York, NY, USA","Proceedings of the 46th International Symposium on Computer Architecture","Phoenix, Arizona","2019","9781450366694","","https://doi.org/10.1145/3307650.3322216;http://dx.doi.org/10.1145/3307650.3322216","10.1145/3307650.3322216","Speculative execution, the base on which modern high-performance general-purpose CPUs are built on, has recently been shown to enable a slew of security attacks. All these attacks are centered around a common set of behaviors: During speculative execution, the architectural state of the system is kept unmodified, until the speculation can be verified. In the event that a misspeculation occurs, then anything that can affect the architectural state is reverted (squashed) and re-executed correctly. However, the same is not true for the microarchitectural state. Normally invisible to the user, changes to the microarchitectural state can be observed through various side-channels, with timing differences caused by the memory hierarchy being one of the most common and easy to exploit. The speculative side-channels can then be exploited to perform attacks that can bypass software and hardware checks in order to leak information. These attacks, out of which the most infamous are perhaps Spectre and Meltdown, have led to a frantic search for solutions.In this work, we present our own solution for reducing the microarchitectural state-changes caused by speculative execution in the memory hierarchy. It is based on the observation that if we only allow accesses that hit in the L1 data cache to proceed, then we can easily hide any microarchitectural changes until after the speculation has been verified. At the same time, we propose to prevent stalls by value predicting the loads that miss in the L1. Value prediction, though speculative, constitutes an invisible form of speculation, not seen outside the core. We evaluate our solution and show that we can prevent observable microarchitectural changes in the memory hierarchy while keeping the performance and energy costs at 11% and 7%, respectively. In comparison, the current state of the art solution, InvisiSpec, incurs a 46% performance loss and a 51% energy increase.","side-channel attacks, speculative execution, caches","","","ISCA '19"
"Book","","Airborne '12: Proceedings of the First ACM MobiHoc Workshop on Airborne Networks and Communications","","2012","","","","Association for Computing Machinery","New York, NY, USA","","Hilton Head, South Carolina, USA","2012","9781450312905","","","","On behalf of the organizers, we extend a warm welcome to the first ACM MobiHoc workshop on ""Airborne Networks and Communications"" to all participants. An airborne network is a mobile network consisting of manned and unmanned air vehicles as well as ground vehicles. The ability of ground and air vehicles to communicate voice, video, and data offers enhanced safety and efficiency for the next generation (NextGen) air transportation systems. Airborne networks can benefit many civilian applications such as air-traffic control, border patrol, and search and rescue missions.This workshop is a result of the ideas that emerged from the meetings held over the past few years on topics that focused on cyber-physical systems (CPS) for air transportation as well as NextGen aviation systems. We believe that the time is right for airborne networking and communications to be part of main stream conferences. We believe that this workshop is an opportunity for researchers engaged in airborne networking and communications to discuss state-of-the-art, share their research results with their peers, and develop directions for future research in this emerging field.Airborne networking is a cyber-physical system. While computation, communication and networking elements form the cyber components of the system, flight-paths, maneuver geometries, and multi-mode resources including ground-based nodes and control stations form the physical components of the CPS. The synergy between the cyber and physical components, if explored and exploited, will significantly enhance the safety and security capabilities of Next Generation air transportation systems. However, fundamental design principles which are needed to explore this synergy do not exist and experimental datasets which are needed to develop such design principles are beyond the reach of academic community.During this workshop, we will hear from experienced speakers coming from the industry, universities, and federal laboratories on topics covering theoretical foundations and models for mobility, connectivity, and coverage, cyber-physical system perspective of airborne networks, airborne/satellite communication and networking platforms and strategies, protocols for secure information sharing, swarming, collaboration, and self-organization, network trials, test-beds, experiments, and measurements and applications of airborne networking to real world domains such as border patrol, air-traffic control, search and rescue missions, and unmanned cargo. We look forward to your active participation in this workshop.","","","Proceedings",""
"Conference Paper","Xu C,Ilyevskiy D","Isopod: An Expressive DSL for Kubernetes Configuration","","2019","","","483","Association for Computing Machinery","New York, NY, USA","Proceedings of the ACM Symposium on Cloud Computing","Santa Cruz, CA, USA","2019","9781450369732","","https://doi.org/10.1145/3357223.3365759;http://dx.doi.org/10.1145/3357223.3365759","10.1145/3357223.3365759","Kubernetes is an open-source cluster orchestration system for containerized workloads to reduce idiosyncrasy across cloud vendors [2]. Using Kubernetes, Cruise has built a multi-tenant platform with thousands of cores and tens of terabytes of memory. Such a scale is possible in part thanks to the declarative abstraction of Kubernetes, where desired states are described in YAML manifests [5].However, YAML as a data serialization format is unfit for workload specification. Structured data in YAML are untyped and prone to wrong indents and missing fields. Due to poor meta-programming support, composing YAML with control logic---loops and branches---suffers from YAML fragmentation and indentation tracking (example at bit.ly/yml-hell). Moreover, YAML manifests are often generated by filling a shared template with cluster-specific parameters---the image tag and the replica count might differ in development and production environments. Existing templating tools---Helm [11], Kustomize [9], Kapitan [7] and the likes---assume these parameters are statically known and use CLIs to query dynamic ones, such as secrets stored in HashiCorp Vault [10]. Such scheme is hard to test, since side effects escape through CLIs, and highly depends on the execution environment, since CLI versions vary across machines or might not exist. Not least, YAML manifests describe the eventual state but not how existing workloads will be affected. Blindly applying the manifest---for example, from a stale version of code---can be disastrous and cause unexpected outages.Isopod presents an alternative configuration paradigm by treating Kubernetes objects as first-class citizens. Without intermediate YAML artifacts, Isopod renders Kubernetes objects directly in Protocol Buffers [8], so they are strongly typed and consumed directly by the Kubernetes API. With Isopod, configurations are scripted in Starlark [3], a Python dialect by Google also used by Bazel [1] and Buck [4] build systems. To replace CLI dependencies, Isopod extends Starlark with runtime built-ins to access services and utilities such as Vault, Kubernetes apiserver, Base64 encoder, and UUID generator, etc. Isopod uses a separate runtime for unit tests to mock all built-ins, providing test coverage that was not possible before.Isopod is also hermetic and secure. The common reliance on the kubeconfig file for cluster authentication leaks secrets to disk, a security risk if working from a shared host, such as a cluster node or CICD worker. Instead, Isopod builds Oauth2 tokens [6] to the target cluster using the Identity & Access Management (IAM) service of the cloud vendor. Application secrets are stored in Vault and queried at runtime. Hence, no secrets escape to the disk. In fact, Isopod prohibits disk IO except for loading Starlark modules from other scripts. No external libraries can be loaded unless explicitly implemented as an Isopod built-in. Distributed as a single binary, Isopod is self-contained with all dependencies.Finally, Isopod is extensible. Protobuf packages of Kubernetes API groups added in the future can be loaded in the same way. Because built-ins are modular and pluggable, users can easily implement and register new built-ins with the Isopod runtime to support any Kubernetes vendors. Isopod offers many other features, such as object life cycle management and parallel rollout to multiple clusters, which is impossible if using kubeconfig. In dry-run mode, Isopod displays intended actions from the current code change as a YAML diff against live objects in the cluster to avoid unexpected configuration change.Since the adoption of Isopod, the PaaS team at Cruise has migrated 14 applications and added another 16 without outage or regression, totaling around 10,000 lines of Starlark. The migration results in up to 60% reduction in code size and 80% faster rollout due to code reuse, cluster parallelism, and the removal of YAML intermediaries. All unit tests take less than 10 secs to finish. Isopod is open source at github.com/cruise-automation/isopod.","Configuration Language, Cluster Orchestration","","","SoCC '19"
"Conference Paper","Martin B","Concurrent Programming vs. Concurrency Control: Shared Events or Shared Data","","1988","","","142–144","Association for Computing Machinery","New York, NY, USA","Proceedings of the 1988 ACM SIGPLAN Workshop on Object-Based Concurrent Programming","San Diego, California, USA","1988","9780897913041","","https://doi.org/10.1145/67386.67426;http://dx.doi.org/10.1145/67386.67426","10.1145/67386.67426","Two views of concurrency in an object system exist. Those pursuing concurrent programming believe that activities in the real world are inherently concurrent and therefore objects are themselves active. Objects engage in shared events by sending and receiving messages. Communicating Sequential Processes [Hoar85a] and Actors [Agha86a] embrace this view. On the other hand, those pursuing models of concurrency control believe that objects are data and that concurrent access to data needs to be controlled by the system according to some correctness notion. Database transactions, atomic objects [Weih84a, Schw84a] and nested objects [Mart88a] embrace this view.Concurrent programming, in our view, places a significant burden on programming. Correct concurrent behavior is specified as combinations of interactions within a potentially large set of concurrent objects. A programmer must verify that the implementations of all the objects never produce undesirable interactions. Correctness of concurrent behavior is left to the programmer.We are pursuing models embracing concurrency control primarily because a programmer is not required to consider concurrency. The operations on an object can be specified in terms of preconditions and postconditions and traditional program verification techniques can be used to verify an operation's implementation. A programmer only considers the serial behavior of an object in isolation; he need not concern himself with how other concurrent activities might affect the object. Correctness of interleavings is left to the system.Serializability is the usual correctness notion for concurrency control algorithms. In transaction terminology, each competing transaction executes a sequence of basic actions. Any interleaving of the actions is correct if it is equivalent to some serial execution of the transaction. Serializability allows a transaction to be programmed in isolation, that is without considering possible interleavings with other transactions. The system may indeed interleave the actions of several transactions but it is up to the system to make the interleaving appear serial.Concurrent programming is apparently more general. A programmer can implement anything, including undesirable interactions like deadlock. The price for this generality is that the programmer must reason about global orderings of events and thus correctness is difficult to show.The traditional transaction model is not general enough for programming shared object systems. For example, several researchers, [Bern87a, Garc87a, Pu88a], have recognized that transactions are too restrictive for long-lived activities. The problem is that the transaction model is too conservative. Only reading and writing a data item at a single layer of abstraction is modeled. Once a read-write, write-read or write-write dependency is established between two transactions, it remains for the life of the transaction and limits further interleavings.Our approach is to discover and explore less restrictive correctness notions that still allow programmers to implement operations on objects in isolation. In [Mart88a] we present two such correctness notions: externally serializable computations and semantically verifiable nonserializable computations. Both correctness notions assume the nested object model. In [Mart87a] we give a nested object solution to the Dining Philosophers' Problem [Dijk71a]. Nested objects incorporate both the semantics of an object and the data abstraction hierarchy of an object.Nested objects form a nested object system. A nested object system is hierarchical; objects exist at different levels of the system. The execution of an operation on an object at level i results in the execution of operations on objects at level i-1. However, only top level objects are viewed externally.A computation at level i is a description of the state change made to level i objects and the return values produced by executing a partially ordered set of operations on level i objects. The computations at each level together form an n-level system computation.Externally serializable computations are n-level system computations in which the top level objects are left in states that could be produced by serial computations. However, lower level objects may be left in states that no serial computation could produce. Because both data abstraction hierarchies and operations semantics are considered in the nested object model, dependencies established between concurrent computations can be systematically ignored. Long-lived computations can execute efficiently if dependencies can later be ignored.Nested objects are more general than other models of concurrency control. Transactions are two-level nested objects that read and write basic data items. Atomic objects are two-level nested objects that perform abstract operations.The 1988 Object Based Concurrent Programming Workshop did not directly address the differences between concurrent programming and concurrency control. Perhaps future workshops can contrast the generality, the applicability, the programmability, the security and the performance implications of models from both concurrent programming and concurrency control.","","","","OOPSLA/ECOOP '88"
"Journal Article","Martin B","Concurrent Programming vs. Concurrency Control: Shared Events or Shared Data","SIGPLAN Not.","1988","24","4","142–144","Association for Computing Machinery","New York, NY, USA","","","1988-09","","0362-1340","https://doi.org/10.1145/67387.67426;http://dx.doi.org/10.1145/67387.67426","10.1145/67387.67426","Two views of concurrency in an object system exist. Those pursuing concurrent programming believe that activities in the real world are inherently concurrent and therefore objects are themselves active. Objects engage in shared events by sending and receiving messages. Communicating Sequential Processes [Hoar85a] and Actors [Agha86a] embrace this view. On the other hand, those pursuing models of concurrency control believe that objects are data and that concurrent access to data needs to be controlled by the system according to some correctness notion. Database transactions, atomic objects [Weih84a, Schw84a] and nested objects [Mart88a] embrace this view.Concurrent programming, in our view, places a significant burden on programming. Correct concurrent behavior is specified as combinations of interactions within a potentially large set of concurrent objects. A programmer must verify that the implementations of all the objects never produce undesirable interactions. Correctness of concurrent behavior is left to the programmer.We are pursuing models embracing concurrency control primarily because a programmer is not required to consider concurrency. The operations on an object can be specified in terms of preconditions and postconditions and traditional program verification techniques can be used to verify an operation's implementation. A programmer only considers the serial behavior of an object in isolation; he need not concern himself with how other concurrent activities might affect the object. Correctness of interleavings is left to the system.Serializability is the usual correctness notion for concurrency control algorithms. In transaction terminology, each competing transaction executes a sequence of basic actions. Any interleaving of the actions is correct if it is equivalent to some serial execution of the transaction. Serializability allows a transaction to be programmed in isolation, that is without considering possible interleavings with other transactions. The system may indeed interleave the actions of several transactions but it is up to the system to make the interleaving appear serial.Concurrent programming is apparently more general. A programmer can implement anything, including undesirable interactions like deadlock. The price for this generality is that the programmer must reason about global orderings of events and thus correctness is difficult to show.The traditional transaction model is not general enough for programming shared object systems. For example, several researchers, [Bern87a, Garc87a, Pu88a], have recognized that transactions are too restrictive for long-lived activities. The problem is that the transaction model is too conservative. Only reading and writing a data item at a single layer of abstraction is modeled. Once a read-write, write-read or write-write dependency is established between two transactions, it remains for the life of the transaction and limits further interleavings.Our approach is to discover and explore less restrictive correctness notions that still allow programmers to implement operations on objects in isolation. In [Mart88a] we present two such correctness notions: externally serializable computations and semantically verifiable nonserializable computations. Both correctness notions assume the nested object model. In [Mart87a] we give a nested object solution to the Dining Philosophers' Problem [Dijk71a]. Nested objects incorporate both the semantics of an object and the data abstraction hierarchy of an object.Nested objects form a nested object system. A nested object system is hierarchical; objects exist at different levels of the system. The execution of an operation on an object at level i results in the execution of operations on objects at level i-1. However, only top level objects are viewed externally.A computation at level i is a description of the state change made to level i objects and the return values produced by executing a partially ordered set of operations on level i objects. The computations at each level together form an n-level system computation.Externally serializable computations are n-level system computations in which the top level objects are left in states that could be produced by serial computations. However, lower level objects may be left in states that no serial computation could produce. Because both data abstraction hierarchies and operations semantics are considered in the nested object model, dependencies established between concurrent computations can be systematically ignored. Long-lived computations can execute efficiently if dependencies can later be ignored.Nested objects are more general than other models of concurrency control. Transactions are two-level nested objects that read and write basic data items. Atomic objects are two-level nested objects that perform abstract operations.The 1988 Object Based Concurrent Programming Workshop did not directly address the differences between concurrent programming and concurrency control. Perhaps future workshops can contrast the generality, the applicability, the programmability, the security and the performance implications of models from both concurrent programming and concurrency control.","","","",""
"Journal Article","Campbell AT,Schwartz M","ACM SIGCOMM Computer Communication Review","SIGCOMM Comput. Commun. Rev.","2001","31","5","20–24","Association for Computing Machinery","New York, NY, USA","","","2001-10","","0146-4833","https://doi.org/10.1145/1037107.1037111;http://dx.doi.org/10.1145/1037107.1037111","10.1145/1037107.1037111","At some point in the future, how far out we do not exactly know, wireless access to the Internet will outstrip all other forms of access bringing the freedom of mobility to the way we access the web, communicate with each other, and conduct business. In short, the Internet is going mobile and wireless, perhaps quite soon.A number of diverse technologies are leading the charge, including, 3G cellular networks based on CDMA technology, a wide variety of what is deemed 2.5G cellular technologies (e.g., EDGE, GPRS and HDR), and IEEE 802.11 wireless local area networks (WLANs). Wireless ISPs will offer a number of these technologies to mobile users. In some case, handsets will come with software radios that simultaneously support multiple access technologies on-the-fly; for example, IEEE 802.11 for high-bandwidth access in urban areas and GPRS for wide area access in rural areas.Each technology has its pros and cons. First and second generation cellular systems offer wide area low bandwidth voice services based on analog and digital technology, respectively. The 3G cellular systems are designed to carry voice, video and data simultaneously, and offer data rates of 144 Kbps for fast-moving mobile users in vehicles, 384 Kbps for slower moving pedestrian users, and 2 Mbps from fixed locations. Note that all users within a cell share these data rates. The 3G networks offer higher capacity and increased spectral efficiency but retain a circuit-switched, hierarchical architecture. In contrast, WLAN offers even higher bandwidth and is considered IP friendly because it offers a link layer that is very similar to wired Ethernet. However, in comparison to 3G networks, WLAN only operates within the local area, only supports best effort services, and uses shared unlicensed spectrum where few quality assurances can be provided to users.Recently, there has been a considerable amount of press on the slow rollout of 3G. However, there are some signs for optimism. Japan's NTT DoCoMo started offering 3G services in October 2001 in the Tokyo area. This came after the initial postponement of the rollout of 3G services by providers in Japan and Europe. Since May 2001, 5,000 residents in the Tokyo area have been using new 3G phones that offer improved i-mode service and real-time videoconferencing. The initial video offering uses a 64 Kbps circuit that carries video and audio combined. One of the guest editors had the opportunity to use a trial handset to set up a video call to a colleague in a taxi while traveling through Tokyo. The real-time video call, which used MPEG4 technology, presented mixed service quality but the experience of setting up the call between two taxis was exciting. I-mode currently has 29 million subscribers in Japan and DoCoMo hopes to keep that figure rising with the new service offerings. The DoCoMo radio access network is based on WCDMA and the core network on ATM switching.Many carriers in the US and Europe will be keenly watching what is happening in Tokyo. Wireless providers in the United States are eager to follow suit but are rolling out service in phases with emphasis on 2.5G technologies such as GPRS, which provides an always-on connection to the Internet that allows users to toggle between surfing the web, a phone call, or text messaging without losing the connection. Carriers in Europe, which have invested more than $100 billion to buy 3G radio spectrum licenses and will need to invest another $100 billion for the build-out of the 3G networks, will be keeping a close watch on DoCoMo's successes and failures.The vast majority of WLAN deployed today is based on IEEE 802.11b operating at 2.4 Ghz and offering data rates up to 11 Mbps. Recently, a number of companies have demonstrated IEEE 802.11 a, which operates in the 5Ghz band and offers data rates up to 54 Mbps. In fact, Atheros Communications supports a ""turbo-networking"" mode that delivers 108 Mbps, roughly equivalent to Fast Ethernet. The cost of the 3G spectrum and the build-out of the 3G networks have been so prohibitive that many operators have been pushed to the brink of bankruptcy. As a result, many small operators in Europe are sharing the cost of the build-out by sharing core and radio access network infrastructure. In contrast, WLAN infrastructure operates in unlicensed frequency bands and is very cheap in comparison to cellular equipment. Cheap, because WLAN base-station transceivers are priced at less than $1,000, and transceiver cards are around $100 or come built into computers. Public wireless LANs can handle large volumes of data at significantly lower costs compared to leading 3G technologies. The cost benefit and bandwidth differential offered by WLAN technology makes it a disruptive technology as the cellular operators migrate from 2G to 3G.Disruptive technologies are characterized as being cheaper and of lower performance than sustainin g technologies (e.g., 2.5G or 3G solutions). Most public wireless networks and enterprise networks use WLAN, not because it is more secure, robust or spectrally efficient, but simply because it is cheap, offers high bandwidth, makes networks easy to build and configure, and, importantly, it works. Typically, customers are not initially satisfied with the performance offered by disruptive technologies when they are first introduced. For WLAN to compete in the marketplace with 2.5G and 3G solutions, public WLAN operators would need to be capable of building metropolitan area networks that provided suitable support for voice-over-IP there by enabling voice communications. Sharing unlicensed spectrum means that wireless ISPs cannot build managed networks where services are tightly controlled, in isolation from other operators, as a means of assuring performance. Historically, however, disruptive technologies have tended to resolve such performance problems as they mature and begin to capture market share.Examples of wireless extensions to Internet are all around us today. Here in New York City many companies, university campuses, coffee shops and stores offer wireless access to the web using WLAN technology. Columbia University, for example, provides students and faculty wireless access to the web as they move around campus. Companies such as MobiStar and Waypoint provide wireless connections at hotels, airports and cafes. Around Manhattan, Starbucks coffee shops offer wireless access to the Internet. At the grassroots level, community groups are putting up wireless antennas around the New York City area and in other cities offering free access to Internet. Some predict that these ""freenets"", which have a feel reminiscent to Napster, will ultimately succumb to a sustained corporate challenge or new wireless ISPs that offer cheap services across dense urban areas. The road to success for such fledgling operators may be littered with a number of business, regulatory and performance obstacles.There are a number of companies, standards bodies, and industrial fora vying to define future wireless extensions to the Internet. The end result is that operators are faced with a large and confusing array of choices on how best to build next generation mobile networks. 3G systems offer support for seamless mobility, paging, and service quality but are built on complex and costly connection-oriented networking infrastructure that lacks the inherent flexibility, scalability, and cost effectiveness found in IP networks. In contrast, Mobile IP represents a simple and scalable global mobility solution but lacks support for fast handoff control, real-time location tracking, and authentication and distributed policy management found in cellular networks today. There has also been considerable interest in new emerging wireless technologies such as personal area networks, mobile ad hoc networks and sensor networks. How these technologies interwork with the global Internet is an active area of research.A number of micro-mobility protocols (e.g., Cellular IP, Hawaii, Hierarchical Mobile IP) and fast handoff schemes have been discussed in the IETF Mobile IP Working Group that address some of these performance and scalability issues. These protocols are designed for environments where mobile hosts change their point of attachment to the network so frequently that the basic Mobile IP protocol tunneling mechanism introduces network overhead in terms of increased delay, packet loss and signaling. For example, many real-time wireless applications (e.g., voice-over-IP) would experience noticeable degradation of service with frequent handoff. Establishment of new tunnels can introduce additional delays in the handoff process, causing packet loss and delayed delivery of data to applications. This delay is inherent in the round-trip incurred by Mobile IP as the registration request is sent to the home agent and the response sent back to the foreign agent. Micromobility protocols aim to handle local movement (e.g., within a domain) of mobile hosts without interaction with the Mobile IP enabled Internet. This has the benefit of reducing delay and packet loss during handoff and eliminating registration between mobile hosts and possibly distant home agents when mobile hosts remain inside their local coverage areas. Eliminating registration in this manner reduces the signaling load experienced by the network in support of mobility.As the numbers of wireless users grow so will the signaling overhead associated with mobility management. In cellular networks registration and paging techniques are used to minimize the signaling overhead and optimize mobility management performance. Currently, Mobile IP supports registration but not paging. An important characteristic of micro-mobility protocols is their ability to reduce the signaling overhead related to frequent mobile migrations taking into account a mobile host's operational mode (i.e., active or idle). When wireless access to Internet becomes the norm then Mobile IP will have to provide efficient and scalable location tracking in support of idle users, and IP paging in support of active communications. Support for ""passive connectivity"" to the wireless Internet balances a number of important design considerations. For example, only keeping the approximate location information of idle users requires significantly less signaling and thus reduces the load over the air interface and in the network. Reducing signaling over the air interfaces in this manner also has the benefit of preserving the power reserves of mobile hosts. Currently, the IETF Seamoby Working Group is tasked with developing an IP paging protocol.The papers in this special issue address a number of the issues and challenges discussed above. We received a total of 32 excellent submissions for this special issue -- a much greater response to our call for papers than we expected. The papers came from different regions around the world and addressed many different aspects of research. Each paper was reviewed by three or more experts, who evaluated the technical content and suitability of the paper for publication in this special issue. As guest editors of the special issue we had the very difficult job of selecting only six papers from those submitted. Several deserving papers could not be accommodated in this special issue because of space. We hope to see those papers appear later in ACM SIGCOMM Computer Communication Review.The first three papers in this special issue address a number of enhancements to Mobile IP and cellular networks to provide for better support for fast handoff and context transfer, wireless Internet telephony, and IP paging. The final three papers deal with the emerging technologies of personal area networks, mobile ad hoc networks and sensor networks.In the first paper, Jonathan Lennox, Kazutaka Murakami, Mehmet Karaul and Thomas F. La Porta, Lucent Technologies, discuss internetworking Internet telephony and wireless telecommunications networks. The authors propose a number of schemes to directly interconnect the 3G UMTS and SIP Internet telephony systems.The next paper by Rajeev Koodli and Charles E. Perkins, Nokia, deals with seamless handoff and context relocation in mobile networks. Context transfer refers to state information (e.g., QOS state) associated with a particular service (e.g., VoIP) that needs to be re-established with mobility. The authors show that fast handoff with context transfer at the network layer can support uninterrupted voice-over-IP services.The paper by Pars Mutaf and Claude Castelluccia, INRIA, proposes adaptive per-host IP paging. The authors observe that many of the existing IP paging proposals found in the literature promote the use of static or manually configured paging areas. The authors argue that there is a need for dynamic and adaptive paging area management that takes into account host mobility and traffic patterns in the network.Robin Kravets, Casey Carter and Luiz Magalhaes, University of Illinois, Urbana-Champaign, discuss cooperative approaches to user mobility. The authors propose the necessary networking functionality that allows groups of mobile devices (e.g., a set of devices that collectively comprise a personal area network) to interact and be seamlessly integrated into the Internet.In the next paper, Jyoti Raju and J. J. Garcia-Luna-Aceves UC Santa Cruz, present a new mobile ad hoc network routing protocol called source tracing and compare it with dynamic source routing (DSR). Both on-demand and table-driven implementations are considered.The final paper in this special issue, by Samir Goel and Tomasz Imielinski, Rutgers University, considers the problem of monitoring data in large sensor networks. The authors propose a prediction-based monitoring scheme that can be visualized by leveraging concepts and techniques found in image processing.There are many other technical challenges before Internet goes truly wireless and mobile. For example, there is a need to minimize the impact of mobility on TCP performance, resolve security issues over-the-air, and further study how best content can be pushed toward mobile users. Finally, in the wake of the recent attack in New York City, we anticipate new advances in rapidly deployable wireless infrastructure, self-configuring networks, and sensor networks - collectively forming disaster relief networks.As guest editors it has been a great pleasure to put together this issue. We would like to thank the authors for their contributions and the reviewers for their time, energy, and comments that helped shape this special issue. We hope you enjoy it as much as we do.","","","",""
